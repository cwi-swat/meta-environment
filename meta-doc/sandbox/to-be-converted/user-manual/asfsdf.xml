<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article [
<!ENTITY % sgml.features "IGNORE">
<!ENTITY % xml.features "INCLUDE">
]>
<article version="5.0" xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:ns6="http://www.w3.org/1999/xhtml"
         xmlns:ns5="http://www.w3.org/2000/svg"
         xmlns:ns4="http://www.w3.org/1998/Math/MathML"
         xmlns:ns3="http://www.w3.org/2001/XInclude"
         xmlns:ns="http://docbook.org/ns/docbook">
  <info>
    <title>Understanding ASF+SDF</title>

    <authorgroup>
      <author>
        <personname><firstname>Mark</firstname><surname>van den
        Brand</surname></personname>
      </author>

      <author>
        <personname><firstname>Paul</firstname><surname>Klint</surname></personname>
      </author>

      <author>
        <personname><firstname>Jurgen</firstname><surname>Vinju</surname></personname>
      </author>
    </authorgroup>
  </info>

  <section>
    <title>An Introduction to ASF+SDF</title>

    <para>ASF+SDF is the result of the marriage of two formalisms ASF
    (Algebraic Specification Formalism) and SDF (Syntax Definition Formalism).
    ASF is based on the notion of a module consisting of a signature defining
    the abstract syntax of functions and a set of conditional equations
    defining their semantics. Modules can be imported in other modules. SDF
    allows the simultaneous definition of concrete (i.e., lexical and
    context-free) and abstract syntax and implicitly defines a translation
    from text strings to abstract syntax trees. The main idea of ASF+SDF is to
    identify the abstract syntax defined by the signature in ASF
    specifications with the abstract syntax defined implicitly by an SDF
    specification, thus yielding a standard mapping from text to abstract
    syntax tree. This allows the association of semantics with (the tree
    representation of) text and introduces user-defined notation in
    specifications. ASF+SDF is therefore a modular specification formalism for
    the integrated definition of syntax and semantics of a (programming)
    language. Other views on ASF+SDF are: </para>

    <itemizedlist>
      <listitem>
        <para>a first-order functional programming language.</para>
      </listitem>

      <listitem>
        <para>an algebraic specification formalism.</para>
      </listitem>
    </itemizedlist>

    <para>Whatever viewpoint is taken, ASF+SDF is a powerful formalism for the
    declarative description of programming languages and meta programs.</para>

    <section>
      <title>EBNF and Lex+Yacc versus SDF</title>

      <para>EBNF-like and Lex+Yacc-like grammar formalisms are well-known.
      Although Lex+Yacc is more a domain specific language than a grammar
      formalism, the grammar of a lot of programming languages are presented
      as Lex_Yacc definition. There a number of differences between both
      EBNF-like and Lex_Yacc-like formalisms and SDF. We assume that the
      reader of this manual has some experience with formalisms like EBNF and
      Lex+Yacc. SDF allows a modular definition of your syntax formalism. This
      allows re-use of parts of other grammar definitions. This is only
      possible given the fact that the underlying parsing technology is based
      on Generalized LR parsing, see \cite{R92} and \cite{Vis97} for more
      details. SDF imposes no restrictions on the grammar. In contrast to
      \Lex+Yacc, restricted to the class of LALR(1)-grammars, we do not impose
      these restrictions. The fact that we do not impose these restrictions
      enables us to have this modular grammar definition formalism. Restricted
      classes, such as LALR(1), are not closed under union. Two grammars, both
      LALR(1) for instance, need not result in a LALR(1) grammar if they are
      combined. SDF does not produce only one parse tree (derivation) if there
      exist more derivations. The basic assumption of SDF is that
      <emphasis>all</emphasis> derivations will be produced and presented in a
      compact manner. This makes sure that <emphasis>no implicit
      disambiguation</emphasis> will take place at any time when you use SDF.
      To disambiguate, the user will apply declarative disambiguation
      constructs from SDF separately. Examples of disambiguations are
      l<emphasis>ongest-match</emphasis> and <emphasis>priorities</emphasis>.
      The most striking difference between SDF and EBNF-like and Lex+Yacc-like
      formalisms is the way the production rules are written in SDF. In EBNF
      and Lex+Yacc one writes production rules as<programlisting> P ::= 'b' D S 'e'</programlisting>whereas
      in SDF this is written as <programlisting>  "b" D S "e" -&gt; P</programlisting>So,
      the left- and right-hand side of the production rules are swapped. SDF
      provides an integrated definition of lexical and context-free syntax.
      EBNF does not provide, or only very restrictive, support for defining
      lexical syntax rules. In Lex+Yacc the lexical syntax is more or less
      defined in a separate formalism. SDF also allows an integrated way of
      defining <link linkend="priorities">associativity and priorities</link>
      between production rules. Finally, SDF provides an automatic way of
      constructing syntax trees. In Lex+Yacc the specification writer has to
      program how syntax trees are constructed.</para>
    </section>

    <section xml:id="Modules">
      <title>Modules and Modular Structure</title>

      <para>An ASF+SDF specification consists of a sequence of module
      declarations. Each module may define syntax rules as well as semantic
      rules and the notation used in the semantic rules depends on the
      definition of syntax rules. The entities declared in a module may be
      visible or invisible to other modules. A module can use another module
      from the specification by importing it. As a result, all visible names
      of the imported module become available in the importing module. The
      overall structure of a module is:<programlisting>module &lt;ModuleName&gt;
  &lt;ImportSection&gt;*
  &lt;ExportOrHiddenSection&gt;*

equations
  &lt;ConditionalEquation&gt;*</programlisting> A module consists of a module
      header, followed by a list of zero or more import sections, followed by
      zero or more hidden or export sections and an optional equations section
      that defines conditional equations. <link
      linkend="ParametersRenamings">Later</link> we will see that modules can
      alse be <emphasis>parameterized</emphasis> and that they can be
      <emphasis>renamed on import</emphasis>. Conceptually, a module is a
      single unit but for technical reasons the syntax sections and the
      equations section are stored in physically separate files. For each
      module <literal><replaceable>M</replaceable></literal> in a
      specification two files exist:
      <literal><replaceable>M</replaceable>.sdf</literal> contains the syntax
      sections of <replaceable>M</replaceable> and
      <replaceable>M</replaceable><literal>.asf</literal> contains the
      equations section of <replaceable>M</replaceable>. \index{compound
      module name@compound module name} </para>

      <para>A <literal>&lt;ModuleName&gt;</literal> is either a simple
      <literal>&lt;ModuleId&gt;</literal> or a
      <literal>&lt;ModuleId&gt;</literal> followed by zero or more parameter
      symbols, e.g., <literal>&lt;Module&gt;[&lt;Symbol&gt;*]</literal>, the
      symbols will be explained <link linkend="Symbols">later</link>. The
      <literal>&lt;ModuleId&gt;</literal> may be a compount module name, the
      <literal>ModuleId</literal> reflects the directory structure. For
      example <literal>basic/Booleans</literal> means that the module
      <literal>Booleans</literal> is found in the subdirectory
      <literal>basic</literal>. \index{exports section@{\tt exports} section}
      \index{hiddens section@{\tt hiddens} section}</para>

      <para> An <literal>&lt;ExportOrHiddenSection&gt;</literal> is either an
      <emphasis>export section</emphasis> or a <emphasis>hidden
      section</emphasis>. The former starts with the keyword
      <literal>exports</literal> and makes all entities in the section visible
      to other modules. The latter starts with the keyword
      <literal>hiddens</literal> and makes all entities in the section local
      to the module. An <literal>&lt;ExportOrHiddenSection&gt;</literal> has
      thus one of the two forms:<programlisting>exports 
  &lt;Grammar&gt;+</programlisting>or<programlisting>hiddens
  &lt;Grammar&gt;+
</programlisting> A <literal>&lt;Grammar&gt;</literal> can be a definition of
      one of the following: </para>

      <itemizedlist>
        <listitem>
          <para><link linkend="Imports">Imports</link>.</para>
        </listitem>

        <listitem>
          <para><link linkend="Aliases">Aliases</link>.</para>
        </listitem>

        <listitem>
          <para><link linkend="Sorts">Sorts</link>.</para>
        </listitem>

        <listitem>
          <para><link
          linkend="ContextFreeStartSymbols">Start-symbols</link>.</para>
        </listitem>

        <listitem>
          <para><link linkend="LexicalSyntax">Lexical syntax</link>.</para>
        </listitem>

        <listitem>
          <para><link linkend="ContextFreeSyntax">Context-free
          syntax</link>.</para>
        </listitem>

        <listitem>
          <para><link linkend="Priorities">Priorities</link>.</para>
        </listitem>

        <listitem>
          <para><link linkend="Variables">Variables</link>.</para>
        </listitem>
      </itemizedlist>

      <para>Note that it is possible to have hidden imports as well, this
      means that the contents of a hidden imported module in some module
      <replaceable>M</replaceable> is visible in <replaceable>M</replaceable>
      but is not exported to modules which import
      <replaceable>M</replaceable>. There are a number of related properties
      which have an effect across the various grammar items, these items are
      intermixed with the discussion of the grammars:</para>

      <itemizedlist>
        <listitem>
          <para><link linkend="Comments">SDF comment convention</link>.</para>
        </listitem>

        <listitem>
          <para><link linkend="Symbols">Symbols</link>.</para>
        </listitem>

        <listitem>
          <para><link linkend="Attributes">Attributes of Lexical and
          Context-free Functions</link>.</para>
        </listitem>

        <listitem>
          <para> <link linkend="Disambiguation">Disambiguation</link>.</para>
        </listitem>

        <listitem>
          <para> <link linkend="ParametersRenamings">Parameterization and
          Renamings</link>.</para>
        </listitem>

        <listitem>
          <para><link linkend="Libraries">Libraries</link>.</para>
        </listitem>

        <listitem>
          <para><link linkend="Equations">Equations</link>.</para>
        </listitem>
      </itemizedlist>

      <para>Each of these entities and properties will now be described and
      illustrated by examples.</para>
    </section>

    <section xml:id="SdfComment">
      <title>SDF comment convention</title>

      <para>\index{Sdf comment@\sdf\ comment} </para>

      <para>The comment convention within an SDF specification is that
      characters between <literal>%%</literal> and the end of line is comment
      as well as every character between two <literal>%</literal> characeters
      including the newline character. An example of the use of comments is
      given <link linkend="CODE_sdfcomment">below</link>. This definition also
      defines the comment convention in SDF itself. More details on defining
      layout can be found in the section <link
      linkend="Restrictions">Restrictions</link>.</para>

      <example xml:id="CODE_sdfcomments">
        <title>SDF comments</title>

        <para><programlisting xml:id="CODE_sdfcomment">module basic/Comments

imports basic/Whitespace

%% In this module we define the 
%% comment convention for SDF.

exports
  lexical syntax
    "%%" ~[\n]* "\n" -&gt; LAYOUT
    "%" ~[\%]+ "%" -&gt; LAYOUT

  context-free restrictions
    LAYOUT? -/- [\%]</programlisting></para>
      </example>
    </section>

    <section xml:id="Imports">
      <title>Imports</title>

      <para> \index{imports@{\tt imports}} \index{{\tt
      &lt;ImportSection&gt;}@{\tt &lt;ImportSection&gt;} Each
      <literal>&lt;ImportSection&gt;</literal> starts with the keyword
      <literal>imports</literal> followed by zero or more module names:
      <programlisting>imports
  &lt;ModuleName&gt;*
</programlisting>Modules can be combined by importing one module in another.
      Imports can occur as <literal>&lt;ImportSection&gt;</literal> at the
      topmost level of a module or they can occur within an exports or hiddens
      section. When importing modules at the topmost level of a module or when
      the import section occurs within the scope of an exports keyword, all
      exported entities of the imported module (and of all modules that are
      imported indirectly by it) become available in the importing module. In
      addition, they are also exported by the importing module. However, if
      the import section occurs within the scope of a hiddens keyword, the
      exported entities are only visible in the importing module but they are
      not exported by the importing module. An imported module can be
      parameterized or decorated with <link
      linkend="Renamings">renamings</link>. The name of the imported module
      can also be a compound module name. In \link*{the definition of the SDF
      comments}[Figure~\Ref]{CODE:sdfcomment} the imported module {\tt
      basic/Whitespace} is an example of such a compound module name.</para>
    </section>

    <section xml:id="Symbols">
      <title>Symbols</title>

      <para>The elementary building block of SDF syntax rules is the symbol.
      It is comparable to terminals and non-terminals in other grammar
      definition formalisms. The elementary symbols are:</para>

      <itemizedlist>
        <listitem>
          <para><emphasis>sort</emphasis>: corresponds to a non-terminal,
          e.g., <literal>Bool</literal>. Sort names always start with a
          capital letter and may be followed by letters and/or digits. Hyphens
          (<literal>-</literal>) may be embedded in a sort name.</para>
        </listitem>

        <listitem>
          <para><emphasis>literal</emphasis>: corresponds to a terminal, e.g.,
          <literal>"true"</literal> or <literal>"\&amp;"</literal>. Terminals
          must always be quoted, also the terminals consisting of only
          letters. </para>
        </listitem>

        <listitem>
          <para><emphasis>character class</emphasis>: corresponds to a set of
          characters, e.g., <literal>[a-z]</literal>. Character classes will
          be explained in the section <link
          linkend="CharacterClasses">Character Classes</link>, they are mainly
          used when describing the lexical syntax of a language.</para>
        </listitem>
      </itemizedlist>

      <para> Starting with the elementary symbols, more complex symbols can be
      constructed by way of the following operators. Examples of the use of
      the various operators will be given in the sections <link
      linkend="LexicalSyntax">Lexical Syntax</link> and <link
      linkend="ContextFreeSyntax">Context-free Syntax</link>.</para>

      <section xml:id="OptionOperator">
        <title>Option</title>

        <para>\index{option operator@option operator} \index{{\tt ?}@{\tt
        ?}}</para>

        <para> The postfix option operator <literal>?</literal> describes an
        optional part in a syntax rule. For instance,
        <literal>ElsePart?</literal> defines zero or exactly one occurrence of
        <literal>ElsePart</literal>.</para>
      </section>

      <section xml:id="SequenceOperator">
        <title>Sequence</title>

        <para>\index{sequence operator@sequence operator} \index{{\tt
        (...)}@{\tt (...)}}</para>

        <para> The sequence operator <literal>(...)</literal> describes the
        grouping of two or more symbols, e.g., <literal>(Bool
        "\&amp;")</literal>. Sequences are mostly used to group symbols
        together to form a more complex symbol using one of the available
        operators, e.g., <literal>(Bool "\&amp;")*</literal>. It has no effect
        to construct a sequence consisting of a single symbol. The empty
        sequence is represented as <literal>()</literal>.</para>
      </section>

      <section xml:id="RepetitionOperator">
        <title>Repetition</title>

        <para> \index{repetition operator@repetition operator}
        \index{list@list} \index{{\tt *}@{\tt *}} \index{{\tt +}@{\tt
        +}}</para>

        <para> Repetition operators express that a symbol should occur several
        times. In this way it is possible to construct flat lists and
        therefore we usually refer to repetitions as \emph{lists}. Repetition
        operators come in two flavors, with and without separators.
        Furthermore, it is possible to express the minimal number of
        repetitions of the symbol: at least zero times (<literal>*</literal>)
        or at least one time (<literal>+</literal>). Examples are:</para>

        <itemizedlist>
          <listitem>
            <para><literal>Bool*</literal> (a list of zero or more {\tt
            Bool}s).</para>
          </listitem>

          <listitem>
            <para><literal>{Bool ","\}+</literal> (a list of one or more
            <literal>Bool</literal>s separated by comma's).</para>
          </listitem>
        </itemizedlist>

        <para> In case of a separated list the element can be an arbitrary
        symbol, but the separator can only be a plain literal. It is possible
        to write, for instance <literal>{Int Bool\}*</literal> or
        <literal>{Int (","|";")}*</literal>, but the <link
        linkend="SEC_SDF-checker">asfsdf-checker</link> will produce a warning
        indicating that this type of symbol is not supported. Neither the
        <link linkend="SEC_interpretationofterms">interpreter</link> nor the
        <link linkend="SEC_reducingofterms">compiler</link>} support this type
        of separated lists.</para>
      </section>

      <section xml:id="AlternativeOperator">
        <title>Alternative</title>

        <para> \index{alternative operator@alternative operator} \index{{\tt
        |}@{\tt |}</para>

        <para> The alternative operator <literal>|</literal> expresses the
        choice between two symbols, e.g., <literal>"true" | "false"</literal>
        represents that either a <literal>"true"</literal> symbol or a
        <literal>"false"</literal> symbol may occur here. The alternative
        operator is right associative and binds stronger than any other
        operator on symbols. This is important because <literal>Bool "," |
        Bool ";" </literal>expresses <literal>Bool ("," | Bool) ";"</literal>
        instead of <literal>(Bool ",") | (Bool ";").</literal> So, in case of
        doubt use the sequence operator in combination with the alternative
        operator.</para>
      </section>

      <section xml:id="TupleOperator">
        <title>Tuple</title>

        <para> \index{tuple operator@tuple operator}</para>

        <para> The tuple operator describes the grouping of a sequence of
        symbols of a fixed length into a tuple. The notation for tuples is
        <literal>&lt; , , &gt;</literal>, i.e., a comma-separated list of
        elements enclosed in angle brackets. For example, <literal>&lt;Bool,
        Int, Id&gt;</literal> describes a tuple with three elements consisting
        of a <literal>Bool</literal>, an <literal>Int</literal> and an
        <literal>Id</literal> (in that order). For instance,
        <literal>&lt;true, 3, x&gt;</literal> is a valid example of such a
        tuple.</para>
      </section>

      <section xml:id="FunctionOperator">
        <title>Function</title>

        <para>\index{function operator@function operator} \index{{\tt
        (...=&gt;...)}@{\tt (...=&gt;...)}}</para>

        <para> The function operator <literal>(...=&gt;...)</literal> allows
        the definition of function types. Left of <literal>=&gt;</literal>
        zero or more symbols may occur, right of <literal>=&gt;</literal>
        exactly one symbol may occur. For example, <literal>(Bool Int) =&gt;
        Int</literal> represents a function with two argument (of types
        <literal>Bool</literal> and <literal>Int</literal>, respectively) and
        a result type <literal>Int</literal>.</para>
      </section>

      <section xml:id="ParameterizedSorts">
        <title>Parameterized Sorts</title>

        <para>\index{parameterized sort@parameterized sort} \index{{\tt
        ...[[...]]}@{\tt ...[[...]]}}</para>

        <para> Sort names can have parameters. This provides a way of
        distinguishing a generic sort <literal>List</literal> from a list for
        integers, e.g. <literal>List[[Int]]</literal>, or one for booleans,
        e.g. <literal>List[[Bool]]</literal>. These sort parameters can be
        instantiated via the parameters of the module name. A parameterized
        sort may have the form <literal>List[[X,Y]]</literal> where
        <literal>X</literal> and <literal>Y</literal> are generic sorts which
        will be provided via the parameters of the module name. See P<link
        linkend="ParametersRenamings">arameterization and Renamings</link>}
        for more details. The context-free syntax rule describing
        parameterized sorts is: <programlisting> Sort "[[" {Symbol ","}+ "]]" -&gt; Symbol</programlisting></para>
      </section>

      <section xml:id="LiftingOperator">
        <title>Lifted Sorts</title>

        <para>\index{lifting operator@lifting operator} \index{{\tt
        `...`}@{\tt `...`}}</para>

        <para> The lifting operator <literal>`...`</literal> translates the
        name of an arbitrary complex symbol to a literal syntax definition of
        that name. It makes a symbol a part of the defined syntax. An example:
        <literal>`X?`</literal> defines the syntax <literal>("X"
        "?")</literal>. The lifting operator is typically used in combination
        with parameterized modules, and specifically for applications of SDF
        that implement concrete syntax.</para>
      </section>
    </section>

    <section xml:id="Aliases">
      <title>Aliases</title>

      <para>In ordinary programming it is good practice to use named constants
      to represent literals or constant values. In SDF it is good practice to
      give a name (alias') to complicated symbols that occur repeatedly in the
      specification. An alias is thus a named abbreviation for a complicated
      symbol. For example,<programlisting>aliases
  &lt;Bool, Int, Id&gt; -&gt; Tuple3</programlisting>introduces the alias
      Tuple3 for the symbol <literal>&lt;Bool, Int, Id&gt;</literal> and
      instead of using <literal>&lt;Bool, Int, Id&gt;</literal> one can use
      the alias <literal>Tuple3</literal>. During parse table generation the
      alias is replaced by the actual symbol. It is not allowed to give an
      alias for an alias or to redefine aliases. For example, the following
      definitions are illegal:<programlisting>aliases
  Tuple3          -&gt; SuperTuple
  &lt;Bool, Int, Id&gt; -&gt; Tuple3</programlisting>(Illegal, since an alias
      is defined for the alias {\tt Tuple3}.)<programlisting>aliases
  &lt;Bool, Int, Id&gt; -&gt; Tuple3
  &lt;Bool, Int&gt;     -&gt; Tuple3</programlisting>(Illegal, since the alias
      <literal>Tuple3</literal> is redefined.) Note, the aliases are a
      convenient short hand for more complex symbols, but a drawback is that
      during parse table generation the aliases completely disappear. They are
      replaced by the actual symbols. This can have some unexpected behaviour
      when parsing or reducing terms.</para>
    </section>

    <section xml:id="Sorts">
      <title>Sorts</title>

      <para>Sorts are declared by listing their name in a sorts section of the
      form:<programlisting>sorts
  &lt;Symbol&gt;*
</programlisting>Only plain <literal>Sort</literal>s and parameterized
      <literal>Sort</literal>s can be declared in the <literal>sorts</literal>
      section, but more complex <literal>Symbol</literal>s will be
      syntactically recognized, but the <link
      linkend="SEC_SDFchecker">asfsdf-checker</link> will generate a warning.
      It is required that all sorts that occur in some symbol in the
      specification are declared. Recall that a sort name should start with a
      capital letter and may be followed by letters and/or digits. Hyphens
      (<literal>-</literal>) may be embedded in sort names. There is one
      predefined sort name <literal>LAYOUT</literal>. It is described in <link
      linkend="LexicalSyntax">Lexical Syntax</link>. It is not allowed (or
      necessary) to define the sorts <literal>LAYOUT</literal> and
      <literal>CHAR</literal>. These two sorts are always available.</para>
    </section>

    <section xml:id="SEC_ContextFreeStartSymbols">
      <title>Context-free start-symbols</title>

      <para>Via the context-free start symbols section the symbols are
      explicitly defined which will serve as start symbols when parsing terms.
      If no start symbols are defined it is not possible to recognize terms.
      This has the effect that input sentences corresponding to these symbols
      can be parsed. So, if we want to recognize booleans terms we have to
      define explicitly the sort <literal>Boolean</literal> as a start symbol
      in the module <literal>Booleans</literal>. Any symbol, also lists,
      tuples, etc., can serve as a start-symbol.<programlisting>context-free start-symbols
  &lt;Symbol&gt;*</programlisting>Context-free start-symbol sections can
      either be hidden or exported. The effect of defined symbols as start
      symbols for the grammar may lead to an explosion of start states for the
      parser and thus lead to performance loss. To prevent this it can be
      advisable to hide start-symbol sections. The symbols defined are only
      visible in the module containing this hidden start-symbols section, but
      not in modules importing this module.</para>
    </section>

    <section xml:id="LexicalSyntax">
      <title>Lexical Syntax</title>

      <para>The lexical syntax describes the low level structure of text by
      means of <emphasis>lexical tokens</emphasis>. A lexical token consists
      of a sort name (used to distinguish classes of tokens like identifiers
      and numbers), and the actual text of the token. The lexical syntax also
      defines which substrings of the text are layout symbols or comments and
      are to be skipped. A lexical syntax contains a set of declarations for
      <emphasis>lexical functions</emphasis>, each consisting of a regular
      expression and a result sort. All functions with the same result sort
      together define the lexical syntax of tokens of that sort. Regular
      expressions may contain any basic symbol and any symbol operator as
      described in the section <link linkend="???">Symbols</link>. Spaces are
      only significant inside strings and character classes. The sort name
      <literal>LAYOUT</literal> is predefined and may not be redeclared.
      <literal>LAYOUT</literal> defines which parts of the text are
      <emphasis>layout symbols</emphasis> (also known as <emphasis>white
      space</emphasis>) between lexical tokens and are to be skipped during
      lexical analysis. It may only be used as result sort of <link
      linkend="LexicalFunctions">lexical functions</link>. When a string is
      matched by both a <literal>LAYOUT</literal> function and by other
      non-<literal>LAYOUT</literal> functions, then the interpretation as
      layout symbol is ignored. <literal>LAYOUT</literal> is typically used
      for defining layout and comment conventions. Traditionally, lexical
      syntax and context-free syntax are treated differently. They are defined
      by different notations and implemented by means of different techniques.
      SDF provides a much more uniform treatment. In SDF the only significant
      difference between the two is that no layout will be accepted while
      recognizing the members of the left-hand side of a lexical function,
      whereas layout <emphasis>will</emphasis> be accepted between the members
      of the left-hand side of a context-free function. At the implementation
      level, both are implemented using a single parsing technique.
      Technically, there exist only <emphasis>syntax</emphasis> sections. Both
      lexical syntax sections and context-free syntax sections are transformed
      into such syntax sections after appropriate insertion of optional layout
      between the elements of context-free functions. In rare cases, the
      specification writer may want to control this process explicitly and
      write syntax sections directly. This will not be discussed in this
      manual, but further details can be found in \cite{Vis97}.</para>

      <section xml:id="LexicalFunctions">
        <title>Lexical Functions</title>

        <para>In their simplest form, declarations of lexical functions
        consist of a sequence of zero or more symbols followed by
        <literal>-&gt;</literal> and a result symbol, say
        <replaceable>L</replaceable>. A lexical function may be followed by a
        list of attributes. The regular expression associated with
        <replaceable>L</replaceable> consists of the logical
        <emphasis>or</emphasis> of all left-hand sides of lexical functions
        with result sort <replaceable>L</replaceable>. All sort names
        appearing in left-hand sides of declarations are replaced by the
        regular expression associated with them.</para>

        <para><remark>%%Circular dependencies between declarations in the
        lexical syntax are %%forbidden.\footnote{Does this limitation still
        apply?} </remark> <link linkend="CODE_simplelex">Below</link> we give
        an example of a simple lexical function definition for defining the
        first three words that Dutch children learn to read. The three sorts
        <literal>Aap</literal>, <literal>Noot</literal> and
        <literal>Mies</literal>, each recognize, respectively, the strings
        <literal>aap</literal>, <literal>noot</literal> and
        <literal>mies</literal>. The sort <literal>LeesPlank</literal> (a
        reading-desk used in primary education) recognizes the single string
        <literal>aapnootmies</literal>.</para>

        <example>
          <title>Simple lexical functions</title>

          <para><programlisting>module LeesPlank

imports basic/Whitespace

exports
  context-free start-symbols LeesPlank
  sorts Aap Noot Mies LeesPlank
  lexical syntax
    "aap"         -&gt; Aap
    "noot"        -&gt; Noot
    "mies"        -&gt; Mies
    Aap Noot Mies -&gt; LeesPlank</programlisting></para>
        </example>

        <para>For each production in a lexical syntax section, a
        <emphasis>lexical constructor function is automatically
        added</emphasis>. Lexical constructor functions are used to construct
        and deconstruct lexical syntax using patterns. For each production
        <literal>A B C -&gt; D</literal> in a lexical syntax section, the
        generated constructor function is of the form: <literal>d "(" A B C
        ")" -&gt; D</literal>. Here, <literal>d</literal> is the name of the
        sort <literal>D</literal> written in lowercase letters only. The
        lexical constructor functions will be discussed in more detail in the
        section on <link linkend="Equations">Equations</link>. They are
        considerably different from previous versions, when ASF+SDF had
        <emphasis>flat lexical constructors</emphasis>. Since version 2.0
        <emphasis>fully structured lexical constructors</emphasis> are
        supported.</para>
      </section>

      <section xml:id="CharacterClasses">
        <title>Character Classes</title>

        <para>Enumerations of characters occur frequently in lexical
        definitions. They can be abbreviated by using character classes
        enclosed by <literal>[</literal> and <literal>]</literal>. A character
        class contains a list of zero or more characters (which stand for
        themselves) or character ranges such as, for instance,
        <literal>[0-9]</literal> as an abbreviation for the characters
        <literal>0</literal>, <literal>1</literal>, ..., <literal>9</literal>.
        In a character range of the form
        c<subscript>1</subscript><literal>-</literal>c<subscript>2</subscript>
        one of the following restrictions should apply:</para>

        <itemizedlist>
          <listitem>
            <para>c<subscript>1</subscript> and c<subscript>2</subscript> are
            both lower-case letters and c<subscript>2</subscript> follows
            c<subscript>1</subscript> in the alphabet, or </para>
          </listitem>
        </itemizedlist>

        <itemizedlist>
          <listitem>
            <para>c<subscript>1</subscript> and c<subscript>2</subscript> are
            both upper-case letters and c<subscript>2</subscript> follows
            c<subscript>1</subscript> in the alphabet, or </para>
          </listitem>
        </itemizedlist>

        <itemizedlist>
          <listitem>
            <para>c<subscript>1</subscript> and c<subscript>2</subscript> are
            both digits and the numeric value of c<subscript>2</subscript> is
            greater than that of c<subscript>1</subscript>, or </para>
          </listitem>
        </itemizedlist>

        <itemizedlist>
          <listitem>
            <para>c<subscript>1</subscript> and c<subscript>2</subscript> are
            both escaped non-printable characters and the character code of
            c<subscript>2</subscript> is greater than that of
            c<subscript>1</subscript>.</para>
          </listitem>
        </itemizedlist>

        <para>Definitions for lower-case letter (<literal>LCLetter</literal>),
        upper-case letters (<literal>UCLetter</literal>), lower-case and
        upper-case letters (<literal>Letter</literal>) and digits
        (<literal>Digit</literal>) are shown in the first example <link
        linkend="CODE_LettersDigits1">below</link>}. </para>

        <example xml:id="CODE_LettersDigits1">
          <title>Defining letter (lower-case and upper-case) and digit</title>

          <para><programlisting>module LettersDigits1

imports basic/Whitespace

exports
  context-free start-symbols Letter Digit
  sorts LCLetter UCLetter Letter Digit
  lexical syntax
    [a-z]    -&gt; LCLetter
    [A-Z]    -&gt; UCLetter
    [a-zA-Z] -&gt; Letter
    [0-9]    -&gt; Digit</programlisting></para>
        </example>

        <para>The <link linkend="CODE_LettersDigits2">next example</link>
        gives a definition of the sort <literal>LetterOrDigit</literal> that
        recognizes a single letter (upper-case or lower-case) or digit.</para>

        <example xml:id="CODE_LettersDigits2">
          <title>Defining a single letter or digit</title>

          <programlisting>module LettersDigits2
imports basic/Whitespace

exports
  context-free start-symbols LetterOrDigit
  sorts LetterOrDigit
  lexical syntax
    [a-z]    -&gt; LetterOrDigit
    [A-Z]    -&gt; LetterOrDigit
    [0-9]    -&gt; LetterOrDigit</programlisting>
        </example>

        <para><emphasis role="bold">Escape Conventions</emphasis> Characters
        with a special meaning in ASF+SDF may cause problems when they are
        needed as ordinary characters in the lexical syntax. The backslash
        character (<literal>\</literal>) is used as escape character for the
        quoting of special characters. You should use
        <literal>\</literal><replaceable>c</replaceable> whenever you need
        special character <replaceable>c</replaceable> as ordinary character
        in a definition. All individual characters in character classes,
        except digits and letters, are <emphasis>always</emphasis> escaped
        with a backslash. In literal strings, the following characters are
        special and should be escaped:</para>

        <itemizedlist>
          <listitem>
            <para><literal>"</literal>: double quote </para>
          </listitem>

          <listitem>
            <para><literal>\</literal>: escape character.</para>
          </listitem>
        </itemizedlist>

        <para>You may use the following abbreviations in literals and in
        character classes:</para>

        <itemizedlist>
          <listitem>
            <para><literal>\n</literal>: newline character </para>
          </listitem>

          <listitem>
            <para><literal>\r</literal>: carriage return</para>
          </listitem>

          <listitem>
            <para><literal>\t</literal>: horizontal tabulation </para>
          </listitem>

          <listitem>
            <para><literal>\</literal><replaceable>x</replaceable>: a
            non-printable character with the decimal code
            <replaceable>x</replaceable>.</para>
          </listitem>
        </itemizedlist>

        <para><emphasis role="bold">Character Class Operators</emphasis> The
        following operators are available for character classes:</para>

        <itemizedlist>
          <listitem>
            <para><literal>~</literal>: complement of character class. Accepts
            all characters not in the original class.</para>
          </listitem>

          <listitem>
            <para><literal>/</literal>: difference of two character classes.
            Accepts all characters in the first class unless they are in the
            second class.</para>
          </listitem>

          <listitem>
            <para><literal>/\</literal>: intersection of two character
            classes. Accepts all characters that are accepted by both
            character classes.</para>
          </listitem>

          <listitem>
            <para> <literal>\/</literal>: union of two character classes.
            Accepts all characters that are accepted by either character
            class.</para>
          </listitem>
        </itemizedlist>

        <para>The first operator is a unary operator, whereas the other three
        are left-associative binary operators. The example \link*{below}[ in
        Figure~\Ref ]{CODE:LettersDigits3} gives the definion of a single
        letter or digit using the alternative operator {\tt \verb+\+/}. This
        definition is equivalent to the one given \link{earlier}[ in
        Figure~\Ref]{CODE:LettersDigits2}.</para>

        <para></para>

        <example xml:id="CODE_LettersDigits3">
          <title>Defining a single letter or digit using the alternative
          operator</title>

          <para><programlisting>module LettersDigits3
exports
  context-free start-symbols LetterOrDigit
  sorts LetterOrDigit
  lexical syntax
    [a-z] \/ [A-Z] \/ [0-9]   -&gt; LetterOrDigit</programlisting></para>
        </example>

        <para>Another example is shown <link
        linkend="CODE_charclasses">below</link>. This definition of characters
        contains all possible characters, either by means of the ordinary
        representation or via their decimal representation.</para>

        <example xml:id="CODE_charclasses">
          <title>Example of character classes</title>

          <para><programlisting>module Characters

imports basic/Whitespace

exports
  context-free start-symbols L-Char
  sorts AlphaNumericalEscChar DecimalEscChar EscChar L-Char
  lexical syntax
    "\\" ~[]                 -&gt; AlphaNumericalEscChar

    "\\" [01] [0-9] [0-9]    -&gt; DecimalEscChar
    "\\" "2" [0-4] [0-9]     -&gt; DecimalEscChar
    "\\" "2" "5" [0-5]       -&gt; DecimalEscChar

    AlphaNumericalEscChar    -&gt; EscChar
    DecimalEscChar           -&gt; EscChar

    ~[\0-\31\"\\] \/ [\t\n]  -&gt; L-Char
    EscChar                  -&gt; L-Char</programlisting></para>
        </example>
      </section>

      <section xml:id="Repetition">
        <title>Repetition</title>

        <para>\index{repetition operator@repetition operator}</para>

        <para> Lexical tokens are often described by patterns that exhibit a
        certain repetition. The operator described in \link*{Repetition}[
        Section~\Ref]{RepetitionOperator} can be used to express repetitions.
        The example <link linkend="CODE_repetition">below</link> demonstrates
        the use of the repetition operator {\tt *} for defining identifiers
        consisting of a letter followed by zero or more letters or
        digits.</para>

        <example xml:id="CODE_repetition">
          <title>Defining identifiers using the repetition operator
          <literal>*</literal></title>

          <para><programlisting>module Identifiers-repetition

imports basic/Whitespace

exports
  context-free start-symbols Id
  sorts Letter DigitLetter Id
  lexical syntax
    [a-z]       -&gt; Letter
    [a-z0-9]    -&gt; DigitLetter

    Letter DigitLetter* -&gt; Id</programlisting></para>
        </example>
      </section>

      <section>
        <title>Option</title>

        <para>\index{option operator@option operator}</para>

        <para> If zero or exactly one occurrence of a lexical token is desired
        the option operator described in \link*{Option}[
        Section~\Ref]{OptionOperator} can be used. The use of the option
        operator is illustrated <link linkend="CODE_option">below</link>.
        Identifiers are defined consisting of one letter followed by one,
        optional, digit. This definition accepts <literal>a</literal> and
        <literal>z8</literal>, but rejects <literal>ab</literal> or
        <literal>z789</literal>.</para>

        <example xml:id="CODE_option">
          <title>Defining a letter followed by an optional number using the
          option operator <literal>?</literal></title>

          <para><programlisting>module Identifiers-optional

imports basic/Whitespace

exports
  context-free start-symbols Id
  sorts Letter Digit Id
  lexical syntax
    [a-z]  -&gt; Letter
    [0-9]  -&gt; Digit

    Letter Digit? -&gt; Id </programlisting></para>
        </example>
      </section>

      <section>
        <title>Alternative</title>

        <para>\index{alternative operator@alternative operator}</para>

        <para> Functions with the same result sort together define the lexical
        syntax of tokens for that sort. The left-hand sides of these function
        definitions form the alternatives for this function. Sometimes, it is
        more convenient to list these alternatives explicitly in a single
        left-hand side or to list alternative parts inside a left-hand side.
        This is precisely the role of the <link
        linkend="AlternativeOperator">alternative operator</link>. The example
        <link linkend="CODE_alternative1">below</link> shows how this operator
        can be used. It describes identifiers starting with an upper-case
        letter followed by one of the following:</para>

        <itemizedlist>
          <listitem>
            <para>zero or more lower-case letters, </para>
          </listitem>

          <listitem>
            <para>zero or more upper-case letters, or</para>
          </listitem>

          <listitem>
            <para>zero or more digits.</para>
          </listitem>
        </itemizedlist>

        <para>According to this definition, <literal>Aap</literal>,
        <literal>NOOT</literal>, and <literal>B49</literal> are acceptable,
        but <literal>MiES</literal>, <literal>B49a</literal> and
        <literal>007</literal> are not.</para>

        <example xml:id="CODE_alternative1">
          <title>Example of alternative operator <literal>|</literal></title>

          <para><programlisting>module Identifiers-alternative1

imports basic/Whitespace

exports
  context-free start-symbols Id
  sorts LCLetter UCLetter Digit Id
  lexical syntax
    [A-Z]   -&gt; UCLetter
    [a-z]   -&gt; LCLetter
    [0-9]   -&gt; Digit

  UCLetter LCLetter* | UCLetter* | Digit* -&gt; Id</programlisting></para>
        </example>

        <para>Note that the relation between juxtaposition and alternative
        operator is best understood by looking at the line defining {\tt Id}.
        A parenthesized version of this same line would read as
        follows:<programlisting> UCLetter (LCLetter* | UCLetter* | Digit*) -&gt; Id</programlisting>As
        an aside, note that moving the <literal>*</literal> outside the
        parentheses as in <programlisting> UCLetter (LCLetter | UCLetter | Digit)* -&gt; Id</programlisting>yields
        a completely different definition: it describes identifiers starting
        with an uppercase letter followed by zero or more lower-case letters,
        uppercase letters or digits. According to this definition
        <literal>MiES</literal>, <literal>B49a</literal> and
        <literal>Bond007</literal> would, for instance, be acceptable. A
        slightly more readable definition that is equivalent to the <link
        linkend="CODE_alternative1">previous one</link> is shown <link
        linkend="CODE_alternative2">below</link>. In any case, we recommend to
        use parentheses to make the scope of alternatives explicit.</para>

        <example xml:id="CODE_alternative2">
          <title>Example of alternative operator <literal>|</literal></title>

          <para><programlisting>module Identifiers-alternative2

imports basic/Whitespace

exports
  context-free start-symbols Id
  sorts UCLetter LCLetter Digit Id
  lexical syntax
    [A-Z]   -&gt; UCLetter
    [a-z]   -&gt; LCLetter
    [0-9]   -&gt; Digit

    (UCLetter LCLetter*) | (UCLetter UCLetter*) | (UCLetter Digit*) -&gt; Id</programlisting></para>
        </example>
      </section>

      <section>
        <title>Miscellaneous Operators</title>

        <para>The other operators described in the section <link
        linkend="Symbols">Symbols</link> are less frequently used within
        lexical syntax definitions and will not be illustrated by means of an
        example.</para>
      </section>

      <section>
        <title>Examples of Lexical Definitions</title>

        <para>We will present a number of non-trivial lexical syntax
        definitions in order to get some ideas what can be specified using
        SDF. <emphasis role="bold">Defining Numbers</emphasis> Definitions of
        integers and real numbers are shown <link
        linkend="CODE_numbers">below</link>. Note the use of the alternative
        operator in the definitions of <literal>UnsignedInt</literal> and
        <literal>Number</literal>. Also note the use of the option operator in
        the definitions of <literal>SignedInt</literal> and
        <literal>UnsignedReal</literal>.</para>

        <example xml:id="CODE_numbers">
          <title>Lexical definition of Numbers</title>

          <para><programlisting>module Numbers

imports basic/Whitespace

exports
  context-free start-symbols Number
  sorts UnsignedInt SignedInt UnsignedReal Number 

  lexical syntax
    [0] | ([1-9][0-9]*)                           -&gt; UnsignedInt

    [\+\-]? UnsignedInt                           -&gt; SignedInt

    UnsignedInt "." UnsignedInt ([eE] SignedInt)? -&gt; UnsignedReal 
    UnsignedInt [eE] SignedInt                    -&gt; UnsignedReal

    UnsignedInt | UnsignedReal                    -&gt; Number  </programlisting></para>
        </example>

        <para><emphasis role="bold">Defining Strings</emphasis> The
        specification <link linkend="CODE_string">below</link>, gives the
        lexical definition of strings which may contain escaped double quote
        characters. It defines a <literal>StringChar</literal> as
        either</para>

        <itemizedlist>
          <listitem>
            <para>zero or more arbitrary characters except double quote or
            newline, or</para>
          </listitem>

          <listitem>
            <para>an escaped double quote, i.e., <literal>\"</literal>.</para>
          </listitem>
        </itemizedlist>

        <para>A string consists of zero or more <literal>StringChar</literal>s
        surrounded by double quotes.</para>

        <example xml:id="CODE_string">
          <title>Lexical definition of String</title>

          <para><programlisting>module Strings

imports basic/Whitespace

exports
  context-free start-symbols String
  sorts String StringChar

  lexical syntax
    ~[\"\n]               -&gt; StringChar
    [\\][\"]              -&gt; StringChar
    "\"" StringChar* "\"" -&gt; String</programlisting></para>
        </example>
      </section>
    </section>
  </section>

  <!--

\subsection{Context-free Syntax}
\label{ContexFreeSyntax}

The context-free syntax describes the concrete and abstract syntactic
structure of sentences in a language. A context-free syntax contains a set of
declarations for \emph{context-free functions}, each consisting of zero or
more symbols followed by `$\rightarrow$' and a result symbol.  They may be
followed by attributes that control how parentheses and brackets affect the
abstract syntax, by attributes that define the associativity of a rule, or by
\link{attributes}[ (Section~\Ref)]{Attributes} which influence the rewriting
process.  All functions with the same result sort together define the
alternatives for that symbol.

Elements of the left-hand side of a context-free function
are separated by an invisible non-terminal {\tt LAYOUT?} 
(optional {\tt LAYOUT}) in order to permit layout between these members.
This optional layout non-terminal is automatically inserted.

\subsubsection{Context-free Functions}

In their simplest form, declarations of context-free functions consist of a
sequence of zero or more symbols followed by `$\rightarrow$'
and a result symbol. All literal strings appearing in a context-free
function declaration are implicitly added to the lexical syntax. Consider the
language of coordinates and drawing commands presented
\link*{below}[in Figure~\Ref]{CODE:simple-cf}.

\begin{figure}
\begin{Label}{CODE:simple-cf}
\begin{IncCode}
\begin{verbatim}
module DrawingCommands

imports basic/Whitespace

exports
  context-free start-symbols CMND 
  sorts NAT COORD CMND 

  lexical syntax
    [0-9]+ -> NAT 

  context-free syntax
    "(" NAT "," NAT ")" -> COORD
    "line" "to" COORD   -> CMND 
    "move" "to" COORD   -> CMND
\end{verbatim}
\end{IncCode}
\caption{Simple context-free syntax definition}
\end{Label}
\end{figure}   


An equivalent conventional BNF grammar (and not considering lexical syntax) 
of the \link{above grammar}[ of Figure~\Ref]{CODE:simple-cf} is
\T presented in Figure \ref{CODE:simple-bnf}.
\W \link{as follows}[]{CODE:simple-bnf}.

\begin{figure}
\begin{Label}{CODE:simple-bnf}
\begin{IncCode}
\begin{verbatim}
<COORD> ::= "(" <NAT> "," <NAT> ")" 
<CMND>  ::= "line" "to" <COORD> | "move" "to" <COORD>
\end{verbatim}
\end{IncCode}
\caption{BNF definition of simple grammar}
\end{Label}
\end{figure}   

When a literal in a context-free function consists only of lower-case letters
and digits and is not a keyword of \asfsdf, it need not be surrounded by
quotes. You may therefore write `{\tt move to COORD -> CMND}' instead of the
\link{previous definition}[ given in Figure~\Ref]{CODE:simple-cf}. But is 
better to always write the quotes.

\subsubsection{Prefix Functions}
\label{PrefixFunctions}

Prefix functions are a special kind of context-free functions. They have
a ``fix'' syntax. They can be considered as an abbreviation mechanism for
functions written as expected. For instance the function {\tt f(X,Y) -> Z}
is a prefix function. This function can also be defined as an ordinary
context-free function {\tt "f" "(" X "," Y ")" -> Z}. The prefix functions
are often used in combination with ASF equations.

\subsubsection{Lists}

Context-free syntax often requires the description of
the repetition of a syntactic notion or of list structures (with or without
separators) containing a syntactic notion. The 
\link{repetition operator}[ described in Section~\Ref]{RepetitionOperator}
can be used for this purpose.

Lists may be used in both the left-hand side and right-hand side of a
context-free function as well as in the right-hand side of a 
\link{variable declaration}[ (see Section~\Ref)]{Variables}.

\T Figure \ref{CODE:pascal-ids} shows 
\W \link{Below}[]{CODE:pascal-ids} an example is given of
how lists can be used to define 
the syntax of a list of identifiers (occurring in a declaration
in a Pascal-like language).

\begin{figure}
\begin{Label}{CODE:pascal-ids}
\begin{IncCode}
\begin{verbatim}
module Decls

imports basic/Whitespace

exports
  context-free start-symbols Decl
  sorts Id Decl Type 

  lexical syntax
    [a-z]+ -> Id 

  context-free syntax
    "decl" {Id ","}+ ":" Type -> Decl
    "integer"                 -> Type 
    "real"                    -> Type
\end{verbatim}
\end{IncCode}
\caption{Definition of a list of identifiers}
\end{Label}
\end{figure}

\subsubsection{Chain Functions}

A context-free syntax may contain functions that do not add syntax, but serve
the sole purpose of including a smaller syntactic notion into a larger one. 
This notion is also known as {\em injections}. 
Injections are functions ``without a name'' and with one argument sort
like {\tt Id -> Data}.
A typical example is the inclusion of identifiers in expressions or of natural
numbers in reals. Such a \emph{chain function} has one of the following forms:

\begin{itemize}

\item {\tt SMALL -> BIG} 
\item {\tt \{SMALL SEP\}* -> BIG} 
\item {\tt SMALL* -> BIG} 
\item {\tt \{SMALL SEP\}+ -> BIG} 
\item {\tt SMALL+ -> BIG}
\item {\tt \{SMALL SEP\}n+ -> BIG} 
\item {\tt SMALLn+ -> BIG}

\end{itemize}

Chain functions do not appear in the abstract syntax but correspond to a
\emph{subsort relation} between {\tt SMALL} and {\tt BIG}.
If {\tt SORT-A} is a subsort of {\tt SORT-B} then in the abstract syntax
tree a tree of sort {\tt SORT-A} can be put wherever a tree of
sort {\tt SORT-B} is required.
\T In Figure~\ref{CODE:inj-exp} 
\W In the example \link{below}[]{CODE:inj-exp}
the symbols {\tt Nat} and {\tt Var} are injected in {\tt Exp}.

\begin{figure}
\begin{Label}{CODE:inj-exp}
\begin{IncCode}
\begin{verbatim}
module Exp

imports basic/Whitespace

exports
  context-free start-symbols Exp
  sorts Nat Var Exp

  lexical syntax
    [0-9]+   -> Nat
    [XYZ]    -> Var

  context-free syntax
    Nat                 -> Exp
    Var                 -> Exp
    Exp "+" Exp         -> Exp
\end{verbatim}
\end{IncCode}
\caption{Definition of expressions that uses injections}
\end{Label}
\end{figure}

\subsubsection{Miscellaneous Operators}

In \link*{Symbols}[ Section~\Ref]{Symbols}
a number of sophisticated operators, like
alternative, option, set, function, sequence, tuple, and permutation
are discussed. These operators allow a concise manner of defining
grammars. There are, however, a number of issues to be taken into consideration
when using this operators. 

\paragraph{Definition of lists}

In the example \link*{below}[ in Figure~\Ref]{CODE:lists-usage},
two different lists are defined, 
{\tt List1} represents a list of naturals separated
by commas whereas {\tt List2} represents a list of naturals separated by
commas and terminated by a comma.

\begin{figure}[t]
\begin{Label}{CODE:lists-usage}
\begin{IncCode}
\begin{verbatim}
module Lists

imports basic/Whitespace

exports
  context-free start-symbols List1 List2
  sorts Nat List1 List2

  lexical syntax
    [0-9]+   -> Nat

  context-free syntax
    {Nat ","}+ -> List1
    (Nat ",")+ -> List2
\end{verbatim}
\end{IncCode}
\caption{Definition of two list variants}
\end{Label}
\end{figure}

\paragraph{Alternative alternatives}
The choice between two symbols can be defined in two different ways: by two
separate syntax rules or by a single syntax rule using an alternative
operator. 
Both styles are shown
\link*{below}[ in Figure~\Ref]{CODE:alternative-alternatives}.

The definition of the binary operators {\tt "|"} and {\tt "\&"} can
be made more concise as shown by {\tt Bool2}, however, it is now
impossible to express that {\tt "\&"} has a higher priority
than {\tt "|"}, see 
\link*{Priorities}[ Section~\Ref]{Priorities}
for more details on priority definitions.

\begin{figure}
\begin{Label}{CODE:alternative-alternatives}
\begin{IncCode}
\begin{verbatim}
module Bool

imports basic/Whitespace

exports
  context-free start-symbols Bool1 Bool2
  sorts Bool1 Bool2

  context-free syntax
    "true"                  -> Bool1
    "false"                 -> Bool1
    Bool1 "|" Bool1         -> Bool1 {left}
    Bool1 "&" Bool1         -> Bool1 {left}

    "true" | "false"        -> Bool2
    Bool2 ("|" | "&") Bool2 -> Bool2 {left}
\end{verbatim}
\end{IncCode}
\caption{Two ways of defining {\tt |} and {\tt \&}}
\end{Label}
\end{figure}

\subsubsection{Lists in combination with optionals or empty producing
sorts}

The combination of lists and optionals or empty producing sorts leads to
cycles in the parse tree. Cycles are considered parse errors.
The parser will produce an error message whenever during parsing
a cycle is detected. No parse tree is constructed in such a case.
Cycles will not lead to non-termination during parsing.
See \link*{below}[ Figure~\Ref]{CODE:listcycle}
for an example of such a specification.

\begin{figure}
\begin{Label}{CODE:listcycle}
\begin{IncCode}
\begin{verbatim}   
module Cycle

imports basic/Whitespace

exports
  context-free start-symbols T
  sorts A P T

  context-free syntax
    "a"        -> A
    A?         -> P
    "[" P+ "]" -> T
\end{verbatim}
\end{IncCode}
\caption{Dangerous combination of lists and optionals}
\end{Label}
\end{figure}

Sometimes commenting out parts of a production rule may lead to cycles,
because a non-terminal becomes an empty producing non-terminal.
This in combination with lists may then produce unexpected cycles.

\subsection{Labels in the left-hand side of Functions}
It is possible to decorate the members in the left-hand side of a
production rule with labels. These labels have no effect when
parsing input terms. However, when an SDF module is used as input
for generating APIs these labels will be used.
See \link*{below}[ Figure~\Ref]{CODE:labels}
for an example of an SDF specification containing labels.

\begin{figure}
\begin{Label}{CODE:labels}
\begin{IncCode}
\begin{verbatim}   
module Booleans

imports basic/Whitespace

exports
  context-free start-symbols Boolean
  sorts Boolean

  context-free syntax
    lhs:Boolean "|" rhs:Boolean -> Boolean
    lhs:Boolean "&" rhs:Boolean -> Boolean
\end{verbatim}
\end{IncCode}
\caption{The module {\tt basic/Booleans} decorated with labels}
\end{Label}
\end{figure}

\subsection{Attributes of Lexical and Context-free Functions}
\label{Attributes}

\index{attribute@attribute}
The definition of a lexical or context-free functions may be followed by
\emph{attributes} that define additional (syntactic or semantic) properties of
that function.  The attributes are written between curly brackets after the
non-terminal in the right hand side. If a production rule has more than
one attribute they are separated by commas.
\begin{verbatim}
context-free syntax
   "{" {Attribute ","}* "}" -> Attributes {cons("attrs")}
                            -> Attributes {cons("no-attrs")}
\end{verbatim}
The following syntax-related attributes exist:

\begin{itemize}

\index{bracket attribute@bracket attribute}
\item {\tt bracket} allows the definitions of parenthesis and other
kinds of brackets that are mostly used for overruling the priorities
of operators in expressions
(see \link*{Bracket Functions}[Section~\Ref]{BracketFunctions}).

\index{left attribute@left attribute}
\index{right attribute@right attribute}
\index{non-assoc attribute@non-assoc attribute}
\index{assoc attribute@assoc attribute}
\item {\tt left}, {\tt right}, {\tt non-assoc}, and {\tt assoc}
are used to define the associativity of functions 
(see \link*{Priorities}[Section~\Ref]{Priorities}).

\index{prefer attribute@prefer attribute}
\item {\tt prefer} is used to indicate that the attributed function should
always be preferred over other functions (without this attribute)
in certain cases of syntactic ambiguity
(see \link*{Preferring, Avoiding or Rejecting Parses}[Section~\Ref]{PreferAvoidReject}).

\index{avoid attribute@avoid attribute}
\item {\tt avoid} is used to indicate that a function should
only be used as a last resort in certain cases of
syntactic ambiguity
(see \link*{Preferring, Avoiding or Rejecting Parses}[Section~\Ref]{PreferAvoidReject}).

\index{reject attribute@reject attribute}
\item {\tt reject} can be used to explicitly forbid certain syntactic
  constructs
  (see  \link*{Preferring, Avoiding or Rejecting Parses}[Section~\Ref]{PreferAvoidReject}).


\end{itemize}

\noindent The remaining attributes define semantic properties of a function:

\begin{itemize}

\index{constructor attribute@constructor attribute}
\item {\tt constructor} declares a function to be a \emph{constructor
function}, this means that for this function \emph{no} equations
may be defined with this function as outermost function symbol
in the left hand side.

\index{memo attribute@memo attribute}
\item {\tt memo} declares a function to be a \emph{memo function} for
which all calls and results will be cached during evaluation
(see \link*{Memo Functions}[Section~\Ref]{MemoFunctions}).

%%\item {\tt delay} is used to influence the evaluation order of the
%%arguments of a function (Section~\ref{Delay}).

\index{traversal attribute@traversal attribute}
\item {\tt traversal} is used to declare so-called traversal functions
that greatly simply the specification of functions that have to visit
(parts of) a term 
(see \link*{Traversal Functions}[Section~\Ref]{Traversal}).

\index{ATerm attribute@ATerm attribute}
\item arbitrary ATerms may also be used as attributes. In the context-free
syntax definition of the {\tt Attributes}, the ATerms {\tt cons("attrs")}
and {\tt cons("no-attrs")} are used. The {\tt cons} attribute is used by
other tools, such as ApiGen.
\end{itemize}

Not all combinations of attributes make sense. If one uses the attribute
{\tt left} in combination with {\tt bracket}, {\tt right}, {\tt assoc}
or {\tt non-assoc}, this will result in an error message. The combination
of {\tt avoid} and {\tt prefer} does not make sense either.
Furthermore, the combination of the traversal attributes is also very strict.

\subsection{Priorities}
\label{Priorities}

\index{priorities@priorities}
The context-free syntax defined in an ASF+SDF specification may be 
ambiguous: there are sentences which have more than one associated tree. 
The common example is the arithmetic expression in which definitions 
of the priority or associativity of operators are missing. There are 
three mechanisms for defining associativity and priority:

\begin{itemize}
  
\item \link{Relative priorities of functions}[ (see Section~\Ref)]{RelativePriorities}
  defined in the {\tt context-free priorities} section.

\index{associativity@associativity}
\item \link{Associativity of functions}[ (see Section~\Ref)]{AssociativeFunctions}
 defined as attributes following the function declaration.
  
\item \link{Associativity of groups of functions}[ (see Section~\Ref)]{GroupAssoc}
  defined in the {\tt context-free priorities} section.

\end{itemize}

Closely related with priorities are brackets that can be used to
overrule priorities.  We will first describe bracket functions,
and then the various methods for defining priorities.

\subsubsection{Bracket Functions}
\label{BracketFunctions}

\index{bracket functions@bracket functions}
A bracket function has the form `{\tt $open$ $S$ $close$ -> $S$}' where $open$
and $close$ are literals acting as opening and closing parenthesis for sort
$S$. Examples are `{\tt (}' and `{\tt )}' in arithmetic expressions.
In most cases, such brackets are only
introduced for grouping and disambiguation, but have no further meaning. By
adding the attribute {\tt bracket} to the function declaration, it will not be
included in the abstract syntax.
The definition of a bracket function for the sort {\tt Expr} 
is given
\link*{below}[ in Figure~\Ref]{CODE:bracket-expr}.

\begin{figure}
\begin{Label}{CODE:bracket-expr}
\begin{IncCode}
\begin{verbatim}
module BracketExpr

imports basic/Whitespace
imports basic/NatCon

exports
  context-free start-symbols E
  sorts E

  context-free syntax
    NatCon    -> E
    "(" E ")" -> E {bracket}
\end{verbatim}
\end{IncCode}
\caption{Syntax definition with a bracket function}
\end{Label}
\end{figure}

Since brackets are necessary for overruling the priority and associativity of
functions,  it is required that bracket 
functions are declared for the argument and result sorts of

\begin{itemize}

\item all functions appearing in priority declarations, and
  
\item all functions having one of the attributes {\tt left}, {\tt right}, 
{\tt assoc}, or {\tt non-assoc}.

\end{itemize}

\subsubsection{Relative Priorities}
\label{RelativePriorities}

\index{relative priorities@relative priorities}
The relative priority of two functions is defined 
in the `{\tt context-free priorities}' section 
by including {\tt $F$ > $G$},
where $F$ and $G$ are 
as written in the context-free grammar. Functions with a higher 
priority bind more strongly than functions with lower priorities and 
the nodes corresponding to them should
thus appear at lower levels in the tree than nodes corresponding to functions
with lower priorities. Lists of functions may be used in a priority
declaration: {\tt $F$ > \{$G$, $H$\}} is an 
abbreviation for {\tt $F$ > $G$, $F$ > $H$}.
Note that this tells us nothing about the priority relation between $G$ and $H$. 

\subsubsection{Associative Functions}
\label{AssociativeFunctions}

\index{associativity functions@associativity functions}
Associativity attributes can be attached to binary functions of the form 
`{\tt $S$ $op$ $S$ -> $S$}', where $op$ is a symbol or empty. 
Without associativity attributes, nested occurrences of such 
functions immediately lead to ambiguities, as is shown by the 
sentence `{\tt S-string op S-string op S-string}' where 
`{\tt S-string}' is a string produced by symbol $S$. 
The particular associativity 
associated with $op$ determines the intended interpretation of such sentences.
  
We call two occurrences of functions $F$ and $G$ \emph{related}, when the node
corresponding to $F$ has a node corresponding to $G$ as first or last child.
The associativity attributes define how to accept or reject trees containing
related occurrences of the same function, $F$:

\begin{itemize}

\item {\tt left}: related occurrences of $F$ associate from left to right. 

\item {\tt right}: related occurrences of $F$ associate from right to left. 

\item{\tt  assoc}: related occurrences of $F$ associate from left to right.

\item {\tt non-assoc}: related occurrences of $F$ are not allowed.

\end{itemize}

Currently, there is no syntactic or semantic difference between `{\tt left}'
and `{\tt assoc}', but we may change the semantics of the `{\tt assoc}'
attribute in the future.

\T Figure \ref{CODE:simple-prio} gives 
\W \link{Below}[]{CODE:simple-prio} we give
an example of a definition of
simple arithmetic expressions with the usual priorities and
associativities.

\begin{figure}
\begin{Label}{CODE:simple-prio}
\begin{IncCode}
\begin{verbatim}
module SimpleExpr

imports basic/Whitespace
imports basic/NatCon

exports
  context-free start-symbols E 
  sorts E 

  context-free syntax
    NatCon    -> E
    E "+" E   -> E {left}
    E "*" E   -> E {left}
    "(" E ")" -> E {bracket}

  context-free priorities
    E "*" E -> E > 
    E "+" E -> E
\end{verbatim}
\end{IncCode}
\caption{Simple context-free priority definition}
\end{Label}
\end{figure}   

\subsubsection{Groups of Associative Functions}
\label{GroupAssoc}

\index{associativity groups@associativity groups}
Groups of associative functions define how to accept or reject trees
containing related occurrences of different functions with the same priority.
They are defined by prefixing a list of context-free functions in a priority
declaration with one of the following attributes:

\begin{itemize}

\item {\tt left}: related occurrences of $F$ and $G$ associate from left to right. 
\item {\tt right}: related occurrences of $F$ and $G$ associate from right to left.
\item {\tt non-assoc}: related occurrences of $F$ and $G$ are not allowed.

\end{itemize}

\noindent where $F$ and $G$ are functions appearing in the list.
\link*{below}[ Figure~\Ref]{CODE:complex-prio},
an example of the use of grouped associativity.

\begin{figure}
\begin{Label}{CODE:complex-prio}
\begin{IncCode}
\begin{verbatim}
module ComplexExpr

imports basic/Whitespace
imports basic/NatCon

exports
  context-free start-symbols E 

  sorts E 

  context-free syntax
    NatCon    -> E
    E "+" E   -> E {left}
    E "-" E   -> E {non-assoc}
    E "*" E   -> E {left}
    E "/" E   -> E {non-assoc}
    E "^" E   -> E {right}
    "(" E ")" -> E {bracket}

  context-free priorities
    E "^" E -> E > 
    {non-assoc: E "*" E -> E
                E "/" E -> E} >
    {left: E "+" E -> E
           E "-" E -> E}
\end{verbatim}
\end{IncCode}
\caption{More complex associativity and priority definitions}
\end{Label}
\end{figure}   

\subsubsection{Restrictions}
\label{Restrictions}
\label{ContextFreeRestrictions}
\label{LexicalRestrictions}

\index{restrictions@restrictions}
\index{lexical restrictions@lexical restrictions}
\index{context-free restrictions@context-free restrictions}
\index{{\tt -/-}@{\tt -/-}}
\index{{\tt <Lookaheads>}@{\tt <Lookaheads>}}
Lexical syntax can be highly ambiguous.  Consider 
a simple lexical definition for identifiers
like the one given \link{earlier}[ in Figure~\Ref]{CODE:repetition}.
When recognizing the text {\tt abc}, what should we return: {\tt a}, {\tt ab}
or, {\tt abc}? 
We discuss the strategy \emph{Prefer Longest Match} for
resolving this kind of ambiguity in
\link*{Lexical Ambiguities}[ Section~\Ref]{lex-ambiguity}.

Here, we describe the notion of \emph{restrictions} that enable the formulation
of this and other lexical disambiguation strategies.

A restriction limits the \emph{lookahead} for a given symbol; it indicates
that a symbol may not be followed by a character from a given character class.
A lookahead may consist of more than one character class.  Restrictions come
in two flavors:

\begin{itemize}
\item lexical restrictions;
\item context-free restrictions.
\end{itemize}

\noindent The general form of a restriction is 

\begin{verbatim}
<Symbol>+ -/- <Lookaheads>
\end{verbatim}
 
\noindent In case of lexical restrictions {\tt <Symbol>} may be   
either a literal or sort.  
In case of context-free restrictions only a sort or symbol is allowed.
The restriction operator {\tt -/-} should be read as ``may not be
followed by''.
Before the restriction operator {\tt -/-} a list of symbols
is given for which the restriction holds.
 
In the example\footnote{Taken from~\cite{Vis97}}
\link*{below}[ in Figure~\Ref]{CODE:functional}
both {\tt let} and {\tt in} may not be followed by a letter.
This example shows how lexical restrictions can be used to prevent
the recognition of erroneous expressions in a small functional language.
The lexical restriction deals with the possible confusion between
the reserved words {\tt let} and {\tt in} and variables (of sort {\tt Var}).
It forbids the recognition of, for instance, {\tt let} as part
of {\tt letter}. Without this restriction {\tt letter} would be recognized
as the keyword {\tt let} followed by the variable  {\tt ter}.
The context-free restriction forbids that a variable is directly
followed by a letter. It does not forbid layout characters between
the letters, e.g. {\tt a b} is a legal recognizable string.

\begin{figure}
\begin{Label}{CODE:functional}
\begin{IncCode}
\begin{verbatim}
module Functional

imports basic/Whitespace

exports
  context-free start-symbols Term 
  sorts Var Term
  lexical syntax
    [a-z]+ -> Var
  context-free syntax
    Var                          -> Term
    Term Term                    -> Term {left}
    "let" Var "=" Term "in" Term -> Term

  lexical restrictions
    "let" "in" -/- [a-z]

  context-free restrictions
    Var -/- [a-z]
\end{verbatim}
\end{IncCode}
\caption{Using restrictions in the definition of a simple functional language}
\end{Label}
\end{figure}   

{\tt <Lookaheads>} are slightly more complex.  The most compact way is to
give the SDF definition of the {\tt <Lookaheads>} and illustrate their use by
means of some examples.

\begin{verbatim}
context-free syntax
  CharClass                    -> Lookahead
  CharClass "." Lookaheads     -> Lookahead
  Lookahead                    -> Lookaheads
  Lookaheads "|" Lookaheads    -> Lookaheads {right}
  "(" Lookaheads ")"           -> Lookaheads {bracket}
  "[[" {Lookahead ","}* "]]"   -> Lookaheads 
\end{verbatim}

The next example illustrates the use of restrictions to define a
`safe' way of layout.  
\link{Recall}[ from Section~\Ref]{LexicalSyntax}
that optional layout, represented by the symbol {\tt LAYOUT?},
may be recognized between the 
members of the left-hand side of a context-free syntax rule.

However, if a such a member recognizes the empty string, this gives rise to a
\link{lexical ambiguity}[ (Section~\Ref)]{lex-ambiguity}. 
This problem is avoided by the definition 
given \link*{below}[in Figure~\Ref]{CODE:safe-layout}:
it simply forbids that optional layout is followed by layout characters.

\begin{figure}
\begin{Label}{CODE:safe-layout}
\begin{IncCode}
\begin{verbatim}
module basic/Whitespace

exports
  lexical syntax
    [\ \t\n] -> LAYOUT

  context-free restrictions
    LAYOUT? -/- [\ \t\n]
\end{verbatim}
\end{IncCode}
\caption{Safe way of defining {\tt LAYOUT}}
\end{Label}
\end{figure}

The example shown \link*{below}[in Figure~\Ref]{CODE:c-comment}
illustrates the
use of restrictions to extend the previous layout definition with C-style
comments. For readability we give here \emph{two} restrictions whereas the
first one is already imported from 
\link{module {\tt basic/Whitespace}}[ (Figure~\Ref)]{CODE:safe-layout}.  
The repetition of this first restriction is
redundant and could be eliminated.

\begin{figure}
\begin{Label}{CODE:c-comment}
\begin{IncCode}
\begin{verbatim}
module Comment

imports basic/Whitespace

exports
  sorts ComWord Comment
  lexical syntax
    ~[\ \n\t\/]+ -> ComWord

  context-free syntax
    "/*" ComWord* "*/" -> Comment
    Comment            -> LAYOUT

  context-free restrictions
    LAYOUT? -/- [\ \t\n]
    LAYOUT? -/- [\/].[\*]
\end{verbatim}
\end{IncCode}
\caption{Definition of C comments}
\end{Label}
\end{figure}

A frequently asked question is when to use \emph{lexical} restrictions
and when to use \emph{context-free} restrictions. 
In one of the \link{previous examples}[ (Figure \Ref)]{CODE:functional}
the lexical restrictions on {\tt let} and {\tt in}
cannot be defined using context-free restrictions
because these keywords do not "live" at the context-free level.
Is it possible to put a lexical restriction on {\tt Var}?
Yes, but it will have no effect, because internally the
lexical {\tt Var} is injected in the context-free {\tt Var}.
The general rule is to define the restrictions always on the
context-free level and not on the lexical level unless a situation 
as will be discussed in the next paragraph occurs.

The specification 
\link*{below}[in Figure~\Ref]{CODE:restrictedexpressions} is an example of
an erroneous use of
context-free expressions, because it prevents the recognition of
{\tt (abc)def}. If we want to enforce the correct restriction, it
is necessary to transform this context-free restriction into
a lexical restriction.

\begin{figure}
\begin{Label}{CODE:restrictedexpressions}
\begin{IncCode}
\begin{verbatim}
module RestrictedExpressions

imports basic/Whitespace

exports
  context-free start-symbols Expr
  sorts Expr

  lexical syntax
    [a-z]+ -> Expr

  context-free syntax
    Expr Expr    -> Expr {left}
    "(" Expr ")" -> Expr {bracket}

  context-free restrictions
    Expr -/- [a-z]
\end{verbatim}
\end{IncCode}
\caption{Erroneous use of restrictions in the definition of simple expressions}
\end{Label}
\end{figure}   



\subsubsection{Preferring, Avoiding or Rejecting Parses} 
\label{PreferAvoidReject}

Priorities can be used to define a priority between two functions or between
two groups of functions. In both cases the functions involved have to be
listed explicitly in the priority declaration. In certain cases, however, it
is desirable to define that a single rule has higher or lower priority than
all other functions or to explicitly reject certain syntactic constructs.
The former is achieved by the attributes {\tt prefer} and {\tt avoid}. The
latter by the attribute {\tt reject}. 

The use of the {\tt reject} attribute leads also to improvements in the 
performance of the parser, see \cite{BSVV02} for more implementation
details.

If a function $F$ is attributed with {\tt prefer} and there is a syntactic
ambiguity in which it is involved, only the parse using $F$ will remain.

If a function $F$ is attributed with {\tt avoid} and there is no ambiguity,
then $F$ will be used. If there is an ambiguity, then $F$ will be immediately
removed from the set of ambiguities.

If a function $F$ is attributed with {\tt reject}, then independently of the
number of ambiguities, the parse using $F$ will be removed.  While
\link{restrictions}[ (Section~\Ref)]{Restrictions}
only impose limitations on the
immediate lookahead that follows a symbol, the reject mechanism can be used
to eliminate complicated syntactic structures.

Examples of the use of {\tt prefer}, {\tt avoid} and {\tt reject} in order
to solve lexical ambiguities are discussed in
\link*{Lexical Ambiguities}[ Section~\Ref]{lex-ambiguity}.
In \link*{Context-free Ambiguities}[ Section~\Ref]{cf-ambiguity}
we will give examples of how to use
these attributes to solve context-free ambiguities, such as the
famous dangling else problem.

\subsection{Disambiguation}
\label{Disambiguation}

\subsubsection{Lexical Ambiguities}
\label{lex-ambiguity}

SDF provides a number of elementary lexical disambiguation features but does
not offer {\em fully automated} lexical disambiguation.
As a result, the specification writer has to be aware of lexical ambiguities
and has to specify disambiguation rules explicitly.
We will discuss various
approaches to lexical disambiguation and illustrate them by means of examples.

\W We will discuss:
\W \htmlmenu{1}

\paragraph{Prefer Longest Match per Sort} Reject all interpretations of 
the input text that are included in a longer interpretation of the same 
sort. Given a standard definition of identifiers, the input `{\tt xyz}' 
will thus lead to recognition of the identifier `{\tt xyz}' and not to 
either `{\tt x}' or `{\tt xy}'.

This is achieved by defining a restriction on this lexical sort. This
can be done using either lexical or context-free
\link{restrictions}[ (see Section~\Ref)]{Restrictions}.
The specification \link*{below}[ in Figure~\Ref]{CODE:restrict-id} 
shows how to enforce the longest match for the sort {\tt Id}.

\begin{figure}
\begin{Label}{CODE:restrict-id}
\begin{IncCode}
\begin{verbatim}
module Identifiers-restrict

imports basic/Whitespace

exports
  context-free start-symbols Id
  sorts Id
  lexical syntax
    [a-zA-Z][a-zA-Z0-9]* -> Id

  context-free restrictions
    Id -/- [a-zA-Z0-9]  
\end{verbatim}
\end{IncCode}
\caption{Using context-free restrictions to define a longest match for
    identifiers}
\end{Label}
\end{figure}   

\paragraph{Prefer Literals} 

In the left-hand side of a context-free syntax rule literals (keywords
and/or operators) may be used.  If these literals overlap with  more
general lexical tokens (such as identifier) this causes ambiguities.

The strategy \emph{Prefer Literals} gives preference to interpretation
as a literal, over interpretation as a more general lexical token.
For instance, the keyword {\tt begin} may be recognized as an identifier
given the lexical definition \link*{below}[ in Figure~\Ref]{CODE:restrict-id}.

There are two approaches to implement Prefer Literals.

In the first approach, we can explicitly forbid the recognition of
literals as tokens of a specific sort using the
\link{reject mechanism}[ (see Section~\Ref)]{PreferAvoidReject}.  
The idea is to define context-free
grammar rules for all literals with the undesired lexical sort (e.g.,
{\tt Id}) in the right-hand side followed by the attribute {\tt reject}.
This is illustrated \link*{below}[in Figure~\Ref]{CODE:reject-id}.
The {\tt reject} attribute
indicates here that the recognition of a keyword as a literal of the sort
{\tt Id} should be rejected. This approach has the major disadvantage
that the addition of a literal in any context-free rule also requires
the addition of a new reject rule for that literal.

\begin{figure}
\begin{Label}{CODE:reject-id}
\begin{IncCode}
\begin{verbatim}
module Identifiers-reject

imports basic/Whitespace

exports
  context-free start-symbols Id
  sorts Id

  lexical syntax
    [a-zA-Z][a-zA-Z0-9]* -> Id

  context-free restrictions
    Id -/- [a-zA-Z0-9]  

  context-free syntax
    "begin" -> Id {reject}
\end{verbatim}
\end{IncCode}
\caption{Using {\tt reject} to implement Prefer Literals}
\end{Label}
\end{figure}   

The second approach is more attractive. The lexical definition of the general
notion that interferes with our literals is written in such a way that it is
only used as a last resort. In other words, it is avoided as much as possible
and is only used when no alternative exists.  
The attribute {\tt avoid} defines precisely this behaviour
(see \link*{Preferring, Avoiding or Rejecting Parses}[Section~\Ref]{PreferAvoidReject}).
\link*{The next example}[Figure~\Ref]{CODE:avoid-id} shows
how the lexical definition of {\tt Id} is attributed with {\tt avoid}.

Although the first approach is more tedious, it allows more flexibility
than the second one.

\begin{figure}
\begin{Label}{CODE:avoid-id}
\begin{IncCode}
\begin{verbatim}
module Identifiers-avoid

imports basic/Whitespace

exports
  context-free start-symbols Id
  sorts Id

  lexical syntax
    [a-zA-Z][a-zA-Z0-9]* -> Id {avoid}

  context-free restrictions
    Id -/- [a-zA-Z0-9]  
\end{verbatim}
\end{IncCode}
\caption{Using {\tt avoid} to implement Prefer Literals}
\end{Label}
\end{figure}   

\paragraph{Prefer Non-Layout} If there are interpretations of the text as
layout symbol and as non-layout symbol, eliminate all interpretations as layout
symbol. This is built-in behaviour of \asfsdf.

\paragraph{Prefer Variables} Give preference to interpretation as a 
variable (as defined in a variables section) over interpretation as a lexical
token. Thus built-in behaviour of \asfsdf. It is achieved by automatically
extending each variable declaration with 
the attribute {\tt prefer}
(see \link*{Preferring, Avoiding or Rejecting Parses}[Section~\Ref]{PreferAvoidReject}).

\subsubsection{Context-free Ambiguities}
\label{cf-ambiguity}

Context-free grammars may be ambiguous and, as a result, the parser may yield
different parses of a text. More precisely, the result of a parse is a single
tree in which the ambiguities are explicitly marked. Each marked ambiguity
consists of a set of different parse trees for that ambiguity.  
 Many, but notall, of these different parses can be eliminated by the following
strategies that are built-in the \ASmetaenv. These strategies use the
priorities and associativities as defined in the specification. In addition,
some standard heuristics are used.

\paragraph{Associativity filtering} The associativity filtering
is performed during the generation of the parse table. Based
on the associativity relations certain entries in the parse table
are removed.

\paragraph{Removing Trees containing Conflicts}

The simplest application of priority and associativity declarations is the
elimination of trees that contain conflicts:

\begin{itemize}

\item A parent node has a child with a lower priority than the parent itself.
  
\item A parent has a first or last child that is in conflict with
  an associativity relation between this parent and child.

\end{itemize}

Reconsidering the example of complex priorities shown \link*{earlier}[in
Figure~\Ref]{CODE:complex-prio} we will give a number of example sentences and
the interpretation given to them by that language definition.

\begin{center}
\begin{tabular}{ll}
  Sentence   & Interpretation \\
\verb"1^2^3" & \verb"1^(2^3)" \\
\verb"1^2*3" & \verb"(1^2)*3" \\
\verb"1*2*3" & \verb"(1*2)*3" \\
\verb"1/2/3" & error \\
\verb"1*2/3" & error \\
\verb"1-2-3" & error \\
\verb"1+2+3" & \verb"(1+2)+3" \\
\verb"1-2+3" & \verb"(1-2)+3" \\
\verb"1+2-3" & \verb"(1+2)-3"\\
\end{tabular}
\end{center}

\paragraph{Removing Trees using {\tt prefer}/{\tt avoid} Attributes at the Root}

The priority declarations are used to eliminate trees 
in three phases: 

\begin{enumerate}
  
\item If there are trees of which the syntax rule at the top node has a {\tt
    prefer} attribute, all other trees are removed.

\item  If there are trees of which the syntax rule at the top node has an {\tt
    avoid} attribute and there are other trees without an {\tt avoid} attribute at
  the root node, then all trees with {\tt avoid} attribute are removed.
  
\end{enumerate}

\paragraph{Removing Trees containing {\tt prefer}/{\tt avoid} Attributes}

After removing all trees containing conflicts, more than one tree may
still remain.  To further reduce this set of remaining trees, the number
of context-free functions with {\tt prefer}/{\tt avoid} attributes is
calculated and compared.  A tree in the set is then rejected if there
is another tree in the set with more {\tt prefer}s and less or equal
{\tt avoid}s, or with equal {\tt prefer}s and more {\tt avoid}s.

\paragraph{Injection count}
Finally, the number of injections in each of the resulting trees
is calculated, the tree with the smallest number of injections
is prefered.


\paragraph{Examples}

The following examples show how the interaction (and resulting ambiguities)
between general context-free functions and special case functions can be
described using {\tt prefer} attribute. 

The \link{first example}[(Figure~\Ref]{CODE:eqn-exprs} concerns expressions
for describing subscripts and superscripts in the typesetting language EQN.
The crucial point is that, for typesetting reasons, we want to treat a
subscript followed by a superscript in a special way. Therefore, the special
case `{\tt E sub E sup E -> E}' is introduced, which is prefered over a
combination of the two functions `{\tt E sub E -> E}' and `{\tt E sup E ->
  E}'.

\begin{figure}
\begin{Label}{CODE:eqn-exprs}
\begin{IncCode}
\begin{verbatim}
module Eqn

imports basic/Whitespace

exports
  context-free start-symbols E
  sorts E 

  context-free syntax
    E "sub" E         -> E {left}
    E "sup" E         -> E {left}
    E "sub" E "sup" E -> E {prefer}
    "{" E "}"         -> E {bracket}
    "a"               -> E 
\end{verbatim}
\end{IncCode}
\caption{Syntax definition of EQN expressions}
\end{Label}
\end{figure}

In the \link{second example}[ (Figure~\Ref)]{CODE:dangling-else}
the {\tt prefer} attribute is used to
solve the dangling else problem in a nice way.
The input sentence {\tt "if 0 then if 1 then hi else ho"} can be parsed
in two ways: {\tt if 0 then (if 1 then hi) else ho} and
{\tt if 0 then (if 1 then hi else ho)}.
We can select the latter derivation by adding the {\tt prefer}
attribute to the production without the {\tt else} part.
The parser will still construct an ambiguity node containing both
deriviations,
namely, {\tt if 0 then (if 1 then hi \{prefer\}) else ho} and
{\tt if 0 then (if 1 then hi else ho) \{prefer\}}.
But given the fact that the \emph{top} node of the latter derivation tree
has the prefer attribute this derivation is selected and the other
tree is removed from the ambiguity node.

\begin{figure}
\begin{Label}{CODE:dangling-else}
\begin{IncCode}
\begin{verbatim}
module DanglingElse

imports basic/Whitespace

exports
  context-free start-symbols S
  sorts E S

  context-free syntax
    "a"                      -> E 
    "if" E "then" S          -> S {prefer}
    "if" E "then" S "else" S -> S
    "s"                      -> S
\end{verbatim}
\end{IncCode}
\caption{Syntax definition of conditionals}
\end{Label}
\end{figure}

\subsection{Parameterization and Renaming}
\label{ParametersRenamings}

Parameterization and renaming were in fact features of 
the original ASF as described
in \cite{BHK89}, but they were never supported by the ASF+SDF
used in the first version of the \ASmetaenv~\cite{Kli93}. 
Based on the work described in \cite{Vis97}, ASF+SDF is extended
with parameterization and symbol renaming\footnote{In \cite{Vis97} the
notion of production renaming is also introduced, but this
will not be supported.}. We will first explain the notion
of parameterization, later we will give details on symbol renaming.

\subsubsection{Parameterization}
\label{Parameters}

Module parameterization allows the definition of generic modules
for lists, pairs, sets, etc. The operations defined in these
modules are independent of a specific type. When importing a
parameterized module and instantiating the formal by actual
parameters the operations become "sort" specific.

Modules can have formal parameters when defining them. The module name
is then followed by a list of symbols, representing the formal
parameters of this module. 
The specification \link*{below}[in Figure~\Ref]{CODE:generic-pairs} shows 
an example of a parameterized module. In this example the
formal parameters are used in the parameterized sorts as well,
in order to increase readability and to avoid name clashes between
different instances of the same module.

\begin{figure}
\begin{Label}{CODE:generic-pairs}
\begin{IncCode}
\begin{verbatim}
module Pair[X Y]

imports basic/Whitespace
imports basic/Booleans

hiddens
  sorts X Y

exports
  context-free start-symbols Pair[[X,Y]]
  sorts Pair[[X,Y]]

  context-free syntax
    "[" X "," Y "]"      -> Pair[[X,Y]]

    make-pair(X, Y)      -> Pair[[X,Y]]
    first(Pair[[X,Y]])   -> X
    second(Pair[[X,Y]])  -> Y
    is-pair(Pair[[X,Y]]) -> Boolean
\end{verbatim}
\end{IncCode}
\caption{Definition of generic pairs}
\end{Label}
\end{figure}

When importing a parameterized module the formal parameters have
to be replaced by actual parameters. 
The specification \link*{below}[in Figure~\Ref]{CODE:importing-pairs} shows 
an example of a rather complicated import of a parameterized module. 
The symbols {\tt Pair[[Boolean,Boolean]]} and {\tt Pair[[Integer,Integer]]} are the
actual parameters of the module {\tt Pair[X Y]} in the last import.

\begin{figure}
\begin{Label}{CODE:importing-pairs}
\begin{IncCode}
\begin{verbatim}
module TestPair

imports basic/Booleans 
imports basic/Integers 
imports Pair[Boolean Boolean]
imports Pair[Integer Integer]
imports Pair[Pair[[Boolean,Boolean]] Pair[[Integer,Integer]]]
\end{verbatim}
\end{IncCode}
\caption{Use of generic pair module}
\end{Label}
\end{figure}

\subsubsection{Symbol Renaming}
\label{Renamings}

Symbol renaming is in fact very similar to parameterization except
that it is not necessary to add formal parameters to a module.
The mechanism of symbol renaming allows the overriding of one
symbol or a set of symbols by another symbol or symbols, respectively. 
It allows a flexible and concise way of adapting specifications.
The specification \link*{below}[in Figure~\Ref]{CODE:pairs} shows 
an example of the {\tt Pair} module without parameters. 
The idea is to achieve the same effect as parameterization
by explicitly renaming {\tt X} and {\tt Y} to the desired
names when {\tt Pair} is imported.

\begin{figure}
\begin{Label}{CODE:pairs}
\begin{IncCode}
\begin{verbatim}
module Pair

imports basic/Whitespace
imports basic/Booleans

hiddens
  sorts X Y

exports
  context-free start-symbols Pair[[X,Y]]
  sorts Pair[[X,Y]]

  context-free syntax
    "[" X "," Y "]"      -> Pair[[X,Y]]

    make-pair(X, Y)      -> Pair[[X,Y]]
    first(Pair[[X,Y]])   -> X
    second(Pair[[X,Y]])  -> Y
    is-pair(Pair[[X,Y]]) -> Boolean
\end{verbatim}
\end{IncCode}
\caption{Definition of generic pairs}
\end{Label}
\end{figure}

During import such module symbols can be renamed via symbol renaming.
The specification \link*{below}[in Figure~\Ref]{CODE:renaming-pairs} shows 
an example of a rather complicated import of the module {\tt Pair}
using renamings. Renaming {\tt X} to {\tt Boolean} is, for instance,
written as {\tt X => Boolean}.

\begin{figure}
\begin{Label}{CODE:renaming-pairs}
\begin{IncCode}
\begin{verbatim}
module TestPair

imports basic/Booleans 
imports basic/Integers 
imports Pair[X => Boolean Y => Boolean]
imports Pair[X => Integer  Y => Integer]
imports Pair[X => Pair[[Boolean,Boolean]] Y => Pair[[Integer,Integer]]]
\end{verbatim}
\end{IncCode}
\caption{Use of generic pair module}
\end{Label}
\end{figure}

\subsection{Variables}
\label{Variables}

\index{variables@variables}
Variables are declared in the `{\tt variables}' section of a module.  Like all
other entities in a 
module, except equations, variables may be exported
(see \link*{Modules}[Section~\Ref]{modules}). 
A variables section consists of a list of variable
names followed by a symbol. In fact, a variable declaration can define an
infinite collection of variables by using a \emph{naming scheme} instead of a
simple variable name.  A naming scheme is a regular expression like the ones
allowed in the \link{lexical syntax}[ (Section~\Ref)]{lexical-syntax} except that sorts
are not allowed. A variable may represent any symbol. 

In the specification \link*{below}[in Figure~\Ref]{CODE:variables},
`{\tt Id}', `{\tt Type3}', and `{\tt Id-list}'
are examples of variables declared by the naming schemes in 
the {\tt variables} section.
Strings that occur in the left-hand side of variable declarations
should {\em always} be quoted.

\begin{figure}
\begin{Label}{CODE:variables}
\begin{IncCode}
\begin{verbatim}
module VarDecls

imports basic/Whitespace

exports
  context-free start-symbols Decl
  sorts Id Decl Type 

  lexical syntax
    [a-z]+ -> Id
 
  context-free syntax
    "decl" {Id ","}+ ":" Type -> Decl 
    "integer"                 -> Type 
    "real"                    -> Type 

hiddens
  variables
    "Id"           -> Id 
    "Type"[0-9]*   -> Type 
    "Id-list"[\']* -> {Id ","}* 
    "Id-ne-list"   -> {Id ","}+
\end{verbatim}
\end{IncCode}
\caption{Variable declarations using naming schemes}
\end{Label}
\end{figure}         

Declared variables can only be used when defining equations. It is not
allowed to use them in terms.

Ambiguities due to variables are resolved by the {\em Prefer Variables}
strategy that was discussed in
\link*{Lexical Ambiguities}[Section~\Ref]{lex-ambiguity}.

\subsection{Libraries}
\label{Libraries}

Via the graphical user interface of the \ASmetaenv\ one has access to
a number of predefined modules. These library modules are divided into
4 different categories:
\begin{enumerate}
\item {\tt basic}
\item {\tt containers}
\item {\tt languages}
\item {\tt utilities}
\end{enumerate}

Each of these categories offers a number of useful library modules, e.g.,
the category {\tt basic} offers the library modules for {\tt Booleans},
{\tt Integers}, {\tt Strings}, etc. The category {\tt containers} offers
modules {\tt List}, {\tt Set}, and {\tt Table}. The category {\tt
languages} offers a number of predefined syntax definitions. 

One can import these library modules in a specification in the following
way:
{\tt imports basic/Booleans} for a library module without parameters and
{\tt imports containers/List[Boolean]} if it is a parameterized library
module. In the various examples presented upto now the library modules
are used whenever appropriate.

When developing a new specification make sure that you check the libraries
in order to reduce the amount of work.

\subsubsection{Position Information}
In a number of cases, for instance when producing error messages, it can
be very useful to retrieve the position information of subterms.
\subsubsection{Error messages}

\subsection{Equations}
\label{Equations}

\index{equations@equations}
\index{Asf+Sdf@\asfsdf}
With equations a meaning or semantics may be added to functions declared in
the lexical and context-free syntax sections. 
In particular, equations consist of two \emph{open terms}, i.e.
terms possibly containing variables.

In the context of \asfsdf, an open term is any string that can be parsed
according to one of the sorts in the specification (possibly including
variables).  
Examples of (open) terms are `{\tt true}', `{\tt not(false)}',
and `{\tt true | Bool}'.

\W We will discuss the following aspects of equations:
\W \htmlmenu{1}

\subsubsection{Unconditional Equations}

\index{unconditional equations@unconditional equations}
An equality then consists of two (possibly open) terms $L$ (lefthand side) and $R$ (righthand
side) such that:

\begin{itemize}

\item $L$ and $R$ are of the same sort.

\item $L$ is not a single variable.
  
\item The variables that occur in $R$ also occur in $L$.

\end{itemize}

It is assumed that the
variables occurring in the equation are universally quantified. In other
words, the equality holds for all possible values of the variables.

The equality of two terms $L$ and $R$ is defined  in ASF+SDF by the following
\emph{unconditional} equation:

\begin{quote}
{\tt [$TagId$] $L$ = $R$} 
\end{quote}

\noindent where $TagId$ is a sequence of letters, digits, and/or minus
signs ({\tt -}) starting with a letter or a digit.


\subsubsection{Conditional Equations}

\index{conditional equations@conditional equations}
An unconditional equation is a special case of a \emph{conditional equation},
i.e., an equality with one or more associated conditions (premises).  The
equality is sometimes called the \emph{conclusion} of the conditional
equation.

In ASF+SDF a conditional equation can be written in three (syntactically
different, but semantically equivalent) ways:

\begin{tabbing}
(a) \= {\tt [$TagId$]} \= {\tt $L$ = $R$ when $C_1$, $C_2$, ...} \\\\
(b) \> {\tt [$TagId$]} \> {\tt $C_1$, $C_2$, ... ===> $L$ = $R$} \\ 
(c) \> {\tt [$TagId$]} \> {\tt $C_1$, $C_2$, ...} \\
             \>    \> {\tt =================} \\
             \>    \> \ \ \ \ \ {\tt $L$ = $R$}
\end{tabbing}


\noindent where ${\tt C}_1$, ${\tt C}_2$, ...  are conditions which may be 
either matching (and have the form `{\tt $S$ := $T$}'),
negative matching (and have the form `{\tt $S$ !:= $T$}'),
positive (and have  the form `{\tt $S$ == $T$}'), 
or negative (and have the form `{\tt $S$ != $T$}').

The conditions of an equation are evaluated from left to right. Let,
initially, $V$ be the set of variables occurring in the left-hand 
side $L$ of the conclusion of the equation. 
For the evaluation of matching conditions we have the following case:
\begin{itemize}

\item Left-hand side of a matching condition must contain at least one
  new or fresh variable not in $V$.
  Reduce the right-hand side of the matching condition to a normal form 
  and the matching condition succeeds if this normal form and the 
  left-hand side of the condition match. 
  The new variables resulting from this match are added
  to $V$. This kind of condition is called a \emph{match} condition.
  The variables occurring in both $V$ and the left-hand side must
  represent the syntactically the same subterm.

\end{itemize}
For the evaluation of each positive condition we
distinguish the following cases:

\begin{itemize}
  
\item The condition contains only variables in $V$. Reduce both sides of the
  condition to normal form and the condition succeeds if both normal 
  forms are identical. 
  Technically, this is called a \emph{join} condition.
  
\end{itemize}
  
The evaluation of negative conditions is described by replacing in the above
description `identical' and `match' by `not identical' and `do not
match', respectively.
 
\warning{}
It is not allowed to introduce new variables in a negative condition.
%%A warning is appropriate here: a negative condition that introduces
%%new variables nearly always succeeds (unless the sort has exactly one
%% element) and this is almost certainly not what you want.

After the successful evaluation of the conditions, all variables occurring in
the right-hand side of the conclusion of the equation should be in $V$.

New variables (see above) should therefore {\bf not} occur on \emph{both} 
sides of a positive condition, in a negative condition, 
or in the right-hand side of the conclusion.




\subsubsection{Executing Equations}
\label{ExecutingEquations}

\index{leftmost-innermost@leftmost-innermost}
\index{rewrite rules@rewrite rules}
\index{default equations@default equations}
In the \ASmetaenv, equations can be executed as \emph{rewrite rules}.  The
above equation is thus executed as the rewrite rule $L \rightarrow R$. This
can be used to reduce some initial closed term (i.e., not containing
variables) to a \emph{normal form} (i.e., a term that is not reducible any
further) by repeatedly applying rules from the specification.

A term is always reduced in the context of a certain module, say $M$. The
rewrite rules that may be used for the reduction of the term are the rules
declared in $M$ itself and in the modules that are (directly or indirectly)
imported by $M$.

The search for an applicable rule is determined by the reduction strategy,
that is, the procedure used to select a subterm for possible reduction. In our
case the \emph{leftmost-innermost} reduction strategy is used. This means that a
left-to-right, depth-first traversal of the term is performed and that for
each subterm encountered an attempt is made to reduce it.

Next, the rules are traversed one after the other.  The textual order of the
rules is irrelevant.  Instead they are ordered according to their
\emph{specificity}: more specific rules come before more general rules and
\link{default equations}[ (see Section~\Ref)]{DefaultEquations} come last.  
\emph{Independent of the specificity, a specification should always be
confluent and terminating.}

If the selected subterm and the left-hand side of a
rule (more precisely: of the left-hand side of its conclusion) match, we say
that a \emph{redex} has been found and the following happens. The conditions
of the rule are evaluated and if the evaluation of a condition fails, other
rules (if any) with matching left-hand sides are tried.  If the evaluation of
all conditions succeeds, the selected subterm is replaced by the right-hand
side of the rule (more precisely: the right-hand side of the conclusion of the
rule) after performing proper \emph{substitutions}. Substitutions come into
existence by the initial matching of the rule and by the evaluation of its
conditions.  For the resulting term the above process is repeated until no
further reductions are possible and a normal form is reached (if any).

\subsubsection{List Matching}

\index{list matching@list matching}
\index{associative matching@associative matching}
List matching, also known as \emph{associative matching}, is a powerful
mechanism to describe complex functionality in a compact way.  

The example \link*{below}[in Figure~\Ref]{CODE:sets}
shows a compact specification to remove double elements from a set.

Unlike the matching of ordinary (non-list) variables, the matching of a list
variable may have more than one solution since the variable can match lists of
arbitrary length.

As a result, backtracking is needed. For instance, to match {\tt X Y} (a list
expression containing the two list variables {\tt X} and {\tt Y} indicating
the division of a list into two sublists) with the list {\tt ab} (a list
containing two elements) the following three alternatives have to be
considered:

\begin{quote}
{\tt X = (empty), Y = ab, \\
X = a, Y = b, \\
X = ab, Y = (empty)}.
\end{quote}

In the unconditional case, backtracking occurs only during matching. When
conditions are present, the failure of a condition following the match of a
list variable leads to the trial of the next possible match of the list
variable and the repeated evaluation of following conditions.

\begin{figure}[tb]
\begin{Label}{CODE:sets}
\begin{IncCode}
\begin{verbatim}
module Sets

imports basic/Whitespace

exports
  context-free start-symbols Set
  sorts Elem Set

  lexical syntax
    [a-z]+ -> Elem

  context-free syntax
    Set[Elem] -> Set

hiddens
  variables
    "Elem"[0-9]*  -> Elem
    "Elem*"[0-9]* -> {Elem ","}*

equations
  
  [set] {Elem*1, Elem, Elem*2, Elem, Elem*3} = {Elem*1, Elem, Elem*2, Elem*3} 
\end{verbatim}
\end{IncCode}
\caption{Set specification}
\end{Label}
\end{figure}   

Another example of list matching in combination with the evaluation
of conditions is shown \link*{below}[ in Figure~\Ref]{CODE:split}.
A list of elements is split into two parts of equal length, if the list
has an even number of elements. In case of a list of uneven length
the middle element is ignored. The first part of the list is returned
as result.

\begin{figure}[t]
\begin{Label}{CODE:split}
\begin{IncCode}
\begin{verbatim}
%% Split.sdf
module Split

imports basic/Integers
imports basic/Whitespace

exports
  context-free start-symbols List
  sorts El List

  lexical syntax
    [a-z]+ -> El
  context-free syntax
    {El ","}*          -> List
    length(List)       -> Integer
    split-in-two(List) -> List

hiddens
  variables
    "El"[0-9]*  -> El
    "El*"[0-9]* -> {El ","}* 

%% Split.asf
equations

  [l-1] length() = 0

  [l-2] length(El, El*) = 1 + length(El*)

  [s-1] length(El*1) == length(El*2)
        ====>
        split-in-two(El*1, El*2) = El*1

  [s-1] length(El*1) == length(El*2)
        ====>
        split-in-two(El*1, El, El*2) = El*1 
\end{verbatim}
\end{IncCode}
\caption{Split-in-two specification}
\end{Label}
\end{figure}  



\subsubsection{Lexical Constructor Functions}

The only way to access the actual characters of a lexical token is
by means of the so-called {\em lexical constructor functions}.
For each lexical sort $LEX$ a lexical constructor function is automatically
derived, the corresponding syntax definition is:
$lex${\tt ( CHAR* ) -> }$LEX$.
The sort {\tt CHAR} is a predefined sort to access the characters.

Characters can be directly addressed by the representation or via
variables which may be of the sorts {\tt CHAR}, {\tt CHAR*}, or
{\tt CHAR+}.
The latter two represent lists of characters.
In the example \link*{below}[in Figure~\Ref]{CODE:lcfs} 
the lexical constructor function {\tt nat-con} is used to remove the leading
zeros from a number.

\warning{}
The argument of a lexical constructor may be an
arbitrary list of characters and there is \emph{no check that they match
the lexical definition of the corresponding sort}.
This means that when writing a specification one should be aware that
it is possible to construct illegal lexical entities, for instance,
by inserting letters in an integer.
In the example \link*{below}[in Figure~\Ref]{CODE:illegallcfs} 
via the lexical constructor function {\tt nat-con} a natural
number containing the letter {\tt a} is constructed.


\begin{figure}[tb]
\begin{Label}{CODE:lcfs}
\begin{IncCode}
\begin{verbatim}
%% Nats.sdf
module Nats

imports basic/Whitespace

exports
  context-free start-symbols Nat-con
  sorts Nat-con

  lexical syntax
    [0-9]+ -> Nat-con 

hiddens
  variables
    "Char+"[0-9]* -> CHAR+

%% Nats.asf
equations

  [1] nat-con("0" Char+) = nat-con(Char+)  
\end{verbatim}
\end{IncCode}
\caption{Use of lexical constructor functions}
\end{Label}
\end{figure}    

\begin{figure}[tb]
\begin{Label}{CODE:illegallcfs}
\begin{IncCode}
\begin{verbatim}
%% Nats.sdf
module Nats

imports basic/Whitespace

exports
  context-free start-symbols Nat-con
  sorts Nat-con

  lexical syntax
    [0-9]+ -> Nat-con 

hiddens
  variables
    "Char+"[0-9]* -> CHAR+

%% Nats.asf
equations

  [1] nat-con(Char+) = nat-con(Char+ "a")  
\end{verbatim}
\end{IncCode}
\caption{Illegal use of lexical constructor functions}
\end{Label}
\end{figure}    

\subsubsection{Default Equations}
\label{DefaultEquations}

\index{default equations@default equations}
The evaluation strategy for normalizing terms given the equations is
based on innermost rewriting. All equations have the same priority.
Given the outermost function symbol of a redex the set of equations with
this outermost function symbol in the left-hand side is selected and all
these rules will be tried.  However, sometimes a specification writer
would like to write down a rule with a special status ``{\em try this rule
if all other rules fail}''.  A kind of default behaviour is needed. ASF
offers functionality in order to obtain this behaviour. If the $TagId$
of an equation starts with {\tt default-} this equation is considered to
be a special equation which will only be applied if no other rule matches.
The specification \link*{below}[in Figure~\Ref]{CODE:types} shows
an example of the use of a default equation.

\begin{figure}
\begin{Label}{CODE:types}
\begin{IncCode}
\begin{verbatim}
%% Types.sdf
module Types

imports basic/Whitespace
imports basic/Booleans

exports
  context-free start-symbols Type
  sorts Type

  context-free syntax
    "natural"     -> Type
    "string"      -> Type
    "nil-type"    -> Type
    compatible(Type, Type) -> Boolean

hiddens
  variables
    "Type"[0-9]*  -> Type

%% Types.asf
equations

  [Type-1]  compatible(natural, natural) = true

  [Type-2]  compatible(string, string) = true

  [default-Type] compatible(Type1,Type2) = false
\end{verbatim}
\end{IncCode}
\caption{Using a default equation}
\end{Label}
\end{figure}   

\subsubsection{Memo Functions}
\label{MemoFunctions}

\index{memo functions@memo functions} 

Computations may contain unnecessary repetitions.  This is the case when a
function with the same argument values is computed more than once.  Memo
functions exploit this behaviour and can improve the efficiency of ASF+SDF 
specifications.

Given a set of argument values for some function the normal form can be
obtained via rewriting. It is possible that some function is called with the
same set of arguments over and over again. Each time the function is rewritten
to obtain the same normal again. By means of adding the {\tt memo} attribute,
this behaviour is improved by storing the set of argument values and the
derived normal form in a memo-table.  For each set of argument values it is
checked whether there exists a normal form in the memo-table. If so, this
normal form is returned.  If not, the function given this set of argument
values is normalized and stored in the memo-table.
There is some overhead involved in accessing the memo-table.  Therefore,
it is not wise to add the memo attribute to each function.  With respect
to the operational behaviour adding a memo attribute does not have any
effect.

The Fibonacci function shown \link*{below}[in Figure~\Ref]{CODE:fib}
is decorated with the memo attribute to improve its efficiency.

\begin{figure}
\begin{Label}{CODE:fib}
\begin{IncCode}
\begin{verbatim}
%% Fib.sdf
module Fib

imports basic/Whitespace

exports
  context-free start-symbols Int
  sorts Int

  context-free syntax
    "0"             -> Int
    "s" "(" Int ")" -> Int

  context-free syntax
    add(Int, Int) -> Int

    fib(Int)      -> Int {memo}

hiddens
  variables
    [xy][0-9]* -> Int

%% Fib.asf
equations

  [add-s] add(s(x), y) = s(add(x, y))
  [add-z] add(0, y) = y

  [fib-z] fib(0) = s(0)
  [fib-o] fib(s(0)) = s(0)
  [fib-x] fib(s(s(x))) = add(fib(s(x)), fib(x))

\end{verbatim}
\end{IncCode}
\caption{Using the memo attribute when defining Fibonacci}
\end{Label}
\end{figure}   

The resulting improvement in performance is shown
\T in Table~\ref{TABLE:fibn}.
\W as follows:

\begin{table}
\begin{center}
\begin{Label}{TABLE:fibn}

\begin{tabular}{|l|c|c|} \hline
fib(n) & Time without memo (sec) & Time with memo (sec) \\ \hline \hline
fib(16)          & \ 2.0 & 0.7  \\ \hline
fib(17)          & \ 3.5 & 1.1  \\ \hline
fib(18)          & \ 5.9 & 1.8  \\ \hline
fib(19)          &  10.4 & 3.3  \\ \hline
\end{tabular}
\caption{Execution times for the evaluation of $\mbox{\em fib}(n)$}

\end{Label}
\end{center}
\end{table}



%%\subsubsection{Delaying} \label{Delay}
%%
%%Both the compiler and the evaluator are based on innermost rewriting.
%%In some cases it is more efficient to overrule this rewriting
%%strategy. The disadvantage of innermost rewriting are redundant work
%%in some cases and in some cases even non-termination. An example
%%of the first point and indirectly of the second point is the
%%evaluation of a conditional (see Figure~\ref{CODE:conditional}), 
%%using innermost rewriting the evaluation of an conditional 
%%amounts to evaluating the expression, then part, and else part, independent
%%of the result of the evaluation of the expression.
%%
%%\begin{figure}
%%\label{CODE:conditional}
%%\begin{IncCode}
%%\begin{verbatim}
%%module Conditional
%%
%%imports Layout Expr Booleans
%%
%%exports
%%  context-free syntax
%%    "if" Bool "then" Expr "else" Expr "fi" -> Expr
%%
%%hiddens
%%  variables
%%    "Bool"[0-9]* -> Bool
%%    "Expr"[0-9]* -> Expr
%%
%%equations
%%
%%  [if-t] if true then Expr1 else Expr2 fi = Expr1
%%  [if-f] if false then Expr1 else Expr2 fi = Expr2
%%\end{verbatim}
%%\end{IncCode}
%%\caption{Equations for conditions}
%%\end{figure}   

%%\subsubsection{Getters and Setters Functions}
%%\label{GettersSetters}
%%
%%\index{getter functions@getter functions}
%%\index{setter functions@setter functions}

\subsubsection{Traversal Functions}
\label{Traversal}

\index{traversal functions@traversal functions}
\index{accumulator@accumulator}
\index{transformer@transformer}
Program analysis and program transformation usually take the syntax
tree of a program as starting point.  One common
problem that one encounters is how to express the \emph{traversal} of
the tree: visit all the nodes of the tree and extract information from
some nodes or make changes to certain other nodes.

The kinds of nodes that may appear in a program's syntax tree are
determined by the grammar of the language the program is written
in. Typically, each rule in the grammar corresponds to a node category
in the syntax tree. Real-life languages are described by grammars which
can easily contain several hundred, if not thousands of grammar rules.
This immediately reveals a hurdle for writing tree traversals: a naive
recursive traversal function should consider many node categories and
the size of its definition will grow accordingly.  This becomes even
more dramatic if we realize that the traversal function will only do
some real work (apart from traversing) for very few node categories.

Traversal functions in \asfsdf~\cite{BKV03} solve this problem.
We distinguish three kinds of traversal functions, defined as follows.

\begin{description}

\item[Transformer:] a sort-preserving transformation that 
will traverse its first argument. Possible extra arguments may contain
additional data that can be used (but not modified) during the traversal.
A transformer is declared as follows:

\[f(S_1 , ..., S_n) \rightarrow S_1 \mbox{\tt \{traversal(trafo, ...)\}}\]

Because a transformer always returns the same sort, it is type-safe. A
transformer is used to transform a tree.

\item[Accumulator:] a mapping of all node types to a single type. 
It will traverse its first argument, while the second
argument keeps the accumulated value. An accumulator is declared as follows:

\[f(S_1 , S_2 , ..., S_n) \rightarrow S_2 \mbox{\tt \{traversal(accu, ...)\}}\] 

After each application of an accumulator, the accumulated argument is updated.
The next application of the accumulator, possibly somewhere else in the term,
will use the \emph{new} value of the accumulated argument. In other words,
the accumulator acts as a global, modifiable, state during the traversal.

An accumulator function never changes the tree, only its accumulated argument.
Furthermore, the type of the second argument has to be equal to the result
type. The end-result of an accumulator is the value of the accumulated
argument. By these restrictions, an accumulator is also type-safe for every
instantiation.

An accumulator is meant to be used to extract information from a tree.

\item[Accumulating transformer:] a sort preserving transformation
that accumulates information while traversing its first argument. The
second argument maintains the accumulated value. The return value of
an accumulating transformer is a tuple consisting of the transformed
first argument and accumulated value. An accumulating transformer
is declared as follows:

**** [f(S_1 , S_2 , ..., S_n) \rightarrow <S_1, S_2> \mbox{\{{\tt
traversal(accu, trafo, ...)}\}}\]

An accumulating transformer is used to simultaneously extract information from a
tree and transform it.
\end{description}

Having these three types of traversals, they must be provided with visiting
strategies. Visiting strategies determine the order of traversal and the
``depth'' of the traversal. We provide the following two strategies for each
type of traversal:

\begin{description}
\item[Bottom-up:] the traversal visits \emph{all} the subtrees of a node where
  the visiting function applies in an \emph{bottom-up}\ fashion.  The
  annotation {\tt bottom-up} selects this behavior.  A traversal function without an
  explicit indication of a visiting strategy also uses the bottom-up strategy.
  
\item[Top-down:] the traversal visits the subtrees of a node in an top-down
  fashion and stops recurring at the first node where the visiting function
  applies and does not visit the subtrees of that node. The annotation
  {\tt top-down} selects this behavior.
\end{description}

Beside the three types of traversals and the order of visiting, we can also
influence whether we want to stop or continue at the matching occurrences:
\begin{description}
\item[Break:] the traversal stops at matching occurrences.
\item[Continue:] the traversal continues at matching occurrences.
\end{description}

The visiting strategies in combination with the continuation strategies
is visualized in the \link{``traversal cube''}[, see
Figure~\Ref]{FIG:treetraversals}. The current implementation of the
traversal mechanism only supports the left-to-right visiting strategy.


\begin{figure}
\begin{center}
\begin{Label}{FIG:treetraversals}
\T \includegraphics[width=8cm]{order}
\W \htmlimage{order.gif}
\caption{The ``traversal cube'': principal ways of traversing a tree}
\end{Label}
\end{center}
\end{figure}


We give two simple examples of traversal functions that are both
based on the \link{tree language}[ defined in
Figure~\Ref]{FIG:tree-language}
that describes binary prefix expressions with natural numbers as leaves.
Examples are {\tt f(0,1)} and {\tt f(g(1,2), h(3,4))}.

\begin{figure}
\begin{Label}{FIG:tree-language}
\begin{IncCode}
\begin{verbatim}
module Tree-syntax

imports basic/Integer
imports basic/Whitespace

exports
  context-free start-symbols Tree
  sorts Tree

  context-free syntax
    Integer       -> Tree
    f(Tree, Tree) -> Tree
    g(Tree, Tree) -> Tree
    h(Tree, Tree) -> Tree
\end{verbatim}
\end{IncCode}
\caption{A simple tree language}
\end{Label}
\end{figure}     


Our \link{first example}[ (Figure~\Ref)]{FIG:inc} 
transforms a given tree into a new tree in which
all numbers have been incremented. 

\begin{figure}
\begin{Label}{FIG:inc}
\begin{IncCode}
\begin{verbatim}
%% Tree-inc.sdf
module Tree-inc
imports Tree-syntax

exports
  context-free syntax
    inc(Tree) -> Tree {traversal(trafo, top-down, continue)}
  
hiddens
  variables
    "N"[0-9]* -> Integer

%% Tree-inc.asf
equations
  [1] inc(N) = N + 1  
\end{verbatim}
\end{IncCode}
\caption{The transformer {\tt inc} increments all numbers in a tree}
\end{Label}
\end{figure}   

Our \link{second example}[ (Figure~\Ref)]{FIG:sum}
computes the sum of all numbers in a tree.
For more examples and a detailed description of traversal functions
see~\cite{BKV01}.

\begin{figure}
\begin{Label}{FIG:sum} 
\begin{IncCode}
\begin{verbatim}
%% Tree-sum.sdf
module Tree-sum
imports Tree-syntax
exports
  context-free syntax
    sum(Tree, Integer) -> Integer {traversal(accu, top-down, continue)}
  
hiddens
  variables
    "N"[0-9]* -> Integer

%% Tree-inc.asf
equations
  [1] sum(N1, N2) = N1 + N2
\end{verbatim}
\end{IncCode}
\caption{The accumulator {\tt sum} that sums all numbers in a tree.}
\end{Label}
\end{figure}   

The SDF definition of a traversal function has to fulfill a number of 
requirements:
\begin{itemize}
\item Traversal functions can only be defined in the context-free syntax
section.
\item Traversal functions must be \link{prefix functions}[, see Section
\Ref]{PrefixFunctions}.
\item The first argument of the prefix function is always a sort of a node
of the tree that is traversed, for both accumulating as well as
transformation functions.
\item In case of a transformation function the result sort should always
be same as the sort of the first argument.
\begin{verbatim}
tf(Tree, A_1, ..., A_n) -> Tree {traversal(trafo, ...)}
\end{verbatim}
\item In case of an accumulating function, the second argument represents
the accumulator and the result sort should be of the same sort.
\begin{verbatim}
tf(Tree, Accu, A_1, ..., A_n) -> Accu {traversal(accu, ...)}
\end{verbatim}
\item In case of an accumulating transformation function, the first
argument
represents the tree node, the second the accumulator, and the result sort
should be a tuple consisting of the tree node sort (first element
of the tuple) and the accumulator (second element of the tuple).
\begin{verbatim}
tf(Tree, Accu, A_1, ..., A_n) -> <Tree, Accu> {traversal(accu, trafo, ...)}
\end{verbatim}
\item The traversal functions may have more arguments, the only restriction
is that they should be consistent over the various occurrences of the
same traversal function.
\begin{verbatim}
tf(Tree1, Accu, A_1, A_2, ..., A_n) -> Tree1 {traversal(trafo, continue, top-down)}
tf(Tree2, Accu, A_2, A_1, ..., A_n) -> Tree2 {traversal(trafo, continue, top-down)}
\end{verbatim}
\item The order of the traversal attributes is free, but should be used
consistently, for instance the following definition is not allowed.
\begin{verbatim}
tf(Tree1, Accu, A_1, ..., A_n) -> Tree1 {traversal(trafo, top-down, continue)}
tf(Tree2, Accu, A_1, ..., A_n) -> Tree2 {traversal(trafo, continue, top-down)}
\end{verbatim}
\item If the number of arguments of the traversal function changes, you
should introduce a new function name. The following definitions are not
correct:
\begin{verbatim}
tf(Tree1, Accu, A_1, A_2) -> Tree1 {traversal(trafo, top-down, continue)}
tf(Tree2, Accu, A_1, A_2, A_3) -> Tree2 {traversal(trafo, continue, top-down)}
\end{verbatim}
but should be:
\begin{verbatim}
tf1(Tree1, Accu, A_1, A_2) -> Tree1 {traversal(trafo, top-down, continue)}
tf2(Tree2, Accu, A_1, A_2, A_3) -> Tree2 {traversal(trafo, continue, top-down)}
\end{verbatim}

\end{itemize}
In the SDF part of a module it is needed to define traversal functions
for all sorts which are needed in the equations. 

\subsubsection{Which Specifications are Executable?}

Which ASF+SDF specifications can be executed? 
The \link{specification of sets}[ in
Figure~\Ref]{CODE:itemsets} 
illustrates a non-executable specification,
since equation {\tt [2]}, which expresses that two elements in a set may
be exchanged, will lead to an infinite rewriting loop.

\begin{figure}
\begin{Label}{CODE:itemsets}
\begin{IncCode}
\begin{verbatim}
%% ItemSet.sdf
module ItemSet

imports basic/Whitespace

exports
  context-free start-symbols Set
  sorts Item Set 

  lexical syntax
    [a-z]+ -> Item 

  context-free syntax
    Set[Item] -> Set

hiddens
  variables
    "i"[0-9]* -> Item
    "l"[0-9]* -> {Item ","}* 

%% ItemSet.asf
equations

  [1] {l1, i, l2, i, l3}   = {l1, i, l2, l3} 
  [2] {l1, i1, l2, i2, l3} = {l1, i2, l2, i1, l3}
\end{verbatim}
\end{IncCode}
\caption{Non-executable specification for sets}
\end{Label}
\end{figure}   

\subsubsection{Common Errors when Executing Specifications}

\begin{itemize}

\item When using the inequality operator {\tt !=} in a condition,
no new variables may be introduced in either side of the inequality.

\item If the normal form of a term still contains function symbols
that should have been removed during rewriting, you probably have
forgotten one or more equations that define the function.
A typical situation is that you have given an \emph{incomplete} set of equations
defining the function.

\item The rewriting process does not stop. Your equations probably contain
an infinite loop.

\item Be careful when a condition contains both instantiated and 
uninstantiated variables.

\end{itemize}


\subsection{Tests}

-->
</article>