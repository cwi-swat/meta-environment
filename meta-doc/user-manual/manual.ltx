%{{{ LaTeX configuration

% vim:ts=4:sw=4:tw=75
\documentclass[a4paper,twoside]{article}

%\usepackage{fullpage}
\usepackage{a4wide}
\usepackage{verbatim}
\usepackage{makeidx}
\usepackage{epsfig}

\makeindex

\newcommand{\ASmetaenv}{{\sc Asf}+{\sc Sdf} Meta-En\-vir\-on\-ment}
\newcommand{\sdf}{{\sc Sdf}}
\newcommand{\asf}{{\sc Asf}}
\newcommand{\asfsdf}{{\sc Asf}+{\sc Sdf}}
\newcommand{\ATerm}{ATerm}
\newcommand{\ATerms}{ATerms}

%% notion of Symbol was changed to AFun, which matches specification.
\newcommand{\Symbol}{AFun}

\newcommand{\ATtrue}{\mbox{\tt ATtrue}}
\newcommand{\ATfalse}{\mbox{\tt ATfalse}}
\newcommand{\main}{\mbox{\tt main}}
\newcommand{\ATinit}{\mbox{\tt ATinit}}
\newcommand{\ATprotect}{\mbox{\tt ATprotect}}
\newcommand{\ATprotectArray}{\mbox{\tt ATprotectArray}}

\newcommand{\toolbus}{\mbox{\tt ToolBus}}

% \example{init.c} will input file "examples/init.c" in verbatim mode.
\newcommand{\example}[1]{
    \noindent
    \hrulefill
    \begin{small}
    \verbatiminput{examples/#1}
    \end{small}
    \hrulefill
}

% NULL
\newcommand{\NULL}{{\tt NULL}}               

% Function definition
\newcommand{\Function}[4]{
    \vspace{0.3cm}
    \noindent
    \framebox[12.6cm][l]{{\bf function:} {\tt #1}} \vspace{0.1cm}\newline
    \label{#1}
    \noindent
    {\bf Summary:\hspace{0.2cm}} #4\newline
    {\bf Declaration:}
        {\tt #2} {\tt #1}({\tt #3});
    \index{#1@{\tt #1}}
}
                                        

% Macro definition
\newcommand{\Macro}[4]{
    \vspace{0.3cm}
    \noindent
    \framebox[12.6cm][l]{{\bf macro:} {\tt #1}} \vspace{0.1cm}\newline
    \label{#1}
    \noindent
    {\bf Summary:\hspace{0.2cm}} #4\newline
    {\bf Declaration:}
        {\tt #2} {\tt #1}({\tt #3})
    \index{#1@{\tt #1}}
}
                        

% Method definition
\newcommand{\Method}[4]{
    \vspace{0.3cm}
    \noindent
    \framebox[12.6cm][l]{{\bf method:} {\tt #1}} \vspace{0.1cm}\newline
    \label{#1}
    \noindent
    {\bf Summary:\hspace{0.2cm}} #4\newline
    {\bf Declaration:}
        {\tt #2} {\tt #1}({\tt #3});
    \index{#1@{\tt #1}}
}

% Throws exception (optional)
\newcommand{\Throws}[2]{

\noindent{\bf Throws:} {\tt #1} #2
}                  

% Function/Macro/Method description (optional)
\newcommand{\Describe}[1]{

    \noindent{\bf Description:} #1
}

\def\aterms{\mbox{ATerms}}
\def\aterm{\mbox{ATerm}}
\def\asfix{\mbox{\sc AsFix}}

%}}}
%{{{ Title page and table of contents

%----[ TITLE PAGE ]----           
\title{\ASmetaenv\ User Manual}
\author{All\\
        {\small\sl Centrum voor Wiskunde en Informatica (CWI),}\\
{\small\sl Kruislaan 413, 1098 SJ Amsterdam, The Netherlands}}

\date{}
\begin{document}
\maketitle    

\begin{abstract}
This is a preliminary user manual for the \ASmetaenv\ Release 1.
This is work under construction.
\end{abstract}

\tableofcontents
\newpage

%}}}

%{{{ Overview

%---- [ OVERVIEW ]---- 

\section{Overview}\label{overview} 

\subsection{When to use the ASF+SDF Meta-Environment?}

The ASF+SDF Meta-Environment is an interactive development environment
for the automatic generation of interactive systems for manipulating
programs, specifications, or other texts written in a formal
language. The generation process is controlled by a definition of the
target language, which typically includes such features as syntax,
pretty printing, type checking and execution of programs in the target
language. The ASF+SDF Meta-environment can help you if:

\begin{itemize}

  \item You have to write a formal specification for some problem
  and you need interactive support to do this.

  \item You have developed your own (application) language and want to
  create an interactive environment for it.

  \item You have programs in some existing programming language and you
   want to analyze or transform them.
\end{itemize}

The ASF+SDF formalism allows the definition of syntactic as well as
semantic issues. It can be used for the definition of languages (for
programming, for writing specifications, for querying databases, for
text processing, or for dedicated applications). In addition it can be
used for the formal specification of a wide variety of
problems. ASF+SDF provides you with:

\begin{itemize}

  \item A general-purpose algebraic specification formalism based on equational logic. 

  \item Modular structuring of specifications.

  \item Integrated definition of lexical, context-free and abstract syntax. 

  \item User-defined syntax, allowing you to write specifications using your own notation. 

  \item Complete integration of the definition of syntax and
  semantics.

\end{itemize}

The ASF+SDF Meta-environment offers: 

\begin{itemize}

  \item Syntax-directed editing of ASF+SDF specifications.

  \item Incremental compilation and testing of specifications.

  \item Compilation of ASF+SDF specifications into dedicated
interactive environments containing various tools such as a lexical
analyzer, a parser, a pretty printer, a syntax-directed editor, a
debugger, and an interpreter or compiler.

\end{itemize}

The advantages of creating interactive environments in this way are twofold:

\begin{itemize}

  \item \emph{Increased uniformity}. Similar tools for different
  languages often suffer from a lack of uniformity.  Generating tools
  from language definitions will result in a large increase in
  uniformity, with corresponding benefits for the user.

  \item \emph{Reduced implementation effort.} Preparing a language
  definition requires significantly less effort than developing an
  environment from scratch.

\end{itemize}

\subsection{Global Structure of the Meta-Environment}

You can create new specifications or modify and test existing ones
using the Meta-Environment. Specifications consist of a series of
modules, and individual modules can be edited by invoking a module
editor. All editing in the Meta-environment is done by creating
instances of a \emph{generic syntax-directed editor}.

After each editing operation on a module its \emph{implementation} is updated
immediately. It consists of a lexical scanner, a parser, a pretty
printer, and a term rewriting system which are all derived from the
module automatically.

A module can be tested by invoking a \emph{term editor} to create and
evaluate terms defined by the module. Term editors use the syntax of
the module for parsing the textual representation of terms and for
converting them to internal format (abstract syntax trees). The
equations of the module are then used to reduce the terms into normal
form. This result is, in its turn, converted back to textual form by
pretty printing it.

%%The reduction of a term can be monitored by using EDB (Equation
%%Debugger), a debugging system that allows you to reduce a term
%%step-by-step or to place breakpoints for interrupting the reduction
%%process at specific moments.

Finally, term editors can be customized by adding \emph{buttons} whose
activation starts the evaluation of a function which is defined in the
specification. In this way you can customize the user-interface of the
application by adding, for instance, a typechecking or evaluation
button to a term editor. (** check; not in Release 1.**)

\subsection{About this Manual}

This manual is intended for those courageous users that want to try
out the new brand new implementation of the \ASmetaenv. This manual is
still under development and we welcome all feed back and comments.

%%In the sequel we will use \ASmetaenv\ to address the new
%%system and old \ASmetaenv\ when addressing the old system.

The focus in this manual will be on using the system to write a
specification like a type checker or evaluator for the toy language
PICO. It follows the user-interface to explain the capabilities of the
system.  Topics that will be addressed include:
\begin{itemize}
\item How to start the system, and how to leave it.
\item How to create, open and save a specification.
\item How to edit the syntax and/or equations part of a module.
\item How to edit a term.
\item How to evaluate a term.
\item How to compile a specification.
\item How to parse a term outside the \ASmetaenv.
\item How to rewrite a term using a compiled specification outside the
\ASmetaenv.
\item How to unparse parse and/or normalized terms.
\end{itemize}

\noindent We do \emph{not} explain:

\begin{itemize}
\item The formalism \asfsdf. We do, however, provide a quick introduction
to \asfsdf\ in Section~\ref{ASF+SDF}.
\item The architectural and implementational aspects of the system.
\item The stand alone usage of various parts of he system.
\end{itemize}

\subsection{Further Reading}
(** To be done **)

\section{Starting the System}

The \ASmetaenv\ can be invoked via the command {\tt meta}.  As a
result, the \ASmetaenv\ main window pops up. This is shown in
Figure~\ref{FIG:meta-start}.


The {\tt meta} command has the following options, which may come in
handy later on.

\begin{itemize}

\item {\tt -c \emph{dir}} instructs the \asfsdf\ compiler to generate
C files in the directory \emph{dir}. Note that this directory is also
controlled by the environment {\tt COMPILER\_OUTPUT}

\item {\tt -d} starts the \ASmetaenv\ in debug mode. As a result,
an interactive viewer (``ToolBus viewer'') will be started that allows the study of
the internal behaviour of the system.

\item {\tt -h } shows help information for the {\tt meta} command.

\item {\tt -T \emph{port}} controls the communication ports that will
be used for communication between the components of the \ASmetaenv.
Note that these ports are also controlled by the environment variable
{\tt TB\_PORT}.  The default value is {\tt 8999}, but this port may be
in use by someone else (or by a aborted previous run of the
\ASmetaenv). In that case, it is advisable to use other value in the
range 9000 and up.

\item {\tt -v} runs the \ASmetaenv\ in verbose mode.

\item {\tt -V} shows the version number of the \ASmetaenv\ you are running.

\end{itemize}

Search paths can initialized via creating a file ``meta.conf''. This file
may contain a list of absolute and/or relative paths. See the meta.conf
file in the demo directory for an example. (**)

\begin{figure}[tb]

  \centerline{\epsfig{file=meta-start.ps,width=12cm}}
  \caption{\label{FIG:meta-start} Main window of \ASmetaenv}

\end{figure}

\section{The Main Window} \label{MainWindow}

The main window of \ASmetaenv\ immediately after starting of the
system was already shown in Figure~\ref{FIG:meta-start}.  After
loading a specification it may look like Figure~\ref{FIG:meta-pico}.
The main window of the consists of the following parts:

\begin{itemize}
\item At the top of the window is a menu bar that contains the following menus:
  \begin{itemize}

   \item {\tt File}: for creating, opening, saving and printing
    specifications as well as for leaving the \ASmetaenv.
    The {\tt File} menu is described in Section~\ref{FileMenu}.

   \item {\tt Edit}: for cut, copy, paste style editing and for setting user
      preferences.
      The {\tt Edit} menu is described in Section~\ref{EditMenu}.

   \item {\tt Graph}: for setting options for the display of 
        the graph in the import pane (see below).
       The {\tt Graph} menu is described in Section~\ref{GraphMenu}.

   \item {\tt Debug}: for turning on/off the display of diagnostic messages.
    The {\tt Debug} menu is described in Section~\ref{DebugMenu}.

   \item {\tt Help} for various forms of information and online help.
    The {\tt Help} menu is described in Section~\ref{HelpMenu}.

  \end{itemize}

\item The \emph{import pane}: A graphical canvas (empty in
Figure~\ref{FIG:meta-start}) at the left hand side of the window that
shows the import graph of the specification you are editing.  The
import pane is described in Section~\ref{ImportPane}.

\item The \emph{module pane}: a vertical list (empty in
Figure~\ref{FIG:meta-start}) at the right/middle part of the window
that shows the names of all modules in the current specification.  The
module pane is described in Section~\ref{ModulePane}.

\item The \emph{button pane}: vertical row of buttons at the right
hand side of the window: they are used for common operations on the
current specification like editing, saving or deleting a module, or
compiling the complete specification. The button pane is described
in Section~\ref{ButtonPane}.

\item A status bar at the bottom of the window that shows the current
activity of the system.

\end{itemize}

\begin{figure}[t]
  \centerline{\epsfig{file=meta-pico.ps,width=10cm,angle=-90}}
  \caption{\label{FIG:meta-pico} Main window after loading the Pico specification}
\end{figure}

\section{The Menus of the Main Window}
 
\subsection{The File menu} \label{FileMenu}

\begin{figure}[t]
  \centerline{\epsfig{file=file-menu.ps,width=3cm}}
  \caption{\label{FIG:file-menu} File pull-down menu of \ASmetaenv}
\end{figure}

The {\tt File} menu is used for creating, opening, saving and printing
specifications as well as for leaving the \ASmetaenv.  It is shown in
Figure \ref{FIG:file-menu}.

{\tt New}, {\tt Open} and {\tt Save} are used for creating
a new module, opening an existing one, respectively, saving a module.
In all three cases a dialog window appears as shown in
Figure~\ref{FIG:open-file}.

{\tt Clear} removes all modules that have been opened so far from the
Meta-Environment. If modules have been modified, you are expicitly
asked to save them. he same effect can be achieved by leaving the
Meta-Environment (using {\tt Quit}, see below) and starting a new
version of the Meta-Environment using the {\tt meta} command.

{\tt Revert} (**)

{\tt Export} allows the export of the import pane in various graphical
formats.  {\tt Print Setup} allows the customization of the command
used for printing.  Its dialog window is shown in
Figure~\ref{FIG:printer-setup}.  {\tt Print} print the current import
pane.

The entry {\tt Quit} ends the execution of the \ASmetaenv.

\begin{figure}[t]
  \centerline{\epsfig{file=printer-setup.ps,width=3cm}}
  \caption{\label{FIG:printer-setup} Dialog for printer setup}
\end{figure}



\begin{figure}[t]
  \centerline{\epsfig{file=open-file.ps,width=8cm}}
  \caption{\label{FIG:open-file} Open module dialog}
\end{figure}

\subsection{The Edit menu} \label{EditMenu}

\begin{itemize}
\item {\tt Undo}
\item {\tt Copy}
\item {\tt Paste}
\item {\tt Preferences}
\end{itemize}

\subsection{The Graph Menu} \label{GraphMenu}

\begin{figure}[t]
  \centerline{\epsfig{file=graph-menu.ps,width=4cm}}
  \caption{\label{FIG:graph-menu} Graph pull-down menu of \ASmetaenv}
\end{figure}


The {\tt Graph} menu is used for setting options for the display of the graph
in the import pane.  It is shown in Figure \ref{FIG:graph-menu} and contains
the entries:

\begin{itemize}
\item {\tt View All}
\item {\tt Autoresize after loading}
\item {\tt Animate while loading}
\end{itemize}

\subsection{The Debug Menu} \label{DebugMenu}

\begin{figure}[t]
  \centerline{\epsfig{file=debug-menu.ps,width=4cm}}
  \caption{\label{FIG:debug-menu}The Debug  Menu}
\end{figure}

The {\tt Debug} menu is shown in Figure~\ref{FIG:debug-menu} and contains the
single check box {\tt Diagnostic messages}.  When turned on, diagnostic
messages will be displayed.  Otherwise the systems runs silently.

\subsection{The Help Menu} \label{HelpMenu}

\begin{figure}[t]
  \centerline{\epsfig{file=help-menu.ps,width=5cm}}
  \caption{\label{FIG:help-menu}The Help  Menu}
\end{figure}

The {\tt Help} menu is shown in Figure~\ref{FIG:help-menu}
and contains the following entries:

\begin{itemize}
\item {\tt About NewMeta}
\item {\tt Meta-Environment}
\item {\tt Mouse operations}
\item {\tt Online help}
\end{itemize}

\section{The Panes of the Main Window}

The two left-most panes of the main window give two, alternative,
views on the same information: the \asfsdf\ specification that has
been loaded into the Meta-Environment.  Using one of these views, the
same set of operations is available either via a pop menu or via the
buttons in the pane at the right-hand side of the main window.

\subsection{The Import Pane} \label{ImportPane}

The \emph{import pane} gives a graphical view of the specification by
displaying the \emph{import} relation between modules in the form of a
graph. A module $M_1$ imports another module $M_2$ if $M_1$ contains
an import statement of the form {\tt imports $M_2$}.

Each module is represented by a circle and an arrow between two
circles represents an import relation between the two corresponding
modules.

The import pane has the following interaction facilities:

\begin{itemize}

\item Clicking \emph{on} a module yields a pop up menu as shown in
Figure~ref{FIG:module-menu}.  It contains the same entries as the
button pane of the main window (see Section \ref{ButtonPane}).

\item Clicking \emph{outside} any module yields a pop up menu as shown
in Figure~\ref{FIG:new-open}.  It contains the entries {\tt New} and
{\tt Open} for creating a new, respectively, opening an existing
module. These two operations are also available from the {\tt File}
menu (see Section~\ref{FileMenu}).

\end{itemize}

\begin{figure}[t]
  \centerline{\epsfig{file=module-menu.ps,width=3cm}}
  \caption{\label{FIG:module-menu}Pop up menu for module operations}
\end{figure}

\begin{figure}[t]
  \centerline{\epsfig{file=new-open.ps,width=2cm}}
  \caption{\label{FIG:new-open}Pop up menu for adding a module}
\end{figure}


\subsection{The Module Pane} \label{ModulePane}

The import pane is particularly usefull when you want to understand the
overall structure of a specification but it may become unwieldy for
very large specifications. For large specifications the module pane
may give you quicker access to the modules in the specification.
It presents a vertical, scrollable, list of the names of all the modules in
the specification.

The main purpose of the module pane is to select one or modeles from
the specification on which an operation from the button pane is to be
performed.  One module is selected by clicking on the corresponding
module name in the module pane.  More than one module can be selected
by clicking on a module name, keeping the mouse button down and and
then dragging the mouse to the last desired module name.
Note that only consecutive modules can be selected.

After making the selection, an operation can be performed on all the
selected modules by pushing a button from the button pane.  For
instance, pushing the {\tt Edit Sdf2} button will create editors for
the syntax of all the selected modules.

\subsection{The Button Pane of the Main Window} \label{ButtonPane}

  \begin{itemize}
  \item {\tt Edit Sdf2}
  \item {\tt Edit Eqs}
  \item {\tt Term}
  \item {\tt Save}
  \item {\tt Revert}
  \item {\tt Delete}
  \item {\tt Info}
  \item {\tt Compile}
  \end{itemize}

\section{Editing Specifications}

\subsection{Editing the syntax part of a module}

\subsection{Editing the equations of a module}

\subsection{Editing terms}

\section{Executing Specifications}

\subsection{Evaluating terms}

\subsection{Compiling a specification}

\section{Guided Tour}

\begin{figure}[t]
  \centerline{\epsfig{file=meta-booleans.ps,width=12cm}}
  \caption{\label{FIG:meta-booleans}Main window after opening {\tt Pico-Booleans}}
\end{figure}

To help you to get acquainted with the ASF+SDF Meta-environment the system
comprises two example specifications, namely the one-module specification:
{\tt Bool-example}, and the specification of the syntax, typechecker and dynamic
semantics of the small programming language Pico.

This Guided Tour is meant to guide you through these specifications, and show
you the main features of the ASF+SDF Meta-environment. Only global information
is given about these features but references are made to parts of the
user-manual with detailed information.

\subsection{Before you start the Guided Tour}

The Meta-Environment is usually installed in a directory named {\tt
  meta-$version$}. For Release 1, this may, for instance, be {\tt meta-1.0.0}.
You will then find the files needed for this Guided Tour in the directory {\tt
  meta-1.0.0/demo/pico}. It is advisable to make your personal copy of this
directory.  In this Guided Tour we will use `{\tt pico}' to refer to your own
copy of the directory.

For each module in a specification two files exist: `{\tt $module$.sdf2}'
\footnote{In the current version the extension is `{\tt sdf2}' ; should this
  not be changed to `{\tt .syn}'?}  contains the syntax of $module$ and `{\tt
  $module$.eqs}' contains the semantics (equations) of $module$. The directory
pico contains:

\begin{itemize}

\item two files for the module {\tt Bool-example}.

\item files for the Pico-specification.

\item three examples of Pico-programs: `{\tt big.pico}', `{\tt fac.pico}',
  `{\tt small.pico}'.

\item terms for typechecking and evaluating these Pico-programs.

\end{itemize}

\subsection{Beginning the Guided Tour}

\begin{itemize}

\item Go to directory pico. 
\item Type the command {\tt meta}. The main window of the Meta-environment
  will appear as shown in Figure~\ref{FIG:meta-start}.
  
\item Add the module {\tt Bool-example} by selecting the File menu, and
  choosing the Open button. In a dialog window, the system asks you to give
  the name of the module to be opened. It presents a list of all files with
  extension `{\tt sdf2}'. Click once on `{\tt Bool-example.sdf2}' and then
  push the {\tt Open} button. This will load the module {\tt Module-example}
  (both its syntax and equations!) into the system
\footnote{*** Strictly speaking this is strange; it would be better to only
display module names without any extension.}
  
\item Verify that module {\tt Bool-example} appears as a rectangle in
the import pane as well as in the module pane of the main window as
shown in Figure~\ref{FIG:meta-Bool-example}.

\end{itemize}

\begin{figure}[t]
  \centerline{\epsfig{file=meta-Bool-example.ps,width=12cm}}
  \caption{\label{FIG:meta-Bool-example}Main window after opening {\tt Bool-example}}
\end{figure}

\subsection{The Module Bool-example}

One of the simplest specifications possible, and therefore frequently used as
an example, is the datatype of the Boolean values. It defines the constants
{\tt true} and {\tt false} and the functions \emph{and} and \emph{or}
 (written in infix notation using
the left-associative operators `{\tt \&}' and `{\tt |}', respectively) and
\emph{not} (written
in prefix notation using the function symbol `{\tt not}'). Here is the
specification:

\begin{verbatim}
module Bool-example
  exports
    sorts BOOL 
    lexical syntax
      [\ \t\n]           -> LAYOUT

    context-free syntax
      "true"             -> BOOL
      "false"            -> BOOL 
      BOOL "|" BOOL      -> BOOL {left}
      BOOL "&" BOOL      -> BOOL {left}
      "not" "(" BOOL ")" -> BOOL
      "(" BOOL ")"       -> BOOL {bracket}

    variables
      "Bool"[0-9\']* -> BOOL

    context-free priorities
      BOOL "&" BOOL -> BOOL >
      BOOL "|" BOOL -> BOOL

    equations

    [B1] true | Bool = true 
    [B2] false | Bool = Bool

    [B3] true & Bool = Bool 
    [B4] false & Bool = false

    [B5] not(false) = true 
    [B6] not(true) = false

\end{verbatim}

\begin{figure}[t]
  \centerline{\epsfig{file=Bool-example.sdf2.ps,width=12cm}}
  \caption{\label{FIG:Bool-example.sdf2}Editor for the syntax of {\tt Bool-example}}
\end{figure}

\begin{figure}[t]
  \centerline{\epsfig{file=Bool-example.eqs.ps,width=12cm}}
  \caption{\label{FIG:Bool-example.eqs}Editor for the equations of {\tt Bool-example}}
\end{figure}

\subsubsection{The module editor for {\tt Bool-example}}

\begin{itemize}
  
\item Select module {\tt Bool-example} from the module pane (the vertical list
  of module names that now only contains {\tt Bool-example}) by clicking on it
  once.
  
\item Push the button {\tt Edit Sdf2} in the button pane at the right-hand
  side of the main window.  An editor will appear containing the syntax part
  of the {\tt Bool-example} specification: the SDF section.  This editor is a
  version of the standard text editor Emacs extended with the menu {\tt
    Meta-Environment}. The result is shown in Figure~\ref{FIG:Bool-example.sdf2}.
  
\item Push the button {\tt Edit Eqs}.  This will reuse the already created
  instance of Emacs by adding a new buffer to it containing the semantic part
  of the {\tt Bool-example} specification: a list of conditional equations.
  Note that the syntax of the equations is determined by the syntax defined in
  the SDF section. Use the {\tt Buffers} menu of Emacs to see which buffers
  are open and to switch between buffers.
The result is shown in Figure~\ref{FIG:Bool-example.eqs}.

\end{itemize}


\begin{figure}[t]
  \centerline{\epsfig{file=Bool-example.trm.ps,width=12cm}}
  \caption{\label{FIG:Bool-example.trm}Term editor for {\tt Bool-example} after entering `{\tt true \& false}'}
\end{figure}

\begin{figure}[t]
  \centerline{\epsfig{file=Bool-example.trm2.ps,width=12cm}}
  \caption{\label{FIG:Bool-example.trm2} Same term editor after parse}
\end{figure}

\begin{figure}[t]
  \centerline{\epsfig{file=Bool-example.trm3.ps,width=12cm}}
  \caption{\label{FIG:Bool-example.trm3}Term editor for {\tt Bool-example} after clicking on `{\tt false}'}
\end{figure}

\subsubsection{A Term Editor for {\tt Bool-example}}

\begin{itemize}
\item Open a term-editor over module {\tt Bool-example} by first selecting
  module {\tt Bool-example} in the module pane, and then pushing the {\tt
    Term} button.  A dialog window pops up\footnote{Why is this note a
    standard file dialog?}
    Enter any new filename, for instance, `{\tt my-term}'.

\item 
  Type the term `{\tt true \& false}' in this editor. Observe how the text
  that you type gets a light blue background.
  This is called a \emph{focus}. The result is shown in Figure~\ref{FIG:Bool-example.trm}.

\item Click in the focus, this will move the cursor (a single character-sized
  red rectangle) 
  
\item From menu {\tt Meta-Envrionment} click the {\tt Parse} button.  The text
  in the focus is now parsed and the blue background has disappeared.
  The result is shown in Figure~\ref{FIG:Bool-example.trm2}.

\end{itemize}

All the text\emph{ outside} the focus is (by definition) always syntactically
correct. The text \emph{inside} the focus is fresh text which may contain syntax
errors.

\begin{itemize}

\item Click on one of the characters of the word `{\tt false}'.  You
have selected `{\tt false}' as new focus and the blue background
reappears. This is shown in Figure~\ref{FIG:Bool-example.trm3}.

\item Click on the \emph{and} operator `{\tt \&}'.  The whole expression is
  now selected as focus.

\end{itemize}

The movements of the focus are \emph{syntax-directed}: when you click on any
character in the text, the smallest syntactic unit enclosing that character
will be selected and becomes the focus.

\begin{itemize}
  
\item Reduce the term in the term-editor by clicking the {\tt Reduce} button
  in the {\tt Meta-Environment} menu of the editor.  The result will appear in
  the terminal window from which the Meta-Environment was started.

\end{itemize}

\paragraph{Error-messages}

\begin{itemize}
  
\item Edit the term `{\tt true \& false}' such that the new term will be
  syntactically incorrect. For instance, type `{\tt true \& wrong}'. Force a
  parse of the term by selecting the {\tt Parse } button of the {\tt
    Meta-Envrionment} menu.
  
  In the status line at the bottom of the edit window a message will appear
  message `{\tt Parse error near cursor}' and the cursor will be positioned in
  the word `{\tt wrong}'

\end{itemize}

\paragraph{Associativity, Priorities and Brackets}

\begin{itemize}
  
\item Erase the term in your term-editor and type a new term `{\tt true \&
    false \& true}'. 

\item Parse the term using the {\tt Parse} button.

\item  Try to find out how this term has been parsed by clicking
  on different parts of the term and studying the resulting focus.

\end{itemize}

The {\tt left} attribute in the SDF definition indicates that the `{\tt \&}'
operator is left associative. The term will thus be parsed as `{\tt (true \&
  false) \& true}'. Clicking on the left or right {\tt \&} yields a focus that
corresponds with this parse.

\begin{itemize}
  
\item Erase the term in your term-window and type a new term `{\tt true |
    false \& true}'. 
\item Parse the term using the {\tt Parse} button.
  
\item Try to find out how this term has been parsed by clicking on various
  parts of the term and studying the resulting focus.

\end{itemize}

The {\tt context-free priorities} definitions in the SDF definition state that the `{\tt
  \&}' operator binds stronger than the `{\tt |}' operator.

\begin{itemize}
  
\item Erase the term in the term-editor and type a new term `{\tt true \&
    false}'.  Click on `false', so that the focus is around `false' only. Then
  add `{\tt | true}' after `{\tt false}', so that the resulting term is `{\tt
    true \& false | true}'.  

\item Parse the term.

\item Click on the `{\tt \&}' symbol. Is this what you wanted? Probably not.
\end{itemize}
  
To resolve a priority conflict `{\tt (}' and `{\tt )}' which are defined as
brackets in the SDF definition are put around the term `{\tt false | true}'.
Thus `{\tt true \& (false | true})' is more likely to express what you
intended.

\subsubsection{Modifying {\tt Bool-example}}

The ASF+SDF Meta-Environment is an \emph{incremental environment generator}. After
each edit operation on a module, its \emph{implementation} (i.e., scanner, parser and
term rewriting system) is updated immediately.

The editing of both the syntax section and the equations secion of a module is
syntax-directed like the editing of terms in a term editor.

\paragraph{Modifying the Equations}

The equation section of a module begins with the keyword {\tt equations}
and is saved in files ending on `{\tt .eqs}'.

\begin{itemize}

\item  Click in the equation section to investigate the focus behavior.
  
\item Change the equations, for instance replace in equation {\tt [B1]} the
  last part `{\tt = true}' by `{\tt = false}'. 
  
\item Study the effect on the reduction of terms in the term-editor.

\end{itemize}

\paragraph{Modifying the Syntax}

The syntax part of a module starts with the keyword {\tt module}
and  is saved in files ending on `{\tt .sdf2}'.
Modifying the syntax causes the generated scanner and parser to be adapted.
After each edit operation in the SDF section that is followed by a parse of
the SDF section, the focus in both the equations section and the term editor
is extended to completely contain the text in these editors.

Modifying the context-free syntax:

\begin{itemize}
  
\item Change the syntax of the defined functions. E.g, replace `{\tt not}' by
  `{\tt negation}'.

\item Try to re-parse the equations. 
  
%%\item Investigate the expand menu in the term-editor. (type `{\tt <BOOL>}' and
%%  select {\tt expand}.)

\end{itemize}

Modifying the priorities: 

\begin{itemize}

\item Remove the priority declaration. 
  
\item Type the term `{\tt true \& false | true}' in the term-editor (or
  anything similar according to your current syntax). Try to parse this term.
\footnote{PROBLEM: there is no feed back here that there is an ambiguity!}

\item Add the priority declarations again.

\end{itemize}

Modifying layout in the lexical section: 

\begin{itemize}

\item Remove the lexical syntax with the {\tt LAYOUT} definitions. 

\item Try parsing equations of {\tt Bool-example}.

\end{itemize}

\paragraph{Note:} Not defining {\tt LAYOUT} is one of the errors most commonly
made when writing a new specification; always make sure your syntax
definitions define at least spaces and newlines to be {\tt LAYOUT}.

\begin{itemize}
  
\item End the editing of your term and the module {\tt Bool-example} by
  selecting the {\tt Exit XEmacs} from the {\tt File} menu of the editor.  You
  may or may not save the changes to module Bool-example.

\end{itemize}

If you save the changes the files `{\tt Bool-example.sdf2}' and `{\tt
  Bool-example.eqs}' will be modified.


\begin{itemize}
  
\item Delete the module {\tt Bool-example} from the specification.  Click on
  {\tt Bool-example} in the module pane and push the {\tt Delete} button. The
  module remains known to the system and its graphical representation is
  changed form a rectangle to an ellipse. It can be re-opened later on.
  
\item Leave the system by pushing the {\tt Quit} entry in the {\tt File} menu
  of the main window of the \ASmetaenv.

\end{itemize}

\begin{figure}[t]

  \centerline{\epsfig{file=meta-Pico-syntax.ps,width=12cm}}
  \caption{\label{FIG:Pico-syntax} Main window after opening {\tt Pico-syntax}}

\end{figure}

\subsection{The Pico Specification}

More features of the  \ASmetaenv\  can be studied by looking at the
Pico specification.


\begin{figure}[t]

  \centerline{\epsfig{file=Pico-Booleans.sdf2.ps,width=12cm}}
  \caption{\label{FIG:Pico-Booleans-sdf2}Editor for syntax of {\tt Pico-Booleans}}

\end{figure}


\begin{figure}[t]

  \centerline{\epsfig{file=Pico-Booleans.eqs.ps,width=12cm}}
  \caption{\label{FIG:Pico-Booleans-eqs}Editor for equations of {\tt Pico-Booleans}}

\end{figure}


\begin{itemize}

\item Open the module {\tt Pico-Booleans} and study the differences in
syntax and equations with {\tt Bool-example}. 

\end{itemize}

Editors for syntax and equations of {\tt Pico-Booleans} are show in
Figures \ref{FIG:Pico-Booleans-sdf2} and \ref{FIG:Pico-Booleans-eqs}.


\begin{itemize}
  
\item Start the Meta-Environment: go to directory {\tt
    pico}, and type `{\tt meta}'.
  
\item Add the module {\tt Pico-syntax} by selecting the {\tt File} menu, and
  choosing the {\tt Open...} button.  In the dialog window that appears, click
  on {\tt Pico-syntax.sdf2} and push the {\tt Open} button.
  
\item As you can see in both the import pane and the module pane, not only
  {\tt Pico-syntax} has been added, but also all modules that are directly or
  transitively imported by {\tt Pico-syntax}. See Figure~\ref{FIG:Pico-syntax}.

\end{itemize}

\subsubsection{The Module Editor for Pico-syntax}

\begin{itemize}
  
\item Open an editor for the syntax of {\tt Pico-syntax} (using the {\tt Edit
    Sdf2} button.

\end{itemize}
  
  A Pico program consist of the word `{\tt begin}', a declaration section, a
  series of zero or more statements, and the word `{\tt end}'. The declaration
  section consists of the word `{\tt declare}', a list of zero or more tuples
  `{\tt $identifier$ : $type$}' and a semi-colon `{\tt ;}'. Types are `{\tt
    string}' and `{\tt natural}'.  There are three kinds of statements:
  assignments, if-then-else statements and while-loops. And there are
  expressions.

\paragraph{Notes:}

\begin{itemize}
  
\item A module{\tt Layout} is imported, in which the sort {\tt LAYOUT} has been
  specified.
  
\item The use of list constructs in the context-free section: `{\tt {-ID-TYPE
      ","}*}' and `{\tt {STATEMENT ","}*}'. In fact, the sort {\tt SERIES}
  could have been left out entirely and be replaced by `{\tt {STATEMENT
      ","}*}' all through the specification. {\tt SERIES} is only used for
  abbreviation in the syntax rules. Also, variables over list constructs are
  being declared.
  
\item When a literal in a context-free function consists only of lower case
  letters and digits, and it is not a SDF-keyword, it need not be quoted.

\item  The Pico-syntax module naturally contains no equations.

\end{itemize}

\subsubsection{A Term Editor for Pico-syntax}

\begin{itemize}
  
\item Open a term-editor for the Pico-program `{\tt small.pico}': select {\tt
    Pico-syntax} in the module pane and push the {\tt term} button in the
  button pane. A dialog window pops up and type `{\tt small.pico}' as name of
  the term.

\item Press the {\tt Parse} button in the {\tt Meta-Environment} menu of the
  editor. As a result, {\tt small.pico} is parsed.

\item Press the {\tt Reduce} button in the {\tt Meta-Environment} menu of the
  editor.

\end{itemize}

This has the following effects:

\begin{itemize}

\item  The term in the editor is parsed. 
  
\item All the equations that are valid for this editor are parsed and compiled
  into a rewrite system.  In this case that means the equations of the
  imported modules {\tt Pico-Booleans}, {\tt Pico-Integers}, {\tt Pico-Strings} and {\tt
    Pico-Types}. This takes some time.
  
\item The term in the editor is reduced. As no equation can be applied to
  reduce this term, the term itself is returned in the shell window from which
  the Meta-Environment has been started.
\end{itemize}

  
Reducing a term for the second time is notably faster: the equations have been
compiled already. If you are curious what is going, have a look at the
status field at the bottom of the main window. It reveals the steps that
are necessary to arrive at an executable specification.

\begin{itemize}
\item Verify this by pushing the {\tt Reduce} button once more.
\end{itemize}

\begin{itemize}

\item Load the module {\tt Pico-typecheck} in the Meta-Environment.

\item Open a term editor for the term {\tt smalltc.pico}.

\item Reduce this term.

\end{itemize}

This has the following effects:

\begin{itemize}

\item  The module {\tt Pico-typecheck} is added to the specification. 
  
\item The term in {\tt smalltc.pico} is identical to the one in {\tt
    small.pico}, except that the program has been surrounded by `{\tt tcp(}
  and `{\tt )}'.  The function {\tt tcp} (for type check program), applies the
  typing rules for the Pico language to its single argument: a complete Pico
  program. The result is {\tt true} or {\tt false}.
  
\item All equations of {\tt Pico-typecheck} and its imported
  modules are being compiled.
  
\item The term {\tt smalltc.pico} is reduced using the equations of {\tt
    Pico-typecheck}.

\end{itemize}
  
Typechecking a term for the second time is notably faster, the
modules have been added already and the equations have been compiled.

\begin{itemize}

\item Verify this, by pushing {\tt Reduce} once more.
  
\item Make some modifications to `{\tt smalltc.pico}' in the term-editor.
  Typecheck the modified program.
  
\item Open term-editors with other pico programs (`{\tt fac.pico}', `{\tt
    big.pico}') or create your own program. The corresponding applications of
  the type check function are in `{\tt factc.pico}', respectively, `{\tt
    bigtc.pico}'.  Typecheck these programs.

\end{itemize}

The evaluation (execution) of programs is achieved in a similar fashion as
typechecking. The evaluation rules are defined in the module `{\tt
  Pico-eval}'. Applications of the evaluation function `{\tt evp}' can be
found in `{\tt smallev.pico}', `{\tt facev.pico}', and `{\tt bigev.pico}.

\begin{itemize}
  
\item Repeat the steps described above for typechecking, now for the
  evaluation of Pico programs.

\end{itemize}

\subsubsection{More Exercises to Study the Pico Specification}

\begin{itemize}

\item Study other modules in the specification. The modules {\tt
    Pico-typecheck} and {\tt  Pico-eval} are explained in the next sections.
  
\item Add a repeat statement `{\tt repeat SERIES until EXP}' to {\tt
    Pico-syntax}, add typecheck equations to {\tt Pico-typecheck}, and
  eval-equations to {\tt Pico-eval}, for this new statement.

\item Add your own module to the specification. 

\item Make your own specification. Create a new directory for each
  specification.

\end{itemize}

\subsubsection{Module Pico-typecheck}

\begin{itemize}

\item Open an editor for the syntax and equations of {\tt Pico-typecheck}.

\end{itemize}

The function `{\tt tcp}' is defined for typechecking Pico-programs.
Variants of this function exist for typechecking various parts of a Pico program. 
The
typechecking of the declarations yields a type-environment: a table of
identifiers and their types. This type-environment, and the `{\tt lookup}'
function is specified in the module {\tt Type-environments}. The typechecking
of statements uses a type-environment and yields a Boolean value.

In the equations is defined how a Pico-program is typechecked. Equation {\tt
  [Tc1]} says that the typechecking of a program is `{\tt true}' if the
typechecking of the Series in the type-environments, `{\tt tcd(Decls)}', is
`{\tt true}'.

Equations {\tt [Tc2]} and {\tt [Tc3]} specify how a type-environment is
constructed, when the declarations are typechecked.

Equations {\tt [Tc3a]} and {\tt [Tc3b]} specify the typechecking of a,
possibly empty, list of statements. Equations {\tt [Tc4a]} through {\tt
  [default-Tc6} specify how the three kinds of Statements are typechecked
using the information from the type-environment.

The rest of the equations deal with the typechecking of expressions.

\subsubsection{Module Pico-eval}

\begin{itemize}

\item Open an editor for the syntax and equations of {\tt Pico-eval}.

\end{itemize}

The functions `{\tt evp}' and variants are defined for describing the dynamic semantics of
Pico. The result of evaluation is a value-environment: a table of identifiers
and values with the final values of the declared identifiers. (Note that Pico
does not have an output-statement.)

In the equations is defined how a program is evaluated. Equation {\tt [Ev1]}
says that the evaluation of a program is the evaluation of the Series in the
value-environments, `{\tt evs(Decls)}'.

Equations {\tt [Ev2]} thorugh {\tt [Ev3c]}  specify how a
value-environment is constructed, when the declarations are evaluated.
Identifiers of type `{\tt natural}' get value `{\tt 0}', Identifiers of type
`{\tt string}' get value `{\tt ""}' (the empty-string).

Equations {\tt [Ev4a]} and {\tt [Ev4b]} specify the evaluation of a, possibly
empty, list of statements. Equations {\tt [Ev5a]} through {\tt [Ev5e]}
specify how the three kinds of statements are
evaluated using the information from the type-environment. Evaluating
statements means updating the value-environment.

The rest of the equations deal with the evaluation of expressions. Evaluating
expressions results in a value.

\section{A quick introduction to ASF+SDF} \label{ASF+SDF}

\paragraph{This whole section is just a conversion
  of text from the old manual; it has to be checked for SDF2 compatibility!}

ASF+SDF is the result of the marriage of two formalisms ASF (Algebraic
Specification Formalism) and SDF (Syntax Definition Formalism). ASF is based
on the notion of a module consisting of a signature defining the abstract
syntax of functions and a set of conditional equations defining their
semantics. Modules can be imported in other modules and can be parameterized.
SDF allows the simultaneous definition of concrete (i.e., lexical and
context-free) and abstract syntax and implicitly defines a translation from
text strings to abstract syntax trees.

The main idea of ASF+SDF is to identify the abstract syntax defined by the
signature in ASF specifications with the abstract syntax defined implicitly by
an SDF specification, thus yielding a standard mapping from text to abstract
syntax tree. This gives the possibility to associate semantics with (the tree
representation of) text and to introduce user-defined notation in
specifications.

ASF+SDF is therefore a modular specification formalism for the integrated
definition of syntax and semantics.

\subsection{Modules and Modular Structure}

An ASF+SDF specification consists of a sequence of module declarations. Each
module may define syntax rules as well as semantic rules and the notation used
in the semantic rules depends on the definition of syntax rules. The entities
declared in a module may be visible or invisible to other modules. A module
can use another module from the specification by importing it. As a result,
all visible names of the imported module become available in the importing
module.

The overall structure of a module is:

\begin{verbatim}

module
   <Name>
imports 
   <Name-of-imported-module>+
 
<Section>*
 
priorities
   <Priority-relation-between-context-free-rules>+

equations
   <Conditional-equation>*
\end{verbatim}

A module consists of a module header, an imports clause followed by a list of zero or more
sections (that define sorts, lexical syntax, context-free syntax and
variables) followed by a priority declaration and conditional
equations. All these parts are optional.

Each \emph{Section} starts with one of the keywords {\tt exports} or {\tt
  hiddens}: {\tt exports} makes all entities in the section visible to other
  modules,{\tt  hiddens} makes all entities in the section local to the module. A Section has the form:

\begin{verbatim}
exports-or-hiddens

  sorts
    Names-of-sorts 
  lexical syntax
    Rules-of-the-lexical-syntax 
  context-free-syntax
    Rules-of-the-context-free-syntax 
  variables
    Names-of-variables

\end{verbatim}
  
  where each of the subsections for sorts, lexical syntax, context-free syntax
  and variables is optional.
  
  Modules can be combined by importing one module in another. As a result all
  exported entities of the imported module (and of all modules that are
  imported indirectly by it) become available in the importing module.

\subsection{Sorts}

A sort is declared by listing its name in a sorts section of a module. A sort
name should start with a capital letter and may be followed by letters and/or
digits. Hyphens (`{\tt -}') and underscores (`{\tt \_}') may be embedded in
sort names. There are four predefined sorts which may not be redeclared:

\begin{itemize}
  
\item {\tt LAYOUT} defines which parts of the text are layout symbols between
  lexical tokens and are to be skipped during lexical analysis. It may only be
  used as result sort of lexical functions. When a string is matched by both a
  LAYOUT function and by other non-LAYOUT functions, then the interpretation
  as layout symbol is ignored. Typically used for defining layout and comment
  conventions.

\item {\tt IGNORE} defines which parts of the text are layout symbols inside lexical tokens and are to be
ignored, i.e. ignored symbols do not contribute to the text of a lexical token. Typically used for defining languages where layout or comment symbols may occur inside lexical tokens.

\item {\tt REJEC}T defines sequences of consecutive lexical tokens that are to be rejected. Typically used to
forbid certain sequences of lexical tokens, like a number immediately followed by an identifier.

\item {\tt CHAR} gives access to the character representation of lexical tokens and may only be used in
declarations of variables.

\end{itemize}

\subsection{Lexical Syntax}

The lexical syntax describes the low level structure of text by means of
\emph{lexical tokens}. A lexical token consists of a sort name (used to
distinguish classes of tokens like identifiers and numbers), and actual text
of the token. The lexical syntax also defines which substrings of the text are
layout symbols or comments and are to be skipped.

A lexical syntax contains a set of declarations for \emph{lexical functions},
each consisting of a regular expression and a result sort. All functions with
the same result sort together define the lexical syntax of tokens of that
sort. Regular expressions may contain strings, sort names, character classes,
or repetition operators. Spaces are only significant inside strings and
character classes.

\subsubsection{Lexical Functions}

In their simplest form, declarations of lexical functions consist of a
sequence of zero or more strings or sort names followed by `{\tt ->}' and the
name of a result sort, say $L$. The regular expression associated with $L$
consists of the \emph{or} of all left-hand sides of lexical functions with
result sort $L$. All sort names appearing in left-hand sides of declarations
are replaced by the regular expression associated with them. Circular
dependencies between declarations in the lexical syntax are forbidden.

For each sort that appears as result sort in the lexical syntax a lexical
constructor function of the form {\tt l "(" CHAR+ ")" -> L} is automatically added
to the context-free syntax of the specification. Here, `{\tt l}' is the name of sort
`{\tt L}' written in lower case letters. In this way, you can get access to the text
of lexical tokens.

5.3.2 Character Classes

Enumerations of characters occur frequently in lexical definitions. They can
be abbreviated by using character classes enclosed by `{\tt [}' and `{\tt
  ]}'. A character class contains a list of zero or more characters (which
stand for themselves) or character ranges such as, for instance, {\tt [0-9]}
as an abbreviation for the characters {\tt 0}, {\tt 1}, ..., {\tt 9}. 
In a character range of the form {\tt $c_1$-$c_2$} one of the following restrictions should apply:

\begin{itemize}
\item $c_1$ and $c_2$ are both lower case letters and $c_2$ follows $c_1$ in
  the alphabet, or 
\item $c_1$ and $c_2$ are both upper case letters and $c_2$ follows $c_1$ in
  the alphabet, or 
\item $c_1$ and $c_2$ are both digits and the numeric value of $c_2$ is
  greater than that of $c_1$, or 
\item $c_1$ and $c_2$ are both escaped non-printable characters and the character code of $c_1$ is larger
than that of $c_2$.
\end{itemize}

By prefixing a character class with `{\tt ~}', it is complemented. Such a
complemented character class accepts all characters not in the original class.

\subsubsection{Escape Conventions}

Characters with a special meaning in ASF+SDF may cause problems when they are
needed as ordinary characters in the lexical syntax. The backslash character
(`{\tt \\}') is used as escape character for the quoting of special characters. You
should use `{\tt \\$c$}' whenever you need special character $c$ as ordinary character in
the definition.

In character classes, the following characters are special and should be
escaped: 

\begin{itemize}
\item {\tt [}: begin of character class 
\item {\tt ]}: end of character class 
\item {\tt -}: character range 
\item \verb+\+: escape character
\end{itemize}

In literal strings, the following characters are special and should be
escaped:

\begin{itemize}
 \item {\tt "}: double quote 
\item \verb+\+: escape character.
\end{itemize}

You may use the following abbreviations in literals and in character classes:

\begin{itemize}

\item \verb+\n+: newline character 

\item \verb+\r+: carriage return

\item \verb+\t+: horizontal tabulation 

\item {\tt $ddd$}: a non-printable character with three digit (octal) code
  $ddd$.

\end{itemize}

\subsubsection{Repetitions}

It is common, that lexical tokens can only be described by patterns that
exhibit a certain repetition. Two postfix operators are available for this
purpose:

\begin{itemize}

\item {\tt *}: indicates zero or more repetitions of the sort, literal or
  character class preceding the {\tt *}. 

\item {\tt +}: indicates one or more repetitions of the sort, literal or
  character class preceding the {\tt +}.

\end{itemize}

\subsubsection{Literals}

All literal symbols such as keywords and operator symbols that appear in the
context-free syntax are added to the lexical syntax implicitly.

\subsubsection{Lexical Ambiguities}

(*** dit moet helemaal op de schop)

Lexical ambiguities are resolved by the following four rules:

\begin{itemize}

\item Prefer Longest Match per Sort: reject all interpretations of the input text that are included

in a longer interpretation of the same sort. Given a standard definition of identifiers, the input `xyz' will thus lead to recognition of the identifier `xyz' and not to either `x' or `xy'. In the context of scanning Fortran, the input `3.NE.4' will lead to the recognition of two lexical tokens: the integer `3' and the floating constant `3.'. Both tokens are passed on to the parser which may decide if either (or both) tokens lead to a syntactically correct parse of the text.

\item Prefer non-Layout: eliminate all interpretations of the text as layout symbol. When, after

applying this rule, no interpretations remain, the next lexical token is taken from the input text.

\item Prefer Literals: give preference to interpretation as a literal, i.e., as keyword or operator

introduced in the context-free syntax, over interpretation as a more general symbol (such as identifier).

\item Prefer variables: give preference to interpretation as a variable (as defined in a variables
section) over interpretation as a literal.

\end{itemize}

Ambiguities that cannot be solved by these rules remain, and are passed on to the syntax analysis phase.

\subsubsection{Examples of Lexical Syntax Definitions}

\paragraph{Defining Identifiers}

\begin{verbatim}

sorts ID 

lexical syntax

   [a-zA-Z] [a-zA-Z0-9]* -> ID
\end{verbatim}

Observe that the space between the two character classes is ignored.

\paragraph{Defining Numbers}

\begin{verbatim}

sorts UnsignedInt SignedInt UnsignedReal Number 

lexical syntax

   [0-9]+                                     -> UnsignedInt
   UnsignedInt                                -> SignedInt 
   [+\-] UnsignedInt                          -> SignedInt
   UnsignedInt "." UnsignedInt                -> UnsignedReal
   UnsignedInt "." UnsignedInt [eE] SignedInt -> UnsignedReal 
   UnsignedInt [eE] SignedInt                 -> UnsignedReal
   UnsignedInt                                -> Number 
   UnsignedReal                               -> Number

\end{verbatim}

\paragraph{Defining Strings}

\begin{verbatim}
sorts String 

lexical syntax
   "\"" ~ ["\n]* "\"" -> String
\end{verbatim}

\paragraph{Defining Comments}

\begin{verbatim}

sorts CommentChar 

lexical syntax

   ~ [*]                  -> CommentChar
   "*" ~ [)]              -> CommentChar
   "(*" CommentChar* "*)" -> LAYOUT
\end{verbatim}

Note: In the current implementation the above definition does not work, since
CommentChar is not properly treated as an auxiliary sort for the lexical
syntax. As a result, every space will be recognized as a
CommentChar. Temporary solution: omit the declaration for CommentChar (this
produces an error message), but the parser will behave as expected.

\begin{verbatim}

lexical syntax
   "%%" ~ [\n] * "\n" -> LAYOUT
   "%" ~[\n%] * "%"   -> LAYOUT
\end{verbatim}

\subsection{Context-free Syntax}

The context-free syntax describes the concrete and abstract syntactic
structure of sentences in a language. A context-free syntax contains a set of
declarations for \emph{context-free functions}, each consisting of zero or
more literals, sort names, or lists followed by `{\tt ->}' and a result sort.
They may be followed by attributes that control how parentheses and brackets
affect the abstract syntax or by attributes that define the associativity of a
rule. All functions with the same result sort together define the alternatives
for that sort.

\subsubsection{Context-free Functions}

In their simplest form, declarations of context-free functions consist of a
sequence of zero or more literal strings or sort names followed by `{\tt ->}'
and the name of a result sort. All literal strings appearing in a context-free
function declaration are implicitly added to the lexical syntax. Consider the
following language of coordinates and drawing commands:

\begin{verbatim}
sorts NAT COORD CMND 

lexical syntax
   [0-9]+ -> NAT 
   [\ \n] -> LAYOUT 

context-free syntax
   "(" NAT "," NAT ")" -> COORD
   "line" "to" COORD   -> CMND 
   "move" "to" COORD   -> CMND
\end{verbatim}

Written as a conventional BNF grammar (and not considering lexical syntax) this is equivalent to:

\begin{verbatim}
<COORD> ::= "(" <NAT> "," <NAT> ")" 
<CMND>  ::= "line" "to" <COORD> | "move" "to" <COORD>
\end{verbatim}

When a literal in a context-free function consists only of lower case letters
and digits and is not a keyword of ASF+SDF, it need not be surrounded with
quotes. You may therefore write `{\tt move to COORD -> CMND}' instead of the
definition given above.

\subsubsection{List Structures}

It happens quite often that a context-free syntax requires the description of
the repetition of a syntactic notion or of list structures (with or without
separators) containing a syntactic notion. ASF+SDF provides the following
primitives for this:

\begin{itemize}

\item Lists without separators:

\begin{itemize}

\item[{\tt $S$*}] defines zero or more repetitions of sort $S$. 

\item[{\tt $S$+}] defines one or more repetitions of sort $S$.

\end{itemize} 

\item Lists with separators

\begin{itemize}

\item[{\tt \{$S$ $sep$}*\}] defines zero or more repetitions of sort $S$ separated by the literal
$sep$.

\item[{\tt \{$S$ $sep$\}+}] defines one or more repetitions of sort $S$ separated by the literal
$sep$.

\end{itemize}

\end{itemize}

Lists may be used in the left-hand side of a context-free function and in the
right-hand side of a variable declaration. see Section ***[Variables]. They
may {\bf not} be used as result sort in the right-hand side of a context-free
function. This imposes no real restriction since a new sort can be introduced
representing a list. This new sort may then be used in the left-hand side of
other context-free rules.

Using lists, the syntax of a list of identifiers (occurring in a declaration
in a Pascal-like language) can be defined as follows:

\begin{verbatim}
sorts ID DECL TYPE 

lexical syntax

   [a-z]+ -> ID 
   " "    -> LAYOUT 

context-free syntax

   decl { ID "," }+ ":" TYPE -> DECL
   integer                   -> TYPE 
   real                      -> TYPE
\end{verbatim}

\subsubsection{Chain Functions}

A context-free syntax may contain functions that do not add syntax, but serve
the sole purpose of including a smaller syntactic notion into a larger one. A
typical example is the inclusion of identifiers in expressions or of natural
numbers in reals. Such a \emph{chain function} has one of the following forms:

\begin{itemize}

\item {\tt $SMALL$ -> $BIG$} 
\item {\tt {$SMALL$ $sep$}* -> $BIG$} 
\item {\tt $SMALL$* -> $BIG$} 
\item {\tt {$SMALL$ $sep$}+ -> $BIG$} 
\item {\tt $SMALL$+ -> $BIG$}

\end{itemize}

Chain functions do not appear in the abstract syntax but correspond to a
\emph{subsort relation} between $SMALL$ and $BIG$.

\subsubsection{Bracket Functions}

A bracket function has the form `{\tt $open$ $S$ $close$ -> $S$}' where $open$
and $close$ are literals acting as opening and closing parenthesis for sort
$S$. Examples are `{\tt (}' and `{\tt )}' in arithmetic expressions and `{\tt
  begin}' and `{\tt end}' in programs. In most cases, such brackets are only
introduced for grouping and disambiguation, but have no further meaning. By
adding the attribute {\tt bracket} to the function declaration, it will not be
included in the abstract syntax.

Since brackets are necessary for overruling the priority and associativity of
functions (see ***[Priorities]), it is required that bracket functions are
declared for the argument and result sorts of

\begin{itemize}

\item all functions appearing in priority declarations, and
  
\item all functions having one of the attributes {\tt left}, {\tt right}, {\tt
    assoc}, or {\tt non-assoc}.

\end{itemize}

\subsubsection{Explicit Naming of Operators in the Abstract Syntax}

(*** Outdated ****)

This section is only relevant when you want to implement yourself functions that operate on the trees constructed by the Meta-environment (or the stand-alone SDF implementation). The following is never needed when you are only writing ASF+SDF specifications.

For each context-free function, the system automatically generates an internal name to label nodes in the abstract syntax tree corresponding to this function. When used inside the ASF+SDF Meta-environment names are thus redundant. However, names are indispensable if you want to build external tools that work directly on the tree structures generated. To name a rule explicitly, write the operator name followed by a colon before the context-free function declaration, like in

plus : EXP "+" EXP -? EXP For list constructs, names are generated of the form SortSeparator.list where Sort is the element sort and Separator is a keyword replacing the iterated separator. The rule for a list of expressions separated by a semi-colon:

- EXP ";" ""+ -? EXP.S generates the name `EXPSEMIC.list' which may be used elsewhere. You may override the automatic naming mechanism by inserting a name, preceded by a colon, after the iterator:

- EXP ";" ""+:exp.s -? EXP.S User defined operator names may not be used more than once.

\subsection{Priorities}

The context-free syntax defined in an ASF+SDF specification may be ambiguous: there are sentences which have more than one associated tree. The common example are the arithmetic expressions in which definitions of the priority or associativity of operators are missing. There are three mechanisms for defining associativity and priority:

\begin{itemize}

\item relative priorities of functions (defined in the `{\tt priorities}' section); 

\item associativity of functions (defined as attribute following the function
  declaration); 

\item associativity of groups of functions (defined in the `{\tt priorities}'
  section).

\end{itemize}

\subsubsection{ Relative Priorities}

The relative priority of two functions is defined by including {\tt $F$ > $G$}
in the `{\tt priorities}' section, where $F$ and $G$ are as written in the
context-free grammar. Functions with a higher priority bind more strongly than
functions with lower priorities and the nodes corresponding to them should
thus appear at lower levels in the tree than nodes corresponding to functions
with lower priorities. Lists of functions may be used in a priority
declaration: {\tt $F$ > {$G$, $H$}} is an abbreviation for {\tt $F$ > $G$, $F$
  > $H$} . 

\subsubsection{Associative Functions}

Associativity attributes can be attached to binary functions of the form `{\tt
  $S$ $op$ $S$ -> $S$}', where $op$ is a literal or empty. Without
  associativity attributes, nested occurrences of such functions immediately
  lead to ambiguities, as is shown by the sentence `{\tt S-string op S-string
    op S-string}' where `{\tt S-string}' is a string of sort $S$. The
  particular associativity associated with $op$ determines the indented
  interpretation of such sentences.
  
  We call two occurrences of functions $F$ and $G$ related, when the node
  corresponding to $F$ has a node corresponding to $G$ as first or last child.
  The associativity attributes define how to accept or reject trees containing
  related occurrences of the same function, $F$:

\begin{itemize}

\item {\tt left}: related occurrences of F associate from left to right. 

\item {\tt right}: related occurrences of F associate from right to left. 

\item{\tt  assoc}: related occurrences of F associate from left to right.

\item {\tt non-assoc}: related occurrences of F are not allowed.

\end{itemize}

Currently, there is no syntactic or semantic difference between `{\tt left}'
and `{\tt assoc'}, but we may change that in the future.

As an example, simple arithmetic expressions with usual priorities and
associativities are defined below:

\begin{verbatim}
sorts E 

lexical syntax
   [0-9]+ -> E 
   [\ \n] -> LAYOUT 

context-free syntax
   E "+" E   -> E {left}
   E "*" E   -> E {left}
   "(" E ")" -> E {bracket}

context-free priorities
   E "*" E   -> E > E "+" E   -> E {left}
\end{verbatim}

5.5.4 Groups of Associative Functions

(*** Outdated ***)

Groups of associative functions define how to accept or reject trees
containing related occurrences of different functions with the same priority.
They are defined by prefixing a list of context-free functions in a priority
declaration with one of the following attributes:

\begin{itemize}

\item left: related occurrences of F and G associate from left to right. 
\item right: related occurrences of F and G associate from right to left.
\item non-assoc: related occurrences of F and G are not allowed.

\end{itemize}

where F and G are functions appearing in the list.

\subsubsection{Removing Trees using Priorities}

The priority and associativity declarations are used to eliminate trees in two
phases: 

\begin{itemize}

\item First, trees containing internal conflicts (regarding priority or associativity) are eliminated.

\item Next, the remaining trees are compared pair-wise and trees are eliminated that are dominated
by another one. The ordering used is obtained by extending the priority
ordering on contextfree functions to an ordering on trees.

\end{itemize}

\subsubsection{Removing Trees Containing Conflicts}

The simplest application of priority and associativity declarations is the
elimination of trees that contain conflicts:

\begin{itemize}
\item a parent node has a child with a lower priority than the parent itself; 
\item a parent has a first or last child that is in conflict with
  associativity of parent and child.
\end{itemize}

A larger example illustrates this:

\begin{verbatim}
sorts E 

lexical syntax
   [0-9]+ -> E
   [\ \n] -> LAYOUT 

context-free syntax
   E "+" E   -> E {left}
   E "-" E   -> E {non-assoc}
   E "*" E   -> E {left}
   E "/" E   -> E {non-assoc}
   E "^" E   -> E {right}
   "(" E ")" -> E {bracket}

context-free  priorities
   "^" > {non-assoc: "*", "/"} > {left: "+", "-"}

\end{verbatim}

The definition of associativities is here only choosen to illustrate various
possibilities and combinations. Some examples show the effect of these
declarations:

\begin{center}
\begin{tabular}{ll}
  Sentence   & Interpretation \\
\verb"1^2^3" & \verb"1^(2^3)" \\
\verb"1^2*3" & \verb"(1^2)*3" \\
\verb"1*2*3" & \verb"(1*2)*3" \\
\verb"1/2/3" & error \\
\verb"1*2/3" & error \\
\verb"1-2-3" & error \\
\verb"1+2+3" & \verb"(1+2)+3" \\
\verb"1-2+3" & \verb"(1-2)+3" \\
\verb"1+2-3" & \verb"(1+2)-3"\\
\end{tabular}
\end{center}

After removing all trees containing conflicts, more than one tree may remain.
To further reduce this set of remaining trees, the priority ordering `>' on
context-free functions is extended to a priority ordering `>>' on trees. A
tree in the set is then rejected if there is another tree in the set with
higher priority. The relation $P_1$ >> $P_2$ holds between two trees $P_1$ and
$P_2$ if

\begin{itemize}

\item $P_1$ is not equal to $P_2$, and 
\item if, for any F, $P_1$ contains more nodes corresponding to F than $P_2$, then $P_2$ contains more
nodes corresponding to some function G witch G ! F in $P_1$. (This also covers
the case that there are no nodes corresponding to F in $P_2$ or no nodes
corresponding to G in $P_1$)

\end{itemize}

The following example shows how the interaction (and resulting ambiguities)
between general context-free functions and special case functions can be
described using priorities. It concerns expressions for describing subscripts
and superscripts in the typesetting language EQN. The crucial point is that,
for typesetting reasons, we want to treat a subscript followed by a
superscript in a special way. Therefore, the special case `{\tt E sub E sup E
  -> E}' is introduced, which has priority over a combination of the two
functions `{\tt E sub E -> E}' and `{\tt E sup E -? E}'.

\begin{verbatim}
sorts E 

context-free syntax
   E sub E       -> E {left}
   E sup E       -> E {left}
   E sub E sup E -> E 
   "{" E "}"     -> E {bracket}
   a             -> E 

context-free priorities
   sub sup > { left: sub , sup}
\end{verbatim}

\subsection{Variables}

Variables are declared in the `variables' section of a module. It consists of
a list of variables together with their sort. Each declaration defines a
naming scheme for variables together with a result sort. A naming scheme is a
regular expression like the ones allowed in the lexical syntax (See Section
5.3 [Lexical Syntax], page 31) except that sorts are not allowed. One variable
declaration may thus define an unlimited number of variables. The sort of a
variable may be a simple sort, or a list with or without separators. The
variables `Id', `Type3', and `Id-list''' are examples of variables declared by
the following specification:

\begin{verbatim}
sorts ID DECL TYPE 

lexical syntax
   [a-z]+ -> ID
   " "    -> LAYOUT 
context-free syntax
   decl {ID ","}+ ":" TYPE -> DECL 
   integer                 -> TYPE 
   real                    -> TYPE 

variables
   Id           -> ID 
   Type [0-9]*  -> TYPE 
   Id-list [']* -> { ID "," }* 
   Id-ne-list   -> {ID "," }+
\end{verbatim}

Note that variables (as all other entities in a module -- except equations)
may be exported.  See Section ***[Modules]..

\subsection{Equations}

With equations a meaning or semantics may be added to functions declared in
the context-free syntax. The equality of two terms $S$ and $T$ is defined by
an unconditional equation of the form:

\begin{quote}
{\tt [$TagId$] $S$ = $T$} 
\end{quote}

where $TagId$ is a sequence of letters and/or digits starting with an
uppercase letter or a digit, and $S$ and $T$ must be terms of the same sort. A
conditional equation consists of a number of conditions (also called premises)
and a conclusion. It can be written in three (syntactically different) ways:

{\tt 
\begin{tabbing}

(a)  [$TagId$] \= $S$ = $T$ when $C_1$, $C_2$, ...\\
(b)  [$TagId$] \> $C_1$, $C_2$, ... ====> $S$ = $T$\\ 
(c)  [$TagId$] \> $C_1$, $C_2$, ...\\
                 \> =================\\
                 \> \ \ \ \ \ $S$ = $T$\\
\end{tabbing}
}

\noindent where $C_1$, $C_2$, ...  are conditions which may be either positive (and have
the form `{\tt $S$ = $T$}'), or negative (and have the form `{\tt $S$ !=
  $T$}').

Note that list sorts are not allowed as the sort of the term at the left-hand side or right-hand
side of a condition or conclusion (but see Section ***[Lists]). This restriction can be circumvented by introducing a new sort for the list.

Equations establish equalities between terms. How they are executed is
discussed in Chapter **[Executing].



\section{Miscellaneous}

\subsection{Parsing a term outside the \ASmetaenv}

\subsection{Rewriting a term using a compiled specification}

\subsection{Unparsing a (parsed/normalized) term}

\end{document}
