
%%
%%    Meta-Environment - An environment for language prototyping.
%%    Copyright (C) 2000  Stichting Mathematisch Centrum, Amsterdam, 
%%    The Netherlands. 
%%
%%    This program is free software; you can redistribute it and/or modify
%%    it under the terms of the GNU General Public License as published by
%%    the Free Software Foundation; either version 2 of the License, or
%%    (at your option) any later version.
%%
%%    This program is distributed in the hope that it will be useful,
%%    but WITHOUT ANY WARRANTY; without even the implied warranty of
%%    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
%%    GNU General Public License for more details.
%%
%%    You should have received a copy of the GNU General Public License
%%    along with this program; if not, write to the Free Software
%%    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
%%
%{{{ LaTeX configuration

% vim:ts=4:sw=4:tw=75
\documentclass[a4paper,twoside]{article}

%\usepackage{fullpage}
\usepackage{a4wide}
\usepackage{verbatim}
\usepackage{makeidx}
\usepackage{epsfig}
\usepackage{alltt}
\usepackage{moreverb}  
\usepackage{url}

\makeindex

\newcommand{\ASmetaenv}{{\sc Asf}+{\sc Sdf} Meta-En\-vir\-on\-ment}
\newcommand{\sdf}{{\sc Sdf}}
\newcommand{\asf}{{\sc Asf}}
\newcommand{\asfsdf}{{\sc Asf}+{\sc Sdf}}
\newcommand{\ATerm}{ATerm}
\newcommand{\ATerms}{ATerms}
\newcommand{\xemacs}{{\tt XEmacs}}

%% notion of Symbol was changed to AFun, which matches specification.
\newcommand{\Symbol}{AFun}

\newcommand{\ATtrue}{\mbox{\tt ATtrue}}
\newcommand{\ATfalse}{\mbox{\tt ATfalse}}
\newcommand{\main}{\mbox{\tt main}}
\newcommand{\ATinit}{\mbox{\tt ATinit}}
\newcommand{\ATprotect}{\mbox{\tt ATprotect}}
\newcommand{\ATprotectArray}{\mbox{\tt ATprotectArray}}

\newcommand{\toolbus}{\mbox{\tt ToolBus}}

% \example{init.c} will input file "examples/init.c" in verbatim mode.
\newcommand{\example}[1]{
    \noindent
    \hrulefill
    \begin{small}
    \verbatiminput{examples/#1}
    \end{small}
    \hrulefill
}

% NULL
\newcommand{\NULL}{{\tt NULL}}               

% Function definition
\newcommand{\Function}[4]{
    \vspace{0.3cm}
    \noindent
    \framebox[12.6cm][l]{{\bf function:} {\tt #1}} \vspace{0.1cm}\newline
    \label{#1}
    \noindent
    {\bf Summary:\hspace{0.2cm}} #4\newline
    {\bf Declaration:}
        {\tt #2} {\tt #1}({\tt #3});
    \index{#1@{\tt #1}}
}
                                        

% Macro definition
\newcommand{\Macro}[4]{
    \vspace{0.3cm}
    \noindent
    \framebox[12.6cm][l]{{\bf macro:} {\tt #1}} \vspace{0.1cm}\newline
    \label{#1}
    \noindent
    {\bf Summary:\hspace{0.2cm}} #4\newline
    {\bf Declaration:}
        {\tt #2} {\tt #1}({\tt #3})
    \index{#1@{\tt #1}}
}
                        

% Method definition
\newcommand{\Method}[4]{
    \vspace{0.3cm}
    \noindent
    \framebox[12.6cm][l]{{\bf method:} {\tt #1}} \vspace{0.1cm}\newline
    \label{#1}
    \noindent
    {\bf Summary:\hspace{0.2cm}} #4\newline
    {\bf Declaration:}
        {\tt #2} {\tt #1}({\tt #3});
    \index{#1@{\tt #1}}
}

% Throws exception (optional)
\newcommand{\Throws}[2]{

\noindent{\bf Throws:} {\tt #1} #2
}                  

% Function/Macro/Method description (optional)
\newcommand{\Describe}[1]{

    \noindent{\bf Description:} #1
}

\newcommand{\fignegspacebefore}{\vspace*{-0.25cm}}
\newcommand{\fignegspacebetween}{\vspace*{-0.25cm}}
\newcommand{\fignegspaceafter}{\vspace*{-0.5cm}}        

\newenvironment{Code}
        {\vspace*{-0.15cm}\begin{small}\begin{center}}
        {\end{center}\end{small}\vspace*{-0.2cm}}

\newenvironment{IncCode}
        {\begin{Code}\begin{small}}
        {\end{small}\end{Code}}      

\def\aterms{\mbox{ATerms}}
\def\aterm{\mbox{ATerm}}
\def\asfix{\mbox{\sc AsFix}}

%}}}
%{{{ Title page and table of contents

%----[ TITLE PAGE ]----           
\title{\ASmetaenv\ User Manual \\ $Revision$}
\author{M.G.J. van den Brand and P. Klint\\
        {\small\sl Centrum voor Wiskunde en Informatica (CWI),}\\
{\small\sl Kruislaan 413, 1098 SJ Amsterdam, The Netherlands}}

\date{}
\begin{document}
\maketitle    

\begin{abstract}
This is a preliminary user manual for the \ASmetaenv\ Release 1.
This is work under construction.
\end{abstract}

\tableofcontents
\newpage

%}}}

%{{{ Overview

%---- [ OVERVIEW ]---- 

\section{Overview}\label{overview} 

\subsection{When to use the \ASmetaenv?}

The \ASmetaenv\ is an interactive development environment
for the automatic generation of interactive systems for manipulating
programs, specifications, or other texts written in a formal
language. The generation process is controlled by a definition of the
target language, which typically includes such features as syntax,
pretty printing, type checking and execution of programs in the target
language. The \ASmetaenv\ can help you if:

\begin{itemize}

  \item You have to write a formal specification for some problem
  and you need interactive support to do this.

  \item You have developed your own (application) language and want to
  create an interactive environment for it.

  \item You have programs in some existing programming language and you
   want to analyze or transform them.
\end{itemize}

The \asfsdf\ formalism allows the definition of syntactic as well as
semantic issues. It can be used for the definition of languages (for
programming, for writing specifications, for querying databases, for
text processing, or for dedicated applications). In addition it can be
used for the formal specification of a wide variety of
problems. \asfsdf\ provides you with:

\begin{itemize}

  \item A general-purpose algebraic specification formalism based on equational logic. 

  \item Modular structuring of specifications.

  \item Integrated definition of lexical, context-free and abstract syntax. 

  \item User-defined syntax, allowing you to write specifications using your own notation. 

  \item Complete integration of the definition of syntax and
  semantics.

\end{itemize}

The \ASmetaenv\ offers: 

\begin{itemize}

  \item Syntax-directed editing of \asfsdf\ specifications.

  \item Incremental compilation and testing of specifications.

  \item Compilation of \asfsdf\ specifications into dedicated
interactive environments containing various tools such as a parser, 
a pretty printer, a syntax-directed editor, a
debugger, and an interpreter or compiler.

\end{itemize}

The advantages of creating interactive environments in this way are twofold:

\begin{itemize}

  \item \emph{Increased uniformity}. Similar tools for different
  languages often suffer from a lack of uniformity.  Generating tools
  from language definitions will result in a large increase in
  uniformity, with corresponding benefits for the user.

  \item \emph{Reduced implementation effort.} Preparing a language
  definition requires significantly less effort than developing an
  environment from scratch.

\end{itemize}

\subsection{Global Structure of the Meta-Environment}

You can create new specifications or modify and test existing ones
using the Meta-Environment. Specifications consist of a series of
modules, and individual modules can be edited by invoking a module
editor. All editing in the Meta-environment is done by creating
instances of a \emph{generic syntax-directed editor}.

After each editing operation on a module its \emph{implementation} is updated
immediately. It consists of a parser, a pretty
printer, and a term rewriting system which are all derived from the
module automatically.

A module can be tested by invoking a \emph{term editor} to create and
evaluate terms defined by the module. Term editors use the syntax of
the module for parsing the textual representation of terms and for
converting them to internal format (abstract syntax trees). The
equations of the module are then used to reduce the terms into normal
form. This result is, in its turn, converted back to textual form by
pretty printing it.

%%The reduction of a term can be monitored by using EDB (Equation
%%Debugger), a debugging system that allows you to reduce a term
%%step-by-step or to place breakpoints for interrupting the reduction
%%process at specific moments.

%%Finally, term editors can be customized by adding \emph{buttons} whose
%%activation starts the evaluation of a function which is defined in the
%%specification. In this way you can customize the user-interface of the
%%application by adding, for instance, a typechecking or evaluation
%%button to a term editor. (** check; not in Release 1.**)

\subsection{About this Manual}

This manual is intended for those courageous users that want to try
out the new brand new implementation of the \ASmetaenv. This manual is
still under development and we welcome all feed back and comments.

%%In the sequel we will use \ASmetaenv\ to address the new
%%system and old \ASmetaenv\ when addressing the old system.

The focus in this manual will be on using the system to write a
specification like a type checker or evaluator for the toy language
PICO. It follows the user-interface to explain the capabilities of the
system.  Topics that will be addressed include:
\begin{itemize}
\item How to start the system, and how to exit it.
\item How to create, open and save a specification.
\item How to edit the syntax and/or equations part of a module.
\item How to edit a term.
\item How to evaluate a term.
\item How to compile a specification.
\item How to parse a term outside the \ASmetaenv.
\item How to rewrite a term using a compiled specification outside the
\ASmetaenv.
\item How to unparse parse and/or normalized terms.
\end{itemize}

\noindent We do \emph{not} explain:

\begin{itemize}
\item The formalism \asfsdf. We do, however, provide a quick introduction
to \asfsdf\ in Section~\ref{ASF+SDF}.
\item The architectural and implementational aspects of the system.
\item The stand alone usage of various parts of he system.
\end{itemize}

\subsection{Further Reading}

%%\cite{DHK96}

\section{Starting the System}

The \ASmetaenv\ can be invoked via the command {\tt meta}.  As a
result, the \ASmetaenv\ main window pops up. This is shown in
Figure~\ref{FIG:meta-start}.


The {\tt meta} command has the following options, which may come in handy
later on. As a novice user, you may want to skip the remainder of this section
and continue with Section~\ref{MainWindow}.

\begin{itemize}

\item {\tt -c \emph{dir}} instructs the \asfsdf\ compiler to generate
C files in the directory \emph{dir}. Note that this directory is also
controlled by the environment variable {\tt COMPILER\_OUTPUT}

\item {\tt -d} starts the \ASmetaenv\ in debug mode. As a result,
an interactive viewer (``ToolBus viewer'') will be started that 
allows the study of the internal behaviour of the system.
The viewer is shown in Figure~\ref{FIG:viewer}.

\item {\tt -h } shows help information for the {\tt meta} command.

\item {\tt -T \emph{port}} controls the communication ports that will
be used for communication between the components of the \ASmetaenv.
Note that these ports are also controlled by the environment variable
{\tt TB\_PORT}.  The default value is {\tt 8999}, but this port may be
in use by someone else (or by a aborted previous run of the
\ASmetaenv). In that case, it is advisable to use other value in the
range 9000 and up.

\item {\tt -v} runs the \ASmetaenv\ in verbose mode.

\item {\tt -V} shows the version number of the \ASmetaenv\ you are running.

\end{itemize}

Search paths can be initialized by creating a file ``meta.conf'' in
the directory from which the {\tt meta} command is initiated.  This
file may contain a list of absolute and/or relative path names (each
on a separate line) that will be searched when opening modules.  For
instance, in the {\tt pico} directory (see Section~\ref{GuidedTour})
you will find an example {\tt meta.conf} file which only contains the
path `{\tt .}', i.e., only the current directory will be searched.

\begin{figure}[tb]

  \centerline{\epsfig{file=meta-start.ps,width=12cm}}
  \caption{\label{FIG:meta-start} Main window of \ASmetaenv}

\end{figure}
\begin{figure}[tb]

  \centerline{\epsfig{file=viewer.ps,width=14cm}}
  \caption{\label{FIG:viewer} ToolBus viewer}

\end{figure}

\section{The Main Window} \label{MainWindow}

The main window of \ASmetaenv\ immediately after starting of the
system was already shown in Figure~\ref{FIG:meta-start}.  After
loading a specification it may look like Figure~\ref{FIG:meta-pico}.
The main window of the consists of the following parts:

\begin{itemize}
\item At the top of the window is a menu bar that contains the following menus:
  \begin{itemize}

   \item {\tt File}: for creating, opening, saving and printing
    specifications as well as for leaving the \ASmetaenv.
    The {\tt File} menu is described in Section~\ref{FileMenu}.

   \item {\tt Edit}: for setting user preferences.
      The {\tt Edit} menu is described in Section~\ref{EditMenu}.

   \item {\tt Graph}: for setting options for the display of 
        the graph in the import pane (see below).
       The {\tt Graph} menu is described in Section~\ref{GraphMenu}.

   \item {\tt Debug}: for turning on/off the display of diagnostic messages.
    The {\tt Debug} menu is described in Section~\ref{DebugMenu}.

   \item {\tt Help} for various forms of information and online help.
    The {\tt Help} menu is described in Section~\ref{HelpMenu}.

  \end{itemize}
  
\item The \emph{import pane}: A graphical canvas (empty in
  Figure~\ref{FIG:meta-start}, but containing rectangles and arrows in
  Figure~\ref{FIG:meta-pico}) at the left hand side of the window that shows
  the import graph of the specification you are editing.  The import pane is
  described in Section~\ref{ImportPane}.
  
\item The \emph{module pane}: a vertical list (empty in
  Figure~\ref{FIG:meta-start}, but containing names like {\tt Layout}, {\tt
    Pico-Booleans}, ...  in Figure~\ref{FIG:meta-pico}) at the right/middle
  part of the window that shows the names of all modules in the current
  specification.  The module pane is described in Section~\ref{ModulePane}.
  
\item The \emph{button pane}: vertical row of buttons at the right hand side
  of the window containing buttons like {\tt Edit Syntax} and {\tt Edit
    Equations}: they are used for common operations on the
  current specification like editing, saving or deleting a module, or
  compiling the complete specification. The button pane is described in
  Section~\ref{ButtonPane}.
  
\item A \emph{status bar} at the bottom of the window that shows the current
  activity of the system. Examples are: {\tt idle} (the system is doing
  nothing), {\tt parsing} (the system is performing a syntactic analysis of
  some module or term), and {\tt rewriting} (the system is rewriting a term).

\end{itemize}

\begin{figure}[t]
  \centerline{\epsfig{file=meta-pico.ps,width=12cm}}
  \caption{\label{FIG:meta-pico} Main window after loading the Pico specification}
\end{figure}

\section{The Menus of the Main Window}
 
\subsection{The File menu} \label{FileMenu}

\begin{figure}[t]
  \centerline{\epsfig{file=file-menu.ps,width=3cm}}
  \caption{\label{FIG:file-menu} {\tt File} menu (main window)}
\end{figure}

The {\tt File} menu is used for creating, opening, saving and printing
specifications as well as for leaving the \ASmetaenv.  It is shown in
Figure \ref{FIG:file-menu}.

{\tt New}, {\tt Open} and {\tt Save} are used for creating
a new module, opening an existing one, respectively, saving a module.
In all three cases a dialog window appears as shown in
Figure~\ref{FIG:open-file}.

{\tt Clear} removes all modules that have been opened so far from the
Meta-Environment. If modules have been modified, you are expicitly
asked to save them. he same effect can be achieved by leaving the
Meta-Environment (using {\tt Quit}, see below) and starting a new
version of the Meta-Environment using the {\tt meta} command.

{\tt Export} allows the export of the import pane in various graphical
formats.  {\tt Print Setup} allows the customization of the command
used for printing.  Its dialog window is shown in
Figure~\ref{FIG:printer-setup}.  {\tt Print} print the current import
pane.

The entry {\tt Quit} ends the execution of the \ASmetaenv.

\begin{figure}[t]
  \centerline{\epsfig{file=printer-setup.ps,width=3cm}}
  \caption{\label{FIG:printer-setup} Dialog for printer setup}
\end{figure}



\begin{figure}[t]
  \centerline{\epsfig{file=open-file.ps,width=8cm}}
  \caption{\label{FIG:open-file} Dialog for opening a module ({\tt File} menu)}
\end{figure}

\subsection{The Edit menu} \label{EditMenu}

\begin{figure}[t]
  \centerline{\epsfig{file=edit-menu.ps,width=3cm}}
  \caption{\label{FIG:edit-menu} {\tt Edit} menu (main window)}
\end{figure}

The {\tt Edit} menu is used for setting the preferences of a user.
However, for the moment this menu is not activated.

\subsection{The Graph Menu} \label{GraphMenu}

\begin{figure}[t]
  \centerline{\epsfig{file=graph-menu.ps,width=4cm}}
  \caption{\label{FIG:graph-menu} {\tt Graph} menu (main window)}
\end{figure}

The {\tt Graph} menu is used for setting options for the display of the graph
in the import pane.  It is shown in Figure \ref{FIG:graph-menu}.


{\tt View All} enlarges the import pane to enable the display of the whole
import graph.

{\tt Autoresize after loading} defines the size of the import pane
after loading a specification. When enabled (check box red), the
import pane will be enlarged to enable the display of the whole import
graph.  When disabled (check box empty), only part of the import graph
will be shown.

{\tt Animate while loading} defines the visualization of the import
graph while the system is loading a specification. When enabled, the
import graph will be updated each time a module from the specication
has been loaded in the system. When disabled, the new import graph
will only be shown when the loading of the specification is complete.


\subsection{The Debug Menu} \label{DebugMenu}

\begin{figure}[t]
  \centerline{\epsfig{file=debug-menu.ps,width=4cm}}
  \caption{\label{FIG:debug-menu}{\tt Debug}  menu (main window)}
\end{figure}

The {\tt Debug} menu is shown in Figure~\ref{FIG:debug-menu} and contains the
single check box {\tt Diagnostic messages}.  When enabled, diagnostic
messages will be displayed.  Otherwise the systems runs silently.

\subsection{The Help Menu} \label{HelpMenu}

\begin{figure}[t]
  \centerline{\epsfig{file=help-menu.ps,width=5cm}}
  \caption{\label{FIG:help-menu}{\tt Help}  menu (main window)}
\end{figure}

The {\tt Help} menu is shown in Figure~\ref{FIG:help-menu}.


{\tt About Meta-Environment} and {\tt About Graph Browser}
give background on the  \ASmetaenv\ and on the graph browser
that is part of the main window.

{\tt Mouse Operations} gives an overview of the meaning of
the available mouse operations.


{\tt Online Help} (***)

{\tt JitterBug Activated} opens in an active {\tt Netscape} window a page
to enter a bug report. This offers the users of the \ASmetaenv\ an online
facility to report bugs to the developers.

Both {\tt Online Help} and {\tt JitterBug Activated} assume that there
is a {\tt Netscape} running, other browsers are not yet supported.

\section{The Panes of the Main Window}

The two left-most panes of the main window give two, alternative,
views on the same information: the \asfsdf\ specification that has
been loaded into the Meta-Environment.  Using one of these views, the
same set of operations is available either via a pop menu or via the
buttons in the pane at the right-hand side of the main window.

\subsection{The Import Pane} \label{ImportPane}

The \emph{import pane} gives a graphical view of the specification by
displaying the \emph{import} relation between modules in the form of a
graph. A module $M_1$ imports another module $M_2$ if $M_1$ contains
an import statement of the form {\tt imports $M_2$}.

Each module is represented by a rectangle. An arrow between two
rectangles represents an import relation between the two corresponding
modules. Modules with a special status (e.g., imported by some other
module but never defined, or containing syntax errors) are represented
by a circle.

The import pane has the following interaction facilities:

\begin{itemize}

\item Different parts of the import graph can be displayed by using
the horizontal or vertical scrollbar next to the import pane.

\item By clicking and holding the middle mouse button outside any
module, the import graph can be dragged across the import pane.

\item Clicking \emph{on} a module yields a pop up menu as shown in
Figure~\ref{FIG:module-menu}.  It contains the same entries as the
button pane of the main window (see Section \ref{ButtonPane}).

\item Clicking \emph{outside} any module yields a pop up menu as shown
in Figure~\ref{FIG:new-open}.  It contains the entries {\tt New} and
{\tt Open} for creating a new, respectively, opening an existing
module. These two operations are also available from the {\tt File}
menu (see Section~\ref{FileMenu}).

\end{itemize}

\begin{figure}[t]
  \centerline{\epsfig{file=module-menu.ps,width=3cm}}
  \caption{\label{FIG:module-menu}Pop up menu for module operations (import pane)}
\end{figure}

\begin{figure}[t]
  \centerline{\epsfig{file=new-open.ps,width=2cm}}
  \caption{\label{FIG:new-open}Pop up menu for adding a module (import pane)}
\end{figure}

\subsection{The Module Pane} \label{ModulePane}

The import pane is particularly usefull when you want to understand the
overall structure of a specification but it may become unwieldy for
very large specifications. For large specifications the module pane
may give you quicker access to the modules in the specification.
It presents a vertical, scrollable, list of the names of all the modules in
the specification.

The main purpose of the module pane is to select one or modeles from
the specification on which an operation from the button pane
(Section~\ref{ButtonPane}) is to be performed.  One module is selected
by clicking on the corresponding module name in the module pane.  More
than one module can be selected by clicking on a module name, keeping
the mouse button down and and then dragging the mouse to the last
desired module name.  Note that only consecutive modules can be
selected.

After making the selection, an operation can be performed on all the
selected modules by pushing a button from the button pane.  For
instance, pushing the {\tt Edit Syntax} button will create editors for
the syntax of all the selected modules.

\subsection{The Button Pane of the Main Window} \label{ButtonPane}

The entries in the button pane (at the right-hand side of the main
window, see Figure~\ref{FIG:meta-start}) and in the module pop-up menu
(see Figure \ref{FIG:module-menu} and Section~\ref{ImportPane}) are
identical in function. We describe them here together.

First, one or more modules are selected via the import pane or the
module pane. Next, one of the following operations can be applied to
them.

{\tt Edit Syntax}, {\tt Edit Equations},
and {\tt Edit Term} activate (structure) editors for
editing syntax, equations, or terms, respectively, for the selected module(s).

{\tt Save} saves the tree representation of the syntax definition
and the equations section of the selected module(s).
{\tt Revert} removes modules and re-opens the removed modules, 
the effect is that modifications made to these modules are discarded.
{\tt Delete} removes modules.

{\tt Compile} invokes the \asfsdf-compiler to generate C code.  If no
or more than one module ihas been selected, a warning appears (Figure
\ref{FIG:compiler-warning}).  Otherwise, a dialog window appears (Figure
\ref{FIG:compiler-dir}) containing the current directory path where the output of the compiler
will be written. It can be modified as well.
Pushing the {\tt Cancel} button aborts the compilation. Section~\ref{compiling-specs}
gives more details on the compilation of \asfsdf\ specifications.

{\tt Info} gives module information (not yet implemented).

\begin{figure}[t]
  \centerline{\epsfig{file=compiler-warning.ps,width=4cm}}
  \caption{\label{FIG:compiler-warning}Warning ({\tt Compile module...})}
\end{figure}

\begin{figure}[t]
  \centerline{\epsfig{file=compiler-dir.ps,width=4cm}}
  \caption{\label{FIG:compiler-dir}Dialog for setting directory path ({\tt Compile Module...})}
\end{figure}

\section{Editing Specifications}

The editors used to create and modify specifications and terms are
based on \xemacs, so some familiarity with this editor is assumed.
See \url{http://www.xemacs.org/Documentation/index.html}
for documentation on \xemacs.

There are two additions to the standard user-interface of \xemacs:

\begin{itemize}
\item The {\tt Meta-Environment} pull-down menu
(Figure~\ref{FIG:meta-env-menu}) for applying the \asfsdf\ parser ({\tt
Parse}) or evaluator ({\tt Reduce}) on the text in the editor.

\item The {\tt Move} pull-down menu (Figure~\ref{FIG:move-menu}) for
structured traversal of the syntax tree of the text in the editor.
Using the entries {\tt Left}, {\tt Righ}t, {\tt Up}, {\tt Down} the
user can navigate in the tree.
\end{itemize}

\begin{figure}[t]
  \centerline{\epsfig{file=move-menu.ps,width=1.2cm}}
  \caption{\label{FIG:move-menu}{\tt Move} menu (editor)}
\end{figure}

\subsection{Editing the Syntax Part of a Module}

An editor for editing the syntax part of a module is activated via the
button {\tt Edit Syntax}. An example is shown in
Figure~\ref{FIG:Bool-example.sdf2}.  Initially the entire text is
highlighted and the message ``{\tt Focus sort is invalid}'', appears
in the status line at the bottom of the main window.

Via the entry {\tt Parse} in the {\tt Meta-Environment} menu of the
editor, the parser can be activated.  The parser is finished when the
status line in the main window displays ``{\tt Idle}'' again.

\paragraph{Note:} if the term to be parsed is a large one, it may take
some time for the editor to be active again. If the parse was
successful the bottom line in the \xemacs\ window contains the message
{\tt Focus sort: None}. Clicking on an arbitrary place sets the focus
and changes the bottom line message.

\begin{figure}[t]
  \centerline{\epsfig{file=meta-env-menu.ps,width=1.5cm}}
  \caption{\label{FIG:meta-env-menu} {\tt Meta-Environment} menu (editor)}
\end{figure}

The entry {\tt Reduce} of the {\tt Meta-Environment} menu of the
editor has no effect when editing a syntax definition.

\subsection{Editing the Equations Section of a Module}

An editor for editing the equations section of a module is activated
via the button {\tt Edit Equations}.  An example is shown in Figure
\ref{FIG:Bool-example.eqs}.  

The entry {\tt Parse} in the {\tt Meta-Environment} menu of the editor
activates the parser for the equations. It is possible that in order
to parse the equations, a parse table needs to be generated. This is
visible through the status message {\tt Generating Parse Table}.  The
entry {\tt Reduce} in the {\tt Meta-Environment} menu of the editor
has no effect when editing equations.

\subsection{Editing Terms} \label{EditingTerms}

An editor for editing a term over a module is activated via the button
{\tt Edit Term}.  An example is shown in Figure
\ref{FIG:Bool-example.trm},

The entry {\tt Parse} in the {\tt Meta-Environment} menu of the editor
activates the
parser for this term. It is possible that in order to parse
the term, a parse table needs to be generated. This is visible
through the status message {\tt Generating Parse Table}.

The entry {\tt Reduce} in the {\tt Meta-Environment} menu of the
editor activates the evaluator (also called interpreter). The term is
reduced given the specified equations (if any). In order to reduce the
term it may be necessary to parse the equations of various modules and
to initialize the evaluator with this set of equations.  Section
\ref{eval-term} gives more details on evaluating terms.


\section{Guided Tour} \label{GuidedTour}

\begin{figure}[t]
  \centerline{\epsfig{file=meta-booleans.ps,width=12cm}}
  \caption{\label{FIG:meta-booleans}Main window after opening {\tt Pico-Booleans}}
\end{figure}

To help you to get acquainted with the \ASmetaenv\ the system
comprises two example specifications, namely the one-module specification:
{\tt Bool-example}, and the specification of the syntax, typechecker and dynamic
semantics of the small programming language Pico.

This Guided Tour is meant to guide you through these specifications, and show
you the main features of the \ASmetaenv. Only global information
is given about these features but references are made to parts of the
user-manual with detailed information.

\subsection{Before you start the Guided Tour}

The Meta-Environment is usually installed in a directory named {\tt
  meta-$version$}. For Release 1, this may, for instance, be {\tt meta-1.0.0}.
You will then find the files needed for this Guided Tour in the directory {\tt
  meta-1.0.0/demo/pico}. It is advisable to make your personal copy of this
directory.  In this Guided Tour we will use `{\tt pico}' to refer to your own
copy of the directory.

For each module in a specification two files exist: `{\tt
  $module$.sdf2}' contains the syntax of $module$ and `{\tt
  $module$.eqs}' contains the semantics (equations) of $module$. The
  directory pico contains:

\begin{itemize}

\item two files for the module {\tt Bool-example}.

\item files for the Pico-specification.

\item three examples of Pico-programs: `{\tt big.pico}', `{\tt fac.pico}',
  `{\tt small.pico}'.

\item terms for typechecking and evaluating these Pico-programs.

\end{itemize}

\subsection{Beginning the Guided Tour}

\begin{itemize}

\item Go to directory {\tt pico}. 
\item Type the command {\tt meta}. The main window of the Meta-environment
  will appear as shown in Figure~\ref{FIG:meta-start}.
  
\item Add the module {\tt Bool-example} by selecting the File menu, and
  choosing the Open button. In a dialog window, the system asks you to give
  the name of the module to be opened. It presents a list of all files with
  extension `{\tt sdf2}'. Click once on `{\tt Bool-example.sdf2}' and then
  push the {\tt Open} button. This will load the module {\tt Module-example}
  (both its syntax and equations!) into the system.
  
\item Verify that module {\tt Bool-example} appears as a rectangle in
the import pane as well as in the module pane of the main window as
shown in Figure~\ref{FIG:meta-Bool-example}.

\end{itemize}

\begin{figure}[t]
  \centerline{\epsfig{file=meta-Bool-example.ps,width=12cm}}
  \caption{\label{FIG:meta-Bool-example}Main window after opening {\tt Bool-example}}
\end{figure}

\subsection{The Module Bool-example}

One of the simplest specifications possible, and therefore frequently used as
an example, is the datatype of the Boolean values. It defines the constants
{\tt true} and {\tt false} and the functions \emph{and} and \emph{or}
 (written in infix notation using
the left-associative operators `{\tt \&}' and `{\tt |}', respectively) and
\emph{not} (written
in prefix notation using the function symbol `{\tt not}'). Here is the
specification:

\begin{verbatim}
module Bool-example
  exports
    sorts BOOL 
    lexical syntax
      [\ \t\n]           -> LAYOUT

    context-free syntax
      "true"             -> BOOL
      "false"            -> BOOL 
      BOOL "|" BOOL      -> BOOL {left}
      BOOL "&" BOOL      -> BOOL {left}
      "not" "(" BOOL ")" -> BOOL
      "(" BOOL ")"       -> BOOL {bracket}

    variables
      "Bool"[0-9\']* -> BOOL

    context-free priorities
      BOOL "&" BOOL -> BOOL >
      BOOL "|" BOOL -> BOOL

    equations

    [B1] true | Bool = true 
    [B2] false | Bool = Bool

    [B3] true & Bool = Bool 
    [B4] false & Bool = false

    [B5] not(false) = true 
    [B6] not(true) = false

\end{verbatim}

\begin{figure}[t]
  \centerline{\epsfig{file=Bool-example.sdf2.ps,width=12cm}}
  \caption{\label{FIG:Bool-example.sdf2}Editor for the syntax of {\tt Bool-example}}
\end{figure}

\begin{figure}[t]
  \centerline{\epsfig{file=Bool-example.eqs.ps,width=12cm}}
  \caption{\label{FIG:Bool-example.eqs}Editor for the equations of {\tt Bool-example}}
\end{figure}

\subsubsection{The Module Editor for {\tt Bool-example}}

\begin{itemize}
  
\item Select module {\tt Bool-example} from the module pane (the vertical list
  of module names that now only contains {\tt Bool-example}) by clicking on it
  once.
  
\item Push the button {\tt Edit Syntax} in the button pane at the right-hand
  side of the main window.  An editor will appear containing the syntax part
  of the {\tt Bool-example} specification: the \sdf\ section.  This editor is a
  version of the standard text editor Emacs extended with the menu {\tt
    Meta-Environment}. The result is shown in Figure~\ref{FIG:Bool-example.sdf2}.
  
\item Push the button {\tt Edit Equations}.  This will reuse the already created
  instance of Emacs by adding a new buffer to it containing the semantic part
  of the {\tt Bool-example} specification: a list of conditional equations.
  Note that the syntax of the equations is determined by the syntax defined in
  the \sdf\ section. Use the {\tt Buffers} menu of Emacs to see which buffers
  are open and to switch between buffers.
The result is shown in Figure~\ref{FIG:Bool-example.eqs}.

\end{itemize}


\begin{figure}[t]
  \centerline{\epsfig{file=Bool-example.trm.ps,width=12cm}}
  \caption{\label{FIG:Bool-example.trm}Term editor for {\tt Bool-example} after entering `{\tt true \& false}'}
\end{figure}

\begin{figure}[t]
  \centerline{\epsfig{file=Bool-example.trm2.ps,width=12cm}}
  \caption{\label{FIG:Bool-example.trm2} Same term editor as in Figure~\ref{FIG:Bool-example.trm} after parse}
\end{figure}

\begin{figure}[t]
  \centerline{\epsfig{file=Bool-example.trm3.ps,width=12cm}}
  \caption{\label{FIG:Bool-example.trm3}Term editor for {\tt Bool-example} after clicking on `{\tt false}'}
\end{figure}

\subsubsection{A Term Editor for {\tt Bool-example}}

\begin{itemize}
\item Open a term-editor over module {\tt Bool-example} by first selecting
  module {\tt Bool-example} in the module pane, and then pushing the {\tt
    Term} button.  A dialog window pops up\footnote{
    In following releases this will be changed into a standard file dialog}
    Enter any new filename, for instance, `{\tt my-term}'.

\item 
  Type the term `{\tt true \& false}' in this editor. Observe how the text
  that you type gets a light blue background.
  This is called a \emph{focus}. The result is shown in Figure~\ref{FIG:Bool-example.trm}.

\item Click in the focus, this will move the cursor (a single character-sized
  red rectangle) 
  
\item From menu {\tt Meta-Environment} click the {\tt Parse} button.  The text
  in the focus is now parsed and the blue background has disappeared.
  The result is shown in Figure~\ref{FIG:Bool-example.trm2}.

\end{itemize}

All the text\emph{ outside} the focus is (by definition) always syntactically
correct. The text \emph{inside} the focus is fresh text which may contain syntax
errors.

\begin{itemize}

\item Click on one of the characters of the word `{\tt false}'.  You
have selected `{\tt false}' as new focus and the blue background
reappears. This is shown in Figure~\ref{FIG:Bool-example.trm3}.

\item Click on the \emph{and} operator `{\tt \&}'.  The whole expression is
  now selected as focus.

\end{itemize}

The movements of the focus are \emph{syntax-directed}: when you click on any
character in the text, the smallest syntactic unit enclosing that character
will be selected and becomes the focus.

\begin{itemize}
  
\item Reduce the term in the term-editor by clicking the {\tt Reduce} button
  in the {\tt Meta-Environment} menu of the editor.  The result will appear in
  the terminal window from which the Meta-Environment was started.

\end{itemize}

\paragraph{Error-messages}

\begin{itemize}
  
\item Edit the term `{\tt true \& false}' such that the new term will be
  syntactically incorrect. For instance, type `{\tt true \& wrong}'. Force a
  parse of the term by selecting the {\tt Parse} button of the 
  {\tt Meta-Environment} menu.
  
  In the status line at the bottom of the edit window a message will appear
  message `{\tt Parse error near cursor}' and the cursor will be positioned in
  the word `{\tt wrong}'

\end{itemize}

\paragraph{Associativity, Priorities and Brackets}

\begin{itemize}
  
\item Erase the term in your term-editor and type a new term `{\tt true \&
    false \& true}'. 

\item Parse the term using the {\tt Parse} button.

\item  Try to find out how this term has been parsed by clicking
  on different parts of the term and studying the resulting focus.

\end{itemize}

The {\tt left} attribute in the \sdf\ definition indicates that the `{\tt \&}'
operator is left associative. The term will thus be parsed as `{\tt (true \&
  false) \& true}'. Clicking on the left or right {\tt \&} yields a focus that
corresponds with this parse.

\begin{itemize}
  
\item Erase the term in your term-window and type a new term `{\tt true |
    false \& true}'. 
\item Parse the term using the {\tt Parse} button.
  
\item Try to find out how this term has been parsed by clicking on various
  parts of the term and studying the resulting focus.

\end{itemize}

The {\tt context-free priorities} definitions in the \sdf\ 
definition state that the `{\tt
  \&}' operator binds stronger than the `{\tt |}' operator.

\begin{itemize}
  
\item Erase the term in the term-editor and type a new term `{\tt true \&
    false}'.  Click on `false', so that the focus is around `false' only. Then
  add `{\tt | true}' after `{\tt false}', so that the resulting term is `{\tt
    true \& false | true}'.  

\item Parse the term.

\item Click on the `{\tt \&}' symbol. Is this what you wanted? Probably not.
\end{itemize}
  
To resolve a priority conflict `{\tt (}' and `{\tt )}' which are defined as
brackets in the \sdf\ definition are put around the term `{\tt false | true}'.
Thus `{\tt true \& (false | true})' is more likely to express what you
intended.

\subsubsection{Modifying {\tt Bool-example}}

The \ASmetaenv\ is an \emph{incremental environment generator}. After
each edit operation on a module, its \emph{implementation} (i.e., scanner, parser and
term rewriting system) is updated immediately.

The editing of both the syntax section and the equations secion of a module is
syntax-directed like the editing of terms in a term editor.

\paragraph{Modifying the Equations}

The equation section of a module begins with the keyword {\tt equations}
and is saved in files ending on `{\tt .eqs}'.

\begin{itemize}

\item  Click in the equation section to investigate the focus behavior.
  
\item Change the equations, for instance replace in equation {\tt [B1]} the
  last part `{\tt = true}' by `{\tt = false}'. 
  
\item Study the effect on the reduction of terms in the term-editor.

\end{itemize}

\paragraph{Modifying the Syntax}

The syntax part of a module starts with the keyword {\tt module}
and  is saved in files ending on `{\tt .sdf2}'.
Modifying the syntax causes the generated scanner and parser to be adapted.
After each edit operation in the \sdf\ section that is followed by a parse of
the \sdf\ section, the focus in both the equations section and the term editor
is extended to completely contain the text in these editors.

Modifying the context-free syntax:

\begin{itemize}
  
\item Change the syntax of the defined functions. E.g, replace `{\tt not}' by
  `{\tt negation}'.

\item Try to re-parse the equations. 
  
%%\item Investigate the expand menu in the term-editor. (type `{\tt <BOOL>}' and
%%  select {\tt expand}.)

\end{itemize}

Modifying the priorities: 

\begin{itemize}

\item Remove the priority declaration. 
  
\item Type the term `{\tt true \& false | true}' in the term-editor (or
  anything similar according to your current syntax). Try to parse this term.

\item Add the priority declarations again.

\end{itemize}

Modifying layout in the lexical section: 

\begin{itemize}

\item Remove the lexical syntax with the {\tt LAYOUT} definitions. 

\item Try parsing equations of {\tt Bool-example}.

\end{itemize}

\paragraph{Note:} Not defining {\tt LAYOUT} is one of the errors most commonly
made when writing a new specification; always make sure your syntax
definitions define at least spaces and newlines to be {\tt LAYOUT}.

\begin{itemize}
  
\item End the editing of your term and the module {\tt Bool-example} by
  selecting the {\tt Exit XEmacs} from the {\tt File} menu of the editor.  You
  may or may not save the changes to module Bool-example.

\end{itemize}

If you save the changes the files `{\tt Bool-example.sdf2}' and `{\tt
  Bool-example.eqs}' will be modified.


\begin{itemize}
  
\item Delete the module {\tt Bool-example} from the specification.  Click on
  {\tt Bool-example} in the module pane and push the {\tt Delete} button. The
  module remains known to the system and its graphical representation is
  changed form a rectangle to an ellipse. It can be re-opened later on.
  
\item Leave the system by pushing the {\tt Quit} entry in the {\tt File} menu
  of the main window of the \ASmetaenv.

\end{itemize}

\begin{figure}[t]

  \centerline{\epsfig{file=meta-Pico-syntax.ps,width=12cm}}
  \caption{\label{FIG:Pico-syntax} Main window after opening {\tt Pico-syntax}}

\end{figure}

\subsection{The Pico Specification}

More features of the  \ASmetaenv\  can be studied by looking at the
Pico specification.


\begin{figure}[t]

  \centerline{\epsfig{file=Pico-Booleans.sdf2.ps,width=12cm}}
  \caption{\label{FIG:Pico-Booleans-sdf2}Editor for syntax of {\tt Pico-Booleans}}

\end{figure}


\begin{figure}[t]

  \centerline{\epsfig{file=Pico-Booleans.eqs.ps,width=12cm}}
  \caption{\label{FIG:Pico-Booleans-eqs}Editor for equations of {\tt Pico-Booleans}}

\end{figure}


\begin{itemize}

\item Open the module {\tt Pico-Booleans} and study the differences in
syntax and equations with {\tt Bool-example}. 

\end{itemize}

Editors for syntax and equations of {\tt Pico-Booleans} are show in
Figures \ref{FIG:Pico-Booleans-sdf2} and \ref{FIG:Pico-Booleans-eqs}.


\begin{itemize}
  
\item Start the Meta-Environment: go to directory {\tt
    pico}, and type `{\tt meta}'.
  
\item Add the module {\tt Pico-syntax} by selecting the {\tt File} menu, and
  choosing the {\tt Open...} button.  In the dialog window that appears, click
  on {\tt Pico-syntax.sdf2} and push the {\tt Open} button.
  
\item As you can see in both the import pane and the module pane, not only
  {\tt Pico-syntax} has been added, but also all modules that are directly or
  transitively imported by {\tt Pico-syntax}. See Figure~\ref{FIG:Pico-syntax}.

\end{itemize}

\subsubsection{The Module Editor for Pico-syntax}

\begin{itemize}
  
\item Open an editor for the syntax of {\tt Pico-syntax} (using the {\tt Edit
    Syntax} button).

\end{itemize}
  
  A Pico program consist of the word `{\tt begin}', a declaration section, a
  series of zero or more statements, and the word `{\tt end}'. The declaration
  section consists of the word `{\tt declare}', a list of zero or more tuples
  `{\tt $identifier$ : $type$}' and a semi-colon `{\tt ;}'. Types are `{\tt
    string}' and `{\tt natural}'.  There are three kinds of statements:
  assignments, if-then-else statements and while-loops. And there are
  expressions.

\paragraph{Notes:}

\begin{itemize}
  
\item A module {\tt Layout} is imported, in which the 
sort {\tt LAYOUT} has been
  specified.
  
\item The use of list constructs in the context-free section: 
`{\tt \{ID-TYPE ","\}*}' and 
`{\tt \{STATEMENT ","\}*}'. In fact, the sort {\tt SERIES}
  could have been left out entirely and be replaced by 
`{\tt \{STATEMENT ","\}*}' all through the specification. 
{\tt SERIES} is only used for
  abbreviation in the syntax rules. Also, variables over list constructs are
  being declared.
  
\item When a literal in a context-free function consists only of lower case
  letters and digits, and it is not a \sdf-keyword, it need not be quoted.

\item  The Pico-syntax module naturally contains no equations.

\end{itemize}

\subsubsection{A Term Editor for Pico-syntax}

\begin{itemize}
  
\item Open a term-editor for the Pico-program `{\tt small.pico}': select {\tt
    Pico-syntax} in the module pane and push the {\tt term} button in the
  button pane. A dialog window pops up and type `{\tt small.pico}' as name of
  the term.

\item Press the {\tt Parse} button in the {\tt Meta-Environment} menu of the
  editor. As a result, {\tt small.pico} is parsed.

\item Press the {\tt Reduce} button in the {\tt Meta-Environment} menu of the
  editor.

\end{itemize}

This has the following effects:

\begin{itemize}

\item  The term in the editor is parsed. 
  
\item All the equations that are valid for this editor are parsed and compiled
  into a rewrite system.  In this case that means the equations of the
  imported modules {\tt Pico-Booleans}, {\tt Pico-Integers}, {\tt Pico-Strings} and {\tt
    Pico-Types}. This takes some time.
  
\item The term in the editor is reduced. As no equation can be applied to
  reduce this term, the term itself is returned in the shell window from which
  the Meta-Environment has been started.
\end{itemize}

  
Reducing a term for the second time is notably faster: the equations have been
compiled already. If you are curious what is going, have a look at the
status field at the bottom of the main window. It reveals the steps that
are necessary to arrive at an executable specification.

\begin{itemize}
\item Verify this by pushing the {\tt Reduce} button once more.
\end{itemize}

\begin{itemize}

\item Load the module {\tt Pico-typecheck} in the Meta-Environment.

\item Open a term editor for the term {\tt smalltc.pico}.

\item Reduce this term.

\end{itemize}

This has the following effects:

\begin{itemize}

\item  The module {\tt Pico-typecheck} is added to the specification. 
  
\item The term in {\tt smalltc.pico} is identical to the one in 
  {\tt small.pico}, except that the program has been surrounded by `{\tt tcp(}'
  and `{\tt )}'.  The function {\tt tcp} (for type check program), applies the
  typing rules for the Pico language to its single argument: a complete Pico
  program. The result is {\tt true} or {\tt false}.
  
\item All equations of {\tt Pico-typecheck} and its imported
  modules are being compiled.
  
\item The term {\tt smalltc.pico} is reduced using the equations of {\tt
    Pico-typecheck}.

\end{itemize}
  
Typechecking a term for the second time is notably faster, the
modules have been added already and the equations have been compiled.

\begin{itemize}

\item Verify this, by pushing {\tt Reduce} once more.
  
\item Make some modifications to `{\tt smalltc.pico}' in the term-editor.
  Typecheck the modified program.
  
\item Open term-editors with other pico programs (`{\tt fac.pico}', `{\tt
    big.pico}') or create your own program. The corresponding applications of
  the type check function are in `{\tt factc.pico}' and `{\tt bigtc.pico}', 
  respectively.  Typecheck these programs.

\end{itemize}

The evaluation (execution) of programs is achieved in a similar fashion as
typechecking. The evaluation rules are defined in the module `{\tt
  Pico-eval}'. Applications of the evaluation function `{\tt evp}' can be
found in `{\tt smallev.pico}', `{\tt facev.pico}', and `{\tt bigev.pico}.

\begin{itemize}
  
\item Repeat the steps described above for typechecking, now for the
  evaluation of Pico programs.

\end{itemize}

\subsubsection{More Exercises to Study the Pico Specification}

\begin{itemize}

\item Study other modules in the specification. The modules {\tt
    Pico-typecheck} and {\tt  Pico-eval} are explained in the next sections.
  
\item Add a repeat statement `{\tt repeat SERIES until EXP}' to {\tt
    Pico-syntax}, add typecheck equations to {\tt Pico-typecheck}, and
  eval-equations to {\tt Pico-eval}, for this new statement.

\item Add your own module to the specification. 

\item Make your own specification. Create a new directory for each
  specification.

\end{itemize}

\subsubsection{Module Pico-typecheck}

\begin{itemize}

\item Open an editor for the syntax of {\tt Pico-typecheck}.

\end{itemize}

The function `{\tt tcp}' is defined for typechecking Pico-programs.
Variants of this function exist for typechecking various parts of a Pico program. 
The
typechecking of the declarations yields a type-environment: a table of
identifiers and their types. This type-environment, and the `{\tt lookup}'
function is specified in the module {\tt Type-environments}. The typechecking
of statements uses a type-environment and yields a Boolean value.


\begin{itemize}

\item Open an editor for the equations of {\tt Pico-typecheck}.

\end{itemize}

In the equations is defined how a Pico-program is typechecked. Equation {\tt
  [Tc1]} says that the typechecking of a program is `{\tt true}' if the
typechecking of the Series in the type-environments, `{\tt tcd(Decls)}', is
`{\tt true}'.

Equations {\tt [Tc2]} and {\tt [Tc3]} specify how a type-environment is
constructed, when the declarations are typechecked.

Equations {\tt [Tc3a]} and {\tt [Tc3b]} specify the typechecking of a,
possibly empty, list of statements. Equations {\tt [Tc4a]} through {\tt
  [default-Tc6]} specify how the three kinds of Statements are typechecked
using the information from the type-environment.

The rest of the equations deal with the typechecking of expressions.

\subsubsection{Module Pico-eval}

\begin{itemize}

\item Open an editor for the syntax of {\tt Pico-eval}.

\end{itemize}

The functions `{\tt evp}' and variants are defined for describing the dynamic semantics of
Pico. The result of evaluation is a value-environment: a table of identifiers
and values with the final values of the declared identifiers. (Note that Pico
does not have an output-statement.)


\begin{itemize}

\item Open an editor for the equations of {\tt Pico-eval}.

\end{itemize}

In the equations is defined how a program is evaluated. Equation {\tt [Ev1]}
says that the evaluation of a program is the evaluation of the Series in the
value-environments, `{\tt evs(Decls)}'.

Equations {\tt [Ev2]} thorugh {\tt [Ev3c]}  specify how a
value-environment is constructed, when the declarations are evaluated.
Identifiers of type `{\tt natural}' get value `{\tt 0}', Identifiers of type
`{\tt string}' get value `{\tt ""}' (the empty-string).

Equations {\tt [Ev4a]} and {\tt [Ev4b]} specify the evaluation of a, possibly
empty, list of statements. Equations {\tt [Ev5a]} through {\tt [Ev5e]}
specify how the three kinds of statements are
evaluated using the information from the type-environment. Evaluating
statements means updating the value-environment.

The rest of the equations deal with the evaluation of expressions. Evaluating
expressions results in a value.

\section{An Introduction to \asfsdf} \label{ASF+SDF}

\asfsdf\ is the result of the marriage of two formalisms \asf\ (Algebraic
Specification Formalism) and \sdf\ (Syntax Definition Formalism).  \asf\ is
based on the notion of a module consisting of a signature defining the
abstract syntax of functions and a set of conditional equations defining their
semantics. Modules can be imported in other modules. \sdf\footnote{To be more
  precise, we will describe here \sdf2, a new version of \sdf. \sdf2 is more
  expressive and offers some special features to write more powerfull lexical
  grammar definitions as well as more concise context-free grammar
  definitions. However, some built-in features of \sdf, like lexical
  disambiguation, have disappeared, and a specification writer has to be aware
  of this.
  
  Currently, the \ASmetaenv\ only supports a subset of \sdf2\ that is mostly
  compatible with \sdf. In due time, full \sdf2\ will be supported. In this
  manual, we only describe features that are supported by the current version
  of the Meta-Environment.} allows the simultaneous definition of concrete
(i.e., lexical and context-free) and abstract syntax and implicitly defines a
translation from text strings to abstract syntax trees.

The main idea of \asfsdf\ is to identify the abstract syntax defined by the
signature in \asf\ specifications with the abstract syntax defined 
implicitly by an \sdf\ specification, thus yielding a standard mapping 
from text to abstract syntax tree. This gives the possibility to 
associate semantics with (the tree representation of) text and to 
introduce user-defined notation in specifications.

\asfsdf\ is therefore a modular specification formalism for the integrated
definition of syntax and semantics.

\subsection{Modules and Modular Structure}
\label{modules}

An \asfsdf\ specification consists of a sequence of module declarations. Each
module may define syntax rules as well as semantic rules and the notation used
in the semantic rules depends on the definition of syntax rules. The entities
declared in a module may be visible or invisible to other modules. A module
can use another module from the specification by importing it. As a result,
all visible names of the imported module become available in the importing
module.

The overall structure of a module is:

\begin{verbatim}
module <ModuleName>

  <ImportSection>*
 
  <ExportOrHiddenSection>*

equations
  <ConditionalEquation>*
\end{verbatim}

A module consists of a module header, followed by a list of zero or more
import sections, followed by zero or more hidden or exported
sections and an optional equations section that defines conditional equations.

Conceptually, a module is a single unit but for technical reasons the
syntax sections and the equations section are stored in physically
separate files.  For each module $M$ in a specification two files
exist: `{\tt $M$.sdf2}' contains the syntax sections of $M$ and `{\tt
$M$.eqs}' contains the equations section of $M$.

A {\tt <Section>} is either an \emph{export section} or a \emph{hidden
  section}. The former starts with the keyword {\tt exports} and makes all entities
in the section visible to other modules.  The latter starts with the keyword
{\tt hiddens} and makes all entities in the section local to the module.

A {\tt <Section>} has the form:

\begin{verbatim}
exports-or-hiddens
  <Grammar>+
\end{verbatim}
  
\noindent A {\tt <Grammar>} 
can be a definition of one of the following: 
\begin{itemize}
\item imports (Section~\ref{Imports});
\item sorts (Section~\ref{Sorts});
\item lexical syntax (Section~\ref{LexicalSyntax});
\item context-free syntax (Section~\ref{ContexFreeSyntax});
%\item lexical variables;
%\item lexical priorities;
\item context-free priorities (Section~\ref{ContextFreePriorities});
%\item priorities;
\item lexical restrictions (Section~\ref{Restrictions});
\item context-free restrictions (Section~\ref{Restrictions});
\item variables (Section~\ref{Variables}).
%\item restrictions;
%\item aliases;
\end{itemize}

\noindent Each of these entities will now be described and illustrated by examples.

\subsection{Imports} \label{Imports}

Each {\tt <ImportSection>} starts with the keyword {\tt imports} followed
by one or more module names.
%module name should be imports where, an import is either a module name
%or a module name followed by renamings.
An {\tt <ImportSection>} has the form:

\begin{verbatim}
imports
  <ModuleName>+
\end{verbatim}

\begin{sloppypar}
\noindent Modules can be combined by importing one module in another. 
Imports can occur as {\tt <ImportSection>} at the topmost level of a module
or they can occur within an exports or hiddens section.
\end{sloppypar}

When importing modules at the topmost level of a module or when the import
section occurs within the scope of an exports keyword, all exported entities
of the imported module (and of all modules that are imported indirectly by it)
become available in the importing module. In addition, they are also exported
by the importing module.  However, if the import section occurs within the
scope of a hiddens keyword, the exported entities are only visible in the
importing module but they are not exported by the importing module.

\subsection{Sorts} \label{Sorts}

Sorts are declared by listing their name in a sorts section of a
module.

\begin{verbatim}
sorts
  <SortName>+
\end{verbatim}

\noindent A sort name should start with a capital letter and may be followed by 
letters and/or digits. Hyphens (`{\tt -}') may be embedded in sort names.
There is one predefined sort name ({\tt LAYOUT}). We will describe it in
Section~\ref{LexicalSyntax}.

\subsection{Lexical Syntax} \label{LexicalSyntax}
\label{lexical-syntax}

The lexical syntax describes the low level structure of text by means of
\emph{lexical tokens}. A lexical token consists of a sort name (used to
distinguish classes of tokens like identifiers and numbers), and the actual text
of the token. The lexical syntax also defines which substrings of the text are
layout symbols or comments and are to be skipped.

A lexical syntax contains a set of declarations for \emph{lexical functions},
each consisting of a regular expression and a result sort. All functions with
the same result sort together define the lexical syntax of tokens of that
sort. Regular expressions may contain strings, sort names, character classes,
optional operators, alternative operators, and repetition operators.  These
notions will be explained in the next subsections.  Spaces are only
significant inside strings and character classes.

The sort name {\tt LAYOUT} is predefined and may not be redeclared.  {\tt
  LAYOUT} defines which parts of the text are \emph{layout symbols} (also
known as \emph{white space}) between lexical tokens and are to be skipped
during lexical analysis. It may only be used as result sort of lexical
functions (Section~\ref{LexicalFunctions}). When a string is matched by both a
LAYOUT function and by other non-LAYOUT functions, then the interpretation as
layout symbol is ignored. {\tt LAYOUT} is typically used for defining layout
and comment conventions.

Traditionally, lexical syntax and context-free syntax are treated
differently.  They are defined by different notations and implemented
by means of different techniques. \sdf\ provides a much more uniform
treatment.  In \sdf, the only significant difference between the two
is that no layout will be accepted while recognizing the members of
the left-hand side of a lexical function, whereas layout \emph{will}
be accepted between the members of the left-hand side of a
context-free function. At the implementation level, both are
implemented using a single parsing technique.

Technically, there exist only \emph{syntax} sections. Both lexical
syntax sections and context-free syntax sections are transformed into
such syntax sections after appropriate insertion of optional layout
between the elements of context-free functions. In rare cases,
the specification writer may want to control this process explicitly
and write syntax sections directly. This will not be discussed
in this manual, but further details can be found in \cite{Vis9?.thesis}.

\subsubsection{Lexical Functions} \label{LexicalFunctions}

In their simplest form, declarations of lexical functions consist of a
sequence of zero or more strings or sort names followed by `{\tt ->}'
and the name of a result sort, say $L$.  A lexical function may be
followed by a list of attributes. The regular expression associated
with $L$ consists of the \emph{or} of all left-hand sides of lexical
functions with result sort $L$.  All sort names appearing in left-hand
sides of declarations are replaced by the regular expression
associated with them. Circular dependencies between declarations in
the lexical syntax are forbidden.  Figure \ref{CODE:simplelex} shows
an example of a simple lexical function definition for defining the
first three words that Dutch children learn to read.  The three sorts
{\tt Aap}, {\tt Noot} and {\tt Mies}, each recognize, respectively,
the strings {\tt aap}, {\tt noot} and {\tt mies}. The sort {\tt
LeesPlank} recognizes the single string {\tt aapnootmies}.


\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module LeesPlank

imports Layout

exports
  sorts Aap Noot Mies
  lexical syntax
    "aap"         -> Aap
    "noot"        -> Noot
    "mies"        -> Mies
    Aap Noot Mies -> LeesPlank
\end{boxedverbatim}
\end{IncCode}
\caption{Simple lexical functions}\label{CODE:simplelex}
\end{figure}   
      

\paragraph{Lexical constructor functions}%
\hspace{-0.3cm}\footnote{Lexical contructor functions will disappear when full \sdf2\ becomes available in the \ASmetaenv.}
For each sort that appears as result sort in the lexical syntax a lexical
constructor function of the form {\tt l "(" CHAR+ ")" -> L} is automatically
added to the context-free syntax of the specification.  Here, `{\tt l}' is the
name of sort `{\tt L}' written in lower case letters.  In this way, you can
get access to the text of lexical tokens.

\subsubsection{Character Classes}

Enumerations of characters occur frequently in lexical definitions. They can
be abbreviated by using character classes enclosed by `{\tt [}' and 
`{\tt ]}'. 
A character class contains a list of zero or more characters (which
stand for themselves) or character ranges such as, for instance, {\tt [0-9]}
as an abbreviation for the characters {\tt 0}, {\tt 1}, ..., {\tt 9}. 
In a character range of the form {\tt $c_1$-$c_2$} one of the following 
restrictions should apply:

\begin{itemize}
\item $c_1$ and $c_2$ are both lower case letters and $c_2$ follows $c_1$ in
  the alphabet, or 
\item $c_1$ and $c_2$ are both upper case letters and $c_2$ follows $c_1$ in
  the alphabet, or 
\item $c_1$ and $c_2$ are both digits and the numeric value of $c_2$ is
  greater than that of $c_1$, or 
\item $c_1$ and $c_2$ are both escaped non-printable characters and the 
character code of $c_2$ is larger than that of $c_1$.
\end{itemize}

Definitions for lower case letter ({\tt LCLetter}), uppercase letters
({\tt UCLetter}), lower and upper case letters ({\tt Letter}) and
digits ({\tt Digit}) are shown in Figure~\ref{CODE:LettersDigits1}.
Figure~\ref{CODE:LettersDigits2} gives
a definition of the sort {\tt LetterOrDigit} that recognizes a single letter
(upper case or lower case) or digit.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module LettersDigits1

imports Layout

exports
  sorts LCLetter UCLetter Letter Digit
  lexical syntax
    [a-z]    -> LCLetter
    [A-Z]    -> UCLetter
    [a-zA-Z] -> Letter
    [0-9]    -> Digit
\end{boxedverbatim}
\end{IncCode}
\caption{Defining letter (lower case and upper case) and digit}\label{CODE:LettersDigits1}
\end{figure}   

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module LettersDigits2

imports Layout

exports
  sorts LetterOrDigit
  lexical syntax
    [a-z]    -> LetterOrDigit
    [A-Z]    -> LetterOrDigit
    [0-9]    -> LetterOrDigit
\end{boxedverbatim}
\end{IncCode}
\caption{Defining a single letter or digit}\label{CODE:LettersDigits2}
\end{figure}   

\paragraph{Escape Conventions}

Characters with a special meaning in \asfsdf\ may cause problems when they are
needed as ordinary characters in the lexical syntax. The backslash character
(`{\tt \verb+\+}') is used as escape character for 
the quoting of special characters. You
should use `{\tt \verb+\+$c$}' whenever you need special 
character $c$ as ordinary character in a definition.
All individual characters, except digits and letters,
are {\em always} escaped with a backslash.

In literal strings, the following characters are special and should be
escaped:

\begin{itemize}
 \item {\tt "}: double quote 
\item \verb+\+: escape character.
\end{itemize}

You may use the following abbreviations in literals and in character classes:

\begin{itemize}

\item \verb+\n+: newline character 

\item \verb+\r+: carriage return

\item \verb+\t+: horizontal tabulation 

\item \verb+\+$nr$: a non-printable character with the decimal code $nr$.

\end{itemize}

\paragraph{Character Class Operators}

The following operators are available for character classes
\begin{itemize}
\item {\tt \~{}}: complement of character class. Accepts all characters not in the original class.
\item {\tt /}: difference of two character classes. Accepts all characters in
  the first class unless they are in the second class.
\item {\tt  /\verb+\+}: intersection of two character classes. Accepts all
  characters that are accepted by both character classes.
\item {\tt  \verb+\+/}: union of two character classes. Accepts all characters
  that are accepted by either character class.
\end{itemize}
\noindent The first operator is a unary operator, whereas the other three are
left-associative binary operators.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module LettersDigits3
exports
  sorts LetterOrDigit
  lexical syntax
    [a-z] \/ [A-Z] \/ [0-9]   -> LetterOrDigit
\end{boxedverbatim}
\end{IncCode}
\caption{Defining a single letter or digit using the alternative operator}\label{CODE:LettersDigits3}
\end{figure}

Figure~\ref{CODE:LettersDigits3} shows the definion of a single letter or digit
using the alternative operator {\tt  \verb+\+/}.
This definition is equivalent to the one given earlier in ~\ref{CODE:LettersDigits2}.
Another example is shown in Figure \ref{CODE:charclasses}.
This definition of characters contains
all possible characters, either by means of the ordinary representation
or via the decimal representation of characters. The character class union
is used as a kind of abbreviation mechanism.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Characters

imports Layout

exports
  sorts AlphaNumericalEscChar DecimalEscChar EscChar L-Char
  lexical syntax
    "\\" ~[]                 -> AlphaNumericalEscChar

    "\\" [01] [0-9] [0-9]    -> DecimalEscChar
    "\\" "2" [0-4] [0-9]     -> DecimalEscChar
    "\\" "2" "5" [0-5]       -> DecimalEscChar

    AlphaNumericalEscChar    -> EscChar
    DecimalEscChar           -> EscChar

    ~[\0-\31\"\\] \/ [\t\n]  -> L-Char
    EscChar                  -> L-Char
\end{boxedverbatim}
\end{IncCode}
\caption{Example of character classes}\label{CODE:charclasses}
\end{figure}  

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Identifiers-repetition

imports Layout

exports
  sorts Let NumLet
  lexical syntax
    [a-z]       -> Let
    [a-z0-9]    -> NumLet

    Let NumLet* -> Id
\end{boxedverbatim}
\end{IncCode}
\caption{Defining identifiers using the repetition operator {\tt *} }\label{CODE:repetition}
\end{figure}   

\subsubsection{Repetition Operators}

It is common, that lexical tokens can only be described by patterns that
exhibit a certain repetition. Two postfix operators are available for this
purpose:

\begin{itemize}

\item {\tt *}: indicates zero or more repetitions of the sort, literal or
  character class preceding the {\tt *}. 

\item {\tt +}: indicates one or more repetitions of the sort, literal or
  character class preceding the {\tt +}.

\end{itemize}

\noindent Figure \ref{CODE:repetition} shows the use of the repetition
operator {\tt *} for defining identifiers consisting of a letter
followed by zero or more letters or digits.


\subsubsection{The Option Operator}

If zero or exactly one occurence of a lexical token is desired the
postfix operator {\tt ?} is available. It indicates that there
should be zero or one occurence of the sort, literal or
character class preceding the {\tt ?}. 

Figure \ref{CODE:option} shows the use of the option operator.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Identifiers-optional

imports Layout

exports
  sorts Let Num
  lexical syntax
    [a-z]+   -> Let
    [0-9]    -> Num

    Let Num? -> Id
\end{boxedverbatim}
\end{IncCode}
\caption{Defining a letter followed by an optional number using the option operator {\tt ?} }\label{CODE:option}
\end{figure}   

\subsubsection{The Alternative Operator}

Functions with the same result sort together define the lexical syntax of
tokens of that sort. The left-hand sides of these function definitions form
the alternatives for this function. Sometimes, it is more convenient to list
these alternatives explicitly in a single left-hand side or to list
alternative parts inside a left-hand side.  This is precisely the role of the
binary alternative operator (`{\tt |}'). It is right-associative and binds
stronger than ordinary juxtapostion of the elements in a definition (the
invisible operator for the concatenation of tokens).

The example  in Figure \ref{CODE:alternative1} shows how this operator can be used.
It describes identifiers starting
with a capital letter followed by one of the following:
\begin{itemize}
\item  zero or more small letters, 

\item zero or more capital letters, or

\item zero or more digits.
\end{itemize}

\noindent According to this definition, 
{\tt Aap}, {\tt NOOT}, and {\tt B49} are acceptable, but {\tt MiES}, {\tt
  B49a} and {\tt 007} are not.

Note that the relation between juxtapostion and alternative operator is best
understood by looking at the line defining {\tt Id}. A parenthesized
version of this same line would read as follows:
\begin{quote}
\begin{verbatim}
  UcLet (ScLets | UcLet* | Digs) -> Id
\end{verbatim}
\end{quote}

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Identifiers-alternative1

imports Layout

exports\
  sorts UcLet ScLets Digs
  lexical syntax
    [A-Z]    -> UcLet
    [a-z]*   -> ScLets
    [0-9]*   -> Digs

  UcLet ScLets | UcLet* | Digs -> Id
\end{boxedverbatim}
\end{IncCode}
\caption{Example of alternative operator {\tt |} }\label{CODE:alternative1}
\end{figure}   

\noindent An equivalent, and more readable, definition is
given in Figure \ref{CODE:alternative2}. We recommend to use parentheses to
make the scope of alternatives explicit.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Identifiers-alternative2

imports Layout

exports
  sorts UcLet ScLets Digs
  lexical syntax
    [A-Z]    -> UcLet
    [a-z]*   -> ScLets
    [0-9]*   -> Digs

    (UcLet ScLets) | (UcLet UcLet*) | (UcLet Digs) -> Id
\end{boxedverbatim}
\end{IncCode}
\caption{Example of alternative operator {\tt |} }\label{CODE:alternative2}
\end{figure}   


\subsubsection{Examples of Lexical Syntax Definitions}

We will present a number of non-trivial lexical syntax definitions
in order to get some ideas what can be specified using 
\sdf.

\paragraph{Defining Numbers}

Definitions of integers and real numbers are shown in Figure
\ref{CODE:numbers}. Note the use of the alternative operator in the
definitions of {\tt UnsignedInt} and {\tt Number}.  Also note the use
of the option operator in the definitions of {\tt SignedReal} and {\tt
UnsignedReal}.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Numbers

imports Layout

exports
  sorts UnsignedInt SignedInt UnsignedReal Number 

  lexical syntax
    [0] | ([1-9][0-9]*)                           -> UnsignedInt

    [\+\-]? UnsignedInt                           -> SignedInt

    UnsignedInt "." UnsignedInt ([eE] SignedInt)? -> UnsignedReal 
    UnsignedInt [eE] SignedInt                    -> UnsignedReal

    UnsignedInt | UnsignedReal                    -> Number
\end{boxedverbatim}
\end{IncCode}
\caption{Lexical definition of Numbers}\label{CODE:numbers}
\end{figure}   

\paragraph{Defining Strings}

Figure \ref{CODE:string} gives the lexical definition of
strings which may contain escaped double quote characters.
It defines a {\tt StringChar} as either
\begin{itemize}
\item zero or more
arbitrary characters except double quote or newline, or
\item an escaped double quote, i.e., \verb+\"+.
\end{itemize}

\noindent A string consists of zero or more {\tt StringChar}s surrounded by
double quotes.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Strings

imports Layout

exports
  sorts String StringChar

  lexical syntax
    ~[\"\n]*              -> StringChar
    [\\][\"]              -> StringChar
    "\"" StringChar* "\"" -> String
\end{boxedverbatim}
\end{IncCode}
\caption{Lexical definition of String}\label{CODE:string}
\end{figure}   

\subsection{Context-free Syntax} \label{ContexFreeSyntax}

The context-free syntax describes the concrete and abstract syntactic
structure of sentences in a language. A context-free syntax contains a set of
declarations for \emph{context-free functions}, each consisting of zero or
more literals, sort names, or lists followed by `{\tt ->}' and a result sort.
They may be followed by attributes that control how parentheses and brackets
affect the abstract syntax, by attributes that define the associativity of a
rule, or by attributes which influence the rewriting process. 
All functions with the same result sort together define the alternatives
for that sort.

Members in the left-hand side of a context-free function
are separated by an invisible non-terminal {\tt LAYOUT?} 
(optional {\tt LAYOUT}) in order to permit layout between these members.
This optional layout non-terminal is automatically inserted by the
parser generator.
%%\footnote{\sdf2 offers the possibility to write
%%down syntax rules in which the optional layout non-terminal
%%is {\em not} automatically inserted. These rules should
%%be written in the {\tt syntax}-section.}.

\subsubsection{Context-free Functions}

In their simplest form, declarations of context-free functions consist of a
sequence of zero or more literal strings or sort names followed by `{\tt ->}'
and the name of a result sort. All literal strings appearing in a context-free
function declaration are implicitly added to the lexical syntax. Consider the
language of coordinates and drawing commands presented in 
Figure \ref{CODE:simple-cf}.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module DrawingCommands

imports Layout

exports
  sorts NAT COORD CMND 

  lexical syntax
    [0-9]+ -> NAT 

  context-free syntax
    "(" NAT "," NAT ")" -> COORD
    "line" "to" COORD   -> CMND 
    "move" "to" COORD   -> CMND
\end{boxedverbatim}
\end{IncCode}
\caption{Simple context-free syntax definition}\label{CODE:simple-cf}
\end{figure}   


An equivalent conventional BNF grammar (and not considering lexical syntax) 
of the grammar of Figure \ref{CODE:simple-cf} is presented in Figure
\ref{CODE:simple-bnf}.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
<COORD> ::= "(" <NAT> "," <NAT> ")" 
<CMND>  ::= "line" "to" <COORD> | "move" "to" <COORD>
\end{boxedverbatim}
\end{IncCode}
\caption{BNF definition of simple grammar}\label{CODE:simple-bnf}
\end{figure}   

%When a literal in a context-free function consists only of lower case letters
%and digits and is not a keyword of \asfsdf, it need not be surrounded with
%quotes. You may therefore write `{\tt move to COORD -> CMND}' instead of the
%definition given above.

\subsubsection{List Structures}

It happens quite often that a context-free syntax requires the description of
the repetition of a syntactic notion or of list structures (with or without
separators) containing a syntactic notion. \asfsdf\ provides the following
primitives for this:

\begin{itemize}

\item Lists without separators:

\begin{itemize}

\item[{\tt $S$*}] defines zero or more repetitions of sort $S$. 

\item[{\tt $S$+}] defines one or more repetitions of sort $S$.

\end{itemize} 

\item Lists with separators:

\begin{itemize}

\item[{\tt \{$S$ $sep$\}*}] defines zero or more repetitions of 
sort $S$ separated by the literal $sep$.

\item[{\tt \{$S$ $sep$\}+}] defines one or more repetitions of 
sort $S$ separated by the literal $sep$.

\end{itemize}

\end{itemize}

Lists may be used in the left-hand side of a context-free function and in the
right-hand side of a variable declaration, see Section \ref{Variables}. They
may {\em not} be used as result sort in the right-hand side of a context-free
function.
This imposes no real restriction since a new sort can be introduced
representing a list. This new sort may then be used in the left-hand side of
other context-free rules.

Figure \ref{CODE:pascal-ids} shows how lists can be used to define 
the syntax of a list of identifiers (occurring in a declaration
in a Pascal-like language).

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Decls

imports Layout

exports
  sorts ID DECL TYPE 

  lexical syntax
    [a-z]+ -> ID 

  context-free syntax
    "decl" {ID ","}+ ":" TYPE -> DECL
    "integer"                 -> TYPE 
    "real"                    -> TYPE
\end{boxedverbatim}
\end{IncCode}
\caption{Syntax definition of a list of identifiers}\label{CODE:pascal-ids}
\end{figure}

\subsubsection{Chain Functions}

A context-free syntax may contain functions that do not add syntax, but serve
the sole purpose of including a smaller syntactic notion into a larger one. 
This notion is also known as {\em injections}. 
Injections are functions ``without a name'' and with one argument sort
like {\tt ID -> DATA}.
A typical example is the inclusion of identifiers in expressions or of natural
numbers in reals. Such a \emph{chain function} has one of the following forms:

\begin{itemize}

\item {\tt $SMALL$ -> $BIG$} 
\item {\tt \{$SMALL$ $sep$\}* -> $BIG$} 
\item {\tt $SMALL$* -> $BIG$} 
\item {\tt \{$SMALL$ $sep$\}+ -> $BIG$} 
\item {\tt $SMALL$+ -> $BIG$}

\end{itemize}

Chain functions do not appear in the abstract syntax but correspond to a
\emph{subsort relation} between $SMALL$ and $BIG$.
If {\tt SORT-A} is a subsort of {\tt SORT-B} then in the abstract syntax
tree a tree of sort {\tt SORT-A} can be put wherever a tree of
sort {\tt SORT-B} is required.

(* EXAMPLE should be added *)


\subsection{Attributes of Lexical and Context-free Functions}

The definition of a lexical or context-free functions may be followed by
\emph{attibutes} that define additional properties of that function.
The following attributes exist:

\begin{itemize}

\item {\tt bracket} allows the definitions of parenthesis and other
kinds of brackets that are mostly used for overruling the priorities
of operators in expressions (Section~\ref{BracketFunctions}).

\item {\tt left}, {\tt right}, {\tt non-assoc}, and {\tt assoc}
are used for defining the associativity of functions 
(Section~\ref{Priorities}).

\item {\tt prefer} and {\tt avoid} are used to define that a function should
be preferred or only be used as last resort in certain cases of
syntactic ambiguity (Section~\ref{XXX}).

\item {\tt reject} can be used to explicitly forbid certain syntactic constructs (Section~\ref{XXX}).

\item {\tt memo} declares a function to be a \emph{memo function} for
which all calls and results will be cached during evaluation
(Section~\ref{MemoFunctions}).

\item {\tt delay} is used to influence the evaluation order of the
arguments of a function (Section~\ref{Delay}).

\end{itemize}


%\subsection{Optional Operator}

%\subsection{Alternative Operator}

%\subsection{Tupling Operator}

%\subsection{Tupling Operator}

\subsection{Priorities} \label{ContextFreePriorities} \label{Priorities}

The context-free syntax defined in an \asfsdf\ specification may be 
ambiguous: there are sentences which have more than one associated tree. 
The common example are the arithmetic expressions in which definitions 
of the priority or associativity of operators are missing. There are 
three mechanisms for defining associativity and priority:

\begin{itemize}

\item relative priorities of functions (defined in 
the `{\tt context-free priorities}' section); 

\item associativity of functions (defined as attribute following the function
  declaration); 

\item associativity of groups of functions (defined in 
the `{\tt context-free priorities}' section).

\end{itemize}

Closely related with priorities are brackets that can be used to
overrule priorities.  We will now first describe bracket functions,
and then the various forms of defining priorities.

\subsubsection{Bracket Functions} \label{BracketFunctions}

A bracket function has the form `{\tt $open$ $S$ $close$ -> $S$}' where $open$
and $close$ are literals acting as opening and closing parenthesis for sort
$S$. Examples are `{\tt (}' and `{\tt )}' in arithmetic expressions 
and `{\tt begin}' and `{\tt end}' in programs. 
In most cases, such brackets are only
introduced for grouping and disambiguation, but have no further meaning. By
adding the attribute {\tt bracket} to the function declaration, it will not be
included in the abstract syntax. Figure \ref{CODE:bracket-expr} shows the
definition of a bracket function for the sort {\tt EXPR}.

Since brackets are necessary for overruling the priority and associativity of
functions,  it is required that bracket 
functions are declared for the argument and result sorts of

\begin{itemize}

\item all functions appearing in priority declarations, and
  
\item all functions having one of the attributes {\tt left}, {\tt right}, 
{\tt assoc}, or {\tt non-assoc}.

\end{itemize}

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module BracketExpr

imports Layout

exports
  sorts EXPR

  lexical syntax
    [0-9]+ -> EXPR

  context-free syntax
    "(" EXPR ")" -> EXPR {bracket}
\end{boxedverbatim}
\end{IncCode}
\caption{Syntax definition with a bracket function}\label{CODE:bracket-expr}
\end{figure}

\subsubsection{Relative Priorities}

The relative priority of two functions is defined by including {\tt $F$ > $G$}
in the `{\tt context-free priorities}' section, where $F$ and $G$ are 
as written in the context-free grammar. Functions with a higher 
priority bind more strongly than functions with lower priorities and 
the nodes corresponding to them should
thus appear at lower levels in the tree than nodes corresponding to functions
with lower priorities. Lists of functions may be used in a priority
declaration: {\tt $F$ > \{$G$, $H$\}} is an 
abbreviation for {\tt $F$ > $G$, $F$ > $H$} . 

\subsubsection{Associative Functions}

Associativity attributes can be attached to binary functions of the form 
`{\tt $S$ $op$ $S$ -> $S$}', where $op$ is a literal, non-terminal, or empty. 
Without associativity attributes, nested occurrences of such 
functions immediately lead to ambiguities, as is shown by the 
sentence `{\tt S-string op S-string op S-string}' where 
`{\tt S-string}' is a string of sort $S$. The particular associativity 
associated with $op$ determines the indented interpretation of such sentences.
  
We call two occurrences of functions $F$ and $G$ related, when the node
corresponding to $F$ has a node corresponding to $G$ as first or last child.
The associativity attributes define how to accept or reject trees containing
related occurrences of the same function, $F$:

\begin{itemize}

\item {\tt left}: related occurrences of $F$ associate from left to right. 

\item {\tt right}: related occurrences of $F$ associate from right to left. 

\item{\tt  assoc}: related occurrences of $F$ associate from left to right.

\item {\tt non-assoc}: related occurrences of $F$ are not allowed.

\end{itemize}

Currently, there is no syntactic or semantic difference between `{\tt left}'
and `{\tt assoc}', but we may change that in the future.

Figure \ref{CODE:simple-prio} gives an example of a definition of
simple arithmetic expressions with usual priorities and
associativities.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Expr1

imports Layout

exports
  sorts E 

  lexical syntax
    [0-9]+ -> E 

  context-free syntax
    E "+" E   -> E {left}
    E "*" E   -> E {left}
    "(" E ")" -> E {bracket}

  context-free priorities
    E "*" E -> E > 
    E "+" E -> E
\end{boxedverbatim}
\end{IncCode}
\caption{Simple context-free priority definition}\label{CODE:simple-prio}
\end{figure}   

\subsubsection{Groups of Associative Functions}

Groups of associative functions define how to accept or reject trees
containing related occurrences of different functions with the same priority.
They are defined by prefixing a list of context-free functions in a priority
declaration with one of the following attributes:

\begin{itemize}

\item {\tt left}: related occurrences of $F$ and $G$ associate from left to right. 
\item {\tt right}: related occurrences of $F$ and $G$ associate from right to left.
\item {\tt non-assoc}: related occurrences of $F$ and $G$ are not allowed.

\end{itemize}

\noindent where $F$ and $G$ are functions appearing in the list.
See Figure \ref{CODE:complex-prio} for an example of the use of grouped
associativity.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Expr2

imports Layout

exports
  sorts E 

  lexical syntax
    [0-9]+ -> E

  context-free syntax
    E "+" E   -> E {left}
    E "-" E   -> E {non-assoc}
    E "*" E   -> E {left}
    E "/" E   -> E {non-assoc}
    E "^" E   -> E {right}
    "(" E ")" -> E {bracket}

  context-free priorities
    E "^" E -> E > 
    {non-assoc: E "*" E -> E
                E "/" E -> E} >
    {left: E "+" E -> E
           E "-" E -> E}
\end{boxedverbatim}
\end{IncCode}
\caption{More complex associativity and priority definitions}\label{CODE:complex-prio}
\end{figure}   




\subsection{Restrictions} \label{Restrictions} \label{ContextFreeRestrictions}
\label{LexicalRestrictions}

One of the disambiguation rules on the lexical level is prefer longest match,
the disambiguation will be discussed in more detail in 
Section \ref{lex-ambiguity}.
The restrictions offer the notion to express this lexical disambiguation
rule.

Via the restriction it is possible to indicate that a symbol may not be
followed by a letter from some character class (lookahead). 
There is the possibility to have a lookahead of more than one character. 
There are two different restrictions:

\begin{itemize}
\item lexical restrictions;
\item context-free restrictions.
\end{itemize}

\noindent The general form of a restriction is 

\begin{verbatim}
<Symbol>+ -/- <Lookaheads>
\end{verbatim}

\noindent Where {\tt <Symbol>} is in case of lexical restrictions 
either a literal
or a sort, and in case of context-free restrictions only sort is
allowed. The {\tt Lookaheads} are slightly more complex.
The most compact way is to give the \sdf\ definition of the
{\tt Lookaheads} and illustrate its use by means of some examples.

\begin{verbatim}
context-free syntax
  CharClass                    -> Lookahead
  CharClass "." Lookaheads     -> Lookahead
  Lookahead                    -> Lookaheads
  Lookaheads "|" Lookaheads    -> Lookaheads {right}
  "(" Lookaheads ")"           -> Lookaheads {bracket}
  "[[" {Lookahead ","}* "]]"   -> Lookaheads 
\end{verbatim}

The first example is how the lexical restrictions can be used to
prevent the recognition of erroneous expressions in a small functional
language, see Figure \ref{CODE:functional}, this example is initial presented
in \cite{Vis97}.
The lexical restriction enforces the recognition of for instance {\tt letter}
as a 6 character long lexical token instead of the keyword {\tt let}
followed by {\tt ter} which is then recognized as a {\tt Var}.
The context-free restriction forbids that a variable may be directly
followed by a letter. This latter context-free restriction can also
be formulated as a lexical restriction.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Functional

imports Layout

exports
  sorts Var Term
  lexical syntax
    [a-z]+ -> Var
  context-free syntax
    Var                          -> Term
    Term Term                    -> Term {left}
    "let" Var "=" Term "in" Term -> Term

  lexical restrictions
    "let" "in" -/- [a-z]

  context-free restrictions
    Var -/- [a-z]
\end{boxedverbatim}
\end{IncCode}
\caption{Simple functional language}\label{CODE:functional}
\end{figure}   

The second example illustrates the use of restrictions in order to
define a `safe' way of layout.
Between the members in the left-hand side of a
context-free syntax rule optional layout may be recognized. However,
if a such a member recognizes the empty string, this gives rise to
a lexical ambiguity, see Section \ref{lex-ambiguity}. 
So, the safe way of defining {\tt LAYOUT} is
presented in Figure \ref{CODE:safe-layout}.
The automatic insertion of this optional layout non-terminal
gives rise to the ``safe'' layout definition presented
in Figure \ref{CODE:safe-layout}. A member may recognize the empty string
and thus causing ambiguity.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Layout

exports
  lexical syntax
    [\ \t\n] -> LAYOUT

  context-free restrictions
    LAYOUT? -/- [\ \t\n]
\end{boxedverbatim}
\end{IncCode}
\caption{Safe way of defining {\tt LAYOUT}}\label{CODE:safe-layout}
\end{figure}

The last example illustrates the use of the look aheads to improve
the layout definition in combination with a definition of comments.
Although it is impossible to give {\em one} lexical definition of
comments.
In Figure \ref{CODE:c-comment} the definition of the C comments
were presented.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Comment

imports Layout

exports
  sorts ComWord Comment
  lexical syntax
    ~[\ \n\t\/]+ -> ComWord

  context-free syntax
    "/*" ComWord * "*/" -> Comment
    Comment             -> LAYOUT

  context-free restrictions
    LAYOUT? -/- [\/].[\*]
\end{boxedverbatim}
\end{IncCode}
\caption{Definition of C comments}\label{CODE:c-comment-improved}
\end{figure}


\subsection{Variables} \label{Variables}

Variables are declared in the `variables' section of a module. It consists of
a list of variables together with their sort. Each declaration defines a
naming scheme for variables together with a result sort. A naming scheme is a
regular expression like the ones allowed in the lexical syntax (See Section
\ref{lexical-syntax}) except that sorts are not allowed. One variable
declaration may thus define an unlimited number of variables. The sort of a
variable may be a simple sort, or a list with or without separators. The
variables `{\tt Id}', `{\tt Type3}', and `{\tt Id-list}'
are examples of variables declared by
the following specification presented in Figure \ref{CODE:variables}.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module VarDecls

imports Layout

exports
  sorts ID DECL TYPE 

  lexical syntax
    [a-z]+ -> ID
 
  context-free syntax
    "decl" {ID ","}+ ":" TYPE -> DECL 
    "integer"                 -> TYPE 
    "real"                    -> TYPE 

  variables
    "Id"           -> ID 
    "Type"[0-9]*   -> TYPE 
    "Id-list"[\']* -> {ID ","}* 
    "Id-ne-list"   -> {ID ","}+
\end{boxedverbatim}
\end{IncCode}
\caption{Variable declarations}\label{CODE:variables}
\end{figure}         

Strings that occur in the left-hand side of variable declarations
should {\em always} be quoted. The use of the character classes
like in {\tt "Type"[0-9]*} and {\tt "Id-list"[\verb+\+\verb+'+]*} allows the
generation of an infinite number of variable names.

The variables can only be used when defining equations. It is not
possible to use variables in ordinary terms. This would imply
that we would allow the rewriting of {\em open} terms.

In Section \ref{lex-ambiguity} we address the disambiguation rule
{\em prefer variables}. This rule states that if a substring
can be recognized as a variable it will be recognized as such.
The parser generator decorates automatically each
variable declaration with an attribute {\tt prefer}.

Note that variables (as all other entities in a module --- except equations)
may be exported, see Section \ref{modules}.

\subsection{Disambiguation}

\subsubsection{Lexical Ambiguities}
\label{lex-ambiguity}

\sdf\ offers {\em no automatic} lexical disambiguation, but it has a number of
mechanisms to disambiguate at the lexical level. The specification writer has
to specify the disambiguation rules explicitly. We will discuss various
approaches to lexical disambiguation\footnote{This behaviour is specific for
  \sdf2. In the original \sdf, most of these disambiguations were built-in.}
and illustrate them by means of examples.

\paragraph{Prefer Longest Match per Sort} Reject all interpretations of 
the input text that are included in a longer interpretation of the same 
sort. Given a standard definition of identifiers, the input `{\tt xyz}' 
will thus lead to recognition of the identifier `{\tt xyz}' and not to 
either `{\tt x}' or `{\tt xy}'.

This is achieved by defining a restriction on this lexical sort. This
can be done in context-free restrictions 
section (see Section \ref{ContextFreeRestrictions}).
Figure \ref{CODE:restrict-id} shows how to enforce the longest match
for the sort {\tt Id}.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Identifiers-restrict

imports Layout

exports
  sorts Id
  lexical syntax
    [a-zA-Z][a-zA-Z0-9]* -> Id

  context-free restrictions
    Id -/- [a-zA-Z0-9]  
\end{boxedverbatim}
\end{IncCode}
\caption{Using context-free restrictions to define a longest match for identifiers}\label{CODE:restrict-id}
\end{figure}   

\paragraph{Prefer Literals} 

In the left-hand side of a context-free syntax rule literals (keywords and/or
operators) may be used. 
If these literals overlap with  more general lexical tokens (such as identifier)
this causes ambiguities.

The strategy \emph{Prefer Literals} give preference to interpretation as a literal, over
interpretation as a more general lexical token.
For instance, the keyword {\tt begin} may be recognized as an
identifier given the lexical definition of Figure \ref{CODE:restrict-id}.
There are two approaches to implement Prefer Literals.

In the first approach, we can explicitly forbid the recognition of literals as
tokens of a specific sort. As a matter of fact, \sdf supports a very general
reject mechanism (see Section~\ref{XXX}) that can be used for this purpose.
The idea is to define context-free grammar rules for all literals with the
undesired lexical sort (e.g., {\tt Id} )in the right-hand side followed by the
attribute {\tt reject}.  Figure \ref{CODE:reject-id} illustrates this.  The
{\tt reject} attribute indicates that the recognizition of a keyword as a
literal of the given sort should be rejected. This approach has the major
disadvantage that the addition of a literal in any context-free rule also
requires the addition of a new reject rule for that literal.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Identifiers-reject

imports Layout

exports
  lexical syntax
    [a-zA-Z][a-zA-Z0-9]* -> Id

  context-free restrictions
    Id -/- [a-zA-Z0-9]  

  context-free syntax
    "begin" -> Id {reject}
\end{boxedverbatim}
\end{IncCode}
\caption{Using {\tt reject} to implement Prefer Literals}\label{CODE:reject-id}
\end{figure}   

The second approach is more attractive. The lexical definition of the
general notion that interferes with our literals is written in such a way that
it is only used as a last resort. In other words, it is avoided as much as
possible and is only used when no alternative exists.  The attribute {\tt
  avoid} defines precisely this behaviour.  Figure \ref{CODE:avoid-id} shows
how the lexical definition of {\tt Id} is attribued with {\tt avoid}.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Identifiers-avoid

imports Layout

exports
  lexical syntax
    [a-zA-Z][a-zA-Z0-9]* -> Id {avoid}

  context-free restrictions
    Id -/- [a-zA-Z0-9]  
\end{boxedverbatim}
\end{IncCode}
\caption{Using {\tt avoid} to implement Prefer Literals}\label{CODE:avoid-id}
\end{figure}   

\paragraph{Prefer Non-Layout} Eliminate all interpretations of the text 
as layout symbol. 

\paragraph{Prefer Variables} Give preference to interpretation as a 
variable (as defined in a variables section) over interpretation as a 
lexical token. This strategy will be discussed in Section \ref{Variables}
in more detail.

\subsection{Context-free ambiguities}

\subsubsection{Removing Trees using Priorities}

The priority and associativity declarations are used to eliminate trees in two
phases: 

\begin{itemize}

\item First, trees containing internal conflicts (regarding priority or 
associativity) are eliminated.

\item Next, the remaining trees are compared pair-wise and trees 
are eliminated that are dominated by another one. The ordering used 
is obtained by extending the priority
ordering on context-free functions to an ordering on trees.

\end{itemize}

\subsubsection{Removing Trees Containing Conflicts}

The simplest application of priority and associativity declarations is the
elimination of trees that contain conflicts:

\begin{itemize}
\item a parent node has a child with a lower priority than the parent itself; 
\item a parent has a first or last child that is in conflict with
associativity relation between this parent and child.
\end{itemize}

Given the example of Figure \ref{CODE:complex-prio} we will give a
number of example sentences and the interpretation given the
language definition in this example.

\begin{center}
\begin{tabular}{ll}
  Sentence   & Interpretation \\
\verb"1^2^3" & \verb"1^(2^3)" \\
\verb"1^2*3" & \verb"(1^2)*3" \\
\verb"1*2*3" & \verb"(1*2)*3" \\
\verb"1/2/3" & error \\
\verb"1*2/3" & error \\
\verb"1-2-3" & error \\
\verb"1+2+3" & \verb"(1+2)+3" \\
\verb"1-2+3" & \verb"(1-2)+3" \\
\verb"1+2-3" & \verb"(1+2)-3"\\
\end{tabular}
\end{center}

After removing all trees containing conflicts, more than one tree may remain.
To further reduce this set of remaining trees, the priority ordering `{\tt >}'
on context-free functions is extended to a priority ordering `{\tt >>}' 
on trees. 
A tree in the set is then rejected if there is another tree in the set with
higher priority. The relation $T_1$ {\tt >>} $T_2$ holds between two 
trees $T_1$ and $T_2$ if

\begin{itemize}

\item $T_1$ is not equal to $T_2$;
 
\item if, for any function {\tt F}, $T_1$ contains more nodes 
corresponding to function {\tt F} than $T_2$, 
then $T_2$ contains more nodes corresponding to some function {\tt G} 
with {\tt G > F} in $T_1$. 
(This also covers the case that there are no nodes corresponding to 
{\tt F} in $T_2$ or no nodes corresponding to {\tt G} in $T_1$);

\item injections counting. (*** uitwerken ***)

\end{itemize}
This definition of resolving the priority conflicts is based
on {\em multi-set ordening}.
(*** Paul deze definitie wijkt af van zowel definitie in Eelco's
proefschrift als wat in SGLR is geimplementeerd. ***)

The following example shows how the interaction (and resulting ambiguities)
between general context-free functions and special case functions can be
described using priorities. It concerns expressions for describing subscripts
and superscripts in the typesetting language EQN. The crucial point is that,
for typesetting reasons, we want to treat a subscript followed by a
superscript in a special way. Therefore, the special case `{\tt E sub E sup E
  -> E}' is introduced, which has priority over a combination of the two
functions `{\tt E sub E -> E}' and `{\tt E sup E -> E}'.
See, Figure \ref{CODE:eqn-exprs} for the \sdf\ definition.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Eqn

imports Layout

exports
  sorts E 

  context-free syntax
    E "sub" E         -> E {left}
    E "sup" E         -> E {left}
    E "sub" E "sup" E -> E 
    "{" E "}"         -> E {bracket}
    "a"               -> E 

  context-free priorities
    E "sub" E "sup" E -> E > 
    {left: E "sub" E -> E 
           E :sup" E -> E}
\end{boxedverbatim}
\end{IncCode}
\caption{Syntax definition of EQN expressions}\label{CODE:eqn-exprs}
\end{figure}


\subsection{Equations}

With equations a meaning or semantics may be added to functions declared in
the context-free syntax. The equality of two terms $S$ and $T$ is defined by
an unconditional equation of the form:

\begin{quote}
{\tt [$TagId$] $S$ = $T$} 
\end{quote}

where $TagId$ is a sequence of letters, digits, and/or {\tt -} 
starting with an letter or a digit, and $S$ and $T$ must be 
terms of the same sort. 
A conditional equation consists of a number of conditions 
(also called premises)
and a conclusion. It can be written in three (syntactically different) ways:

\begin{tabbing}
(a) \= {\tt [$TagId$]} \= {\tt $S$ = $T$ when $C_1$, $C_2$, ...} \\
%(b) \> {\tt [$TagId$]} \> {\tt $C_1$, $C_2$, ... ====> $S$ = $T$} \\ 
(b) \> {\tt [$TagId$]} \> {\tt $C_1$, $C_2$, ...} \\
             \>    \> {\tt =================} \\
             \>    \> \ \ \ \ \ {\tt $S$ = $T$}
\end{tabbing}


\noindent where $C_1$, $C_2$, ...  are conditions which may be 
either positive (and have  the form `{\tt $S$ = $T$}'), 
or negative (and have the form `{\tt $S$ != $T$}').

%Note that list sorts are not allowed as the sort of the term at the 
%left-hand side or right-hand side of a condition or 
%conclusion (but see Section ***[Lists]). This restriction can be 
%circumvented by introducing a new sort for the list.

Equations establish equalities between terms. How they are executed is
discussed in Section \ref{ExecutingSpecifications}.
The evaluation strategy is based on innermost rewriting.
One thing the specification writer has to keep in mind
that there is {\em no} semantics related to the order in which
the rules are specified.

In Section \ref{large-examples} we will present a number of larger
examples. We conclude this section with a number of smaller examples
to illustrate the use of list matching, lexical constructor functions,
default equations, memo functions, and delaying.

\subsubsection{List Matching}

List matching also known as associative matching is a powerful
mechanism to describe complex functionality in a compact way.
See Figure \ref{CODE:sets} for a compact specification to remove
double elements from a set.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Sets

imports Layout

exports
  sorts Elem Set

  lexical syntax
    [a-z]+ -> Elem

  context-free syntax
    "{" {Elem ","}* "}" -> Set

  variables
    "Elem"[0-9]*  -> Elem
    "Elem*"[0-9]* -> {Elem ","}*

%% Sets.eqs
equations
  
  [set] {Elem*1, Elem, Elem*2, Elem, Elem*3} = {Elem*1, Elem, Elem*2, Elem*3} 
\end{boxedverbatim}
\end{IncCode}
\caption{Set specification}\label{CODE:sets}
\end{figure}   

Note: although Figure \ref{CODE:sets} contains both the syntax definition
as well as the equations this is within the \ASmetaenv\ not possible.
The equations are physically separated from the syntax definition.

\subsubsection{Lexical Constructor Functions}

The only way to access the actual characters of a lexical token is
by means of the so-called {\em lexical constructor functions}.
For each lexical sort $LEX$ a lexical constructor function is automatically
derived, the corresponding syntax definition is:
{\tt "lex" "(" CHAR* ")" -> LEX}.
The sort {\tt CHAR} is a predefined sort to access the characters.

Characters can directly addressed by the representation or via
variables which are either of the sort {\tt CHAR}, {\tt CHAR*}, or
{\tt CHAR+}, where the latter two represent list of characters.
In Figure \ref{CODE:lcfs} a lexical constructor function is used
to remove the leading zeros for a number.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Nats

imports Layout

exports
  sorts NAT-CON
  lexical syntax
    [0-9]+ -> NAT-CON 

hiddens
  variables
    "Char+"[0-9]* -> CHAR+

%% Nats.eqs
equations

  [1] nat-con("0" Char+) = nat-con(Char+)  
\end{boxedverbatim}
\end{IncCode}
\caption{Use of lexical constructor functions}\label{CODE:lcfs}
\end{figure}   

\noindent Note: there is no check on the use of characters within the
lexical constructor function.

\noindent Note: the lexical constructor functions will disappear when 
the \ASmetaenv\ supports fully \sdf2.

\subsubsection{Default Equations}

The evaluation strategy for normalizing terms given the equations is
based on innermost rewriting. All equations have the same priority.
Given the outermost function symbol of a redex the set of equations
with this outermost function symbol in the left-hand side is selected
and all these rules will be tried.
However, sometimes a specification writer would like to write down
a rule with a special status ``{\em try this rule if all other rules fail}''.
A kind of default behaviour is needed. \asf\ offers functionality in order
to obtain this behaviour. If the $TagId$ of a equation starts with
{\tt default-} this equation is considered as special equation which
will only applied if none of the other rules match.
Figure \ref{CODE:types} shows an example of the use of a default equation.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Types

imports Booleans

exports
  sorts Type
  context-free syntax
    "natural"     -> Type
    "string"      -> Type
    "nil-type"    -> Type
    "compatible" "(" Type "," Type ")" -> Bool 
  variables
    "Type"[0-9]*  -> Type

%% Types.eqs
equations

  [Type-1]  compatible(natural, natural) = true

  [Type-2]  compatible(string, string) = true

  [default-Type] compatible(Type1,Type2) = false
\end{boxedverbatim}
\end{IncCode}
\caption{Use of a default equation}\label{CODE:types}
\end{figure}   

\subsubsection{Memo Functions} \label{MemoFunctions}

\subsubsection{Delaying} \label{Delay}

\section{Executing Specifications} 
\label{ExecutingSpecifications}

Some (but not all!) \asfsdf\ specifications can be executed by interpreting
each equation as a (conditional) rewrite rule from left to right.

When you have created a term (using a term editor, see
Section~\ref{EditingTerms}), you can reduce it (by selecting the {\tt Reduce}
entry from the {\tt Meta-Environment} menu of the term editor).  As a result,
rewrite rules will be applied until a normal form is reached (a term for which
no applicable rule can be found). This normal form is the result of the
execution and is displayed in the window from which the \ASmetaenv\ was
started.

\subsection{Which Rule Will Be Applied Where?}

A term is always reduced in the context of a certain module, say $M$. The
rewrite rules that may be used for the reduction of the term are the rules
declared in $M$ itself and in the modules that are (directly or indirectly)
imported by $M$.

The search for an applicable rule is determined by the reduction strategy,
that is, the procedure used to select a subterm for possible reduction. In our
case the leftmost-innermost reduction strategy is used. This means that a
left-to-right, depth-first traversal of the term is performed and that for
each subterm encountered an attempt is made to reduce it.

Next, the rules are traversed one after the other.  The textual order of the
rules is irrelevant.  Instead they are ordered according to their
\emph{specificity}: more specific rules come before more general rules and
default rules come last.  If the selected subterm and the left-hand side of a
rule (more precisely: of the left-hand side of its conclusion) match, we say
that a \emph{redex} has been found and the following happens. The conditions
of the rule are evaluated and if the evaluation of a condition fails, other
rules (if any) with matching left-hand sides are tried.  If the evaluation of
all conditions succeeds, the selected subterm is replaced by the right-hand
side of the rule (more precisely: the right-hand side of the conclusion of the
rule) after performing proper \emph{substitutions}. Substitutions come into
existence by the initial matching of the rule and by the evaluation of its
conditions.  For the resulting term the above process is repeated until no
further reductions are possible and a normal form is reached (if any).

\subsection{The Evaluation of Conditions}

The conditions of an equation are evaluated from left to right. Let,
initially, $V$ be the set of variables occurring in the left-hand side of the
conclusion of the equation. For the evaluation of each positive condition we
distinguish the following cases:

\begin{itemize}
  
\item The condition contains only variables in $V$. Reduce both sides of the
  condition to normal form and the condition succeeds if both normal forms are
  identical.
  
\item One of the sides of the condition contains new variables not in $V$.
  Reduce the side that does not contain new variables to normal form and the
  condition succeeds if this normal form and the other (unnormalized) side of
  the condition match. The new variables resulting from this match are added
  to $V$.

\end{itemize}
  
The evaluation of negative conditions is described by replacing in the above
description `identical' and `match' by `not identical' and `do not
match', respectively. 
However, it is not allow to introduce new variables in a negative condition.
%%A warning is appropriate here: a negative condition that introduces
%%new variables nearly always succeeds (unless the sort has exactly one
%% element) and this is almost certainly not what you want.

After the successful evaluation of the conditions, all variables occurring in
the right-hand side of the conclusion of the equation should be in $V$.

New variables (see above) should therefore {\bf not} occur on \emph{both} 
sides of a positive condition, in a negative condition, 
or in the right-hand side of the conclusion.

\subsection{The Treatment of List Variables}

Unlike the matching of ordinary (non-list) variables, the matching of a list
variable may have more than one solution since the variable can match lists of
arbitrary length.

As a result, backtracking is needed. For instance, to match {\tt X Y} (a list
expression containing the two list variables {\tt X} and {\tt Y} indicating
the division of a list into twbo sublists) with the list {\tt ab} (a list
containing two elements) the following three alternatives have to be
considered:

\begin{quote}
{\tt X = (empty), Y = ab, \\
X = a, Y = b, \\
X = ab, Y = (empty)}.
\end{quote}

In the unconditional case, backtracking occurs only during matching. When
conditions are present, the failure of a condition following the match of a
list variable leads to the trial of the next possible match of the list
variable and the repeated evaluation of following conditions.

This is exemplified by the Set specification presented in 
Figure \ref{CODE:sets}.
Yet another example of list matching in combination with the evaluation
of conditions is shown in Figure \ref{CODE:split}.
A list of elements is split into two parts of equal length, if the list
has an even number of elements. In case of a list of uneven length
the middle element is ignored. The first part of the list is returned
as result.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Split

imports Integers

exports
  sorts El List
  lexical syntax
    [a-z]+ -> El
  context-free syntax
    {El ","}* -> List
    "length" "(" List ")"       -> Int
    "split-in-two" "(" List ")" -> List

  variables
    "El"[0-9]*  -> El
    "El*"[0-9]* -> {El ","}* 

%% Split.eqs
equations

  [l-1] length() = 0

  [l-2] length(El, El*) = 1 + length(El*)

  [s-1] length(El*1) = length(El*2)
        ===========================
        split-in-two(El*1, El*2) = El*1

  [s-1] length(El*1) = length(El*2)
        ===========================
        split-in-two(El*1, El, El*2) = El*1 
\end{boxedverbatim}
\end{IncCode}
\caption{Split-in-two specification}\label{CODE:split}
\end{figure}   

\subsection{Which Specifications are Executable?}

Which \asfsdf\ specifications can be executed? The following specification of
sets illustrates a non-executable specification, since equation {\tt [2]}, that
expresses that two elements in a set may be exchanged, will lead to an
infinite loop during rewriting.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module ItemSet

imports Layout

exports
  sorts Item Set 

  lexical syntax
    [a-z]+ -> Item 

  context-free syntax
    "{" { Item "," }* "}" -> Set

  variables
    "i"[0-9]* -> Item
    "l"[0-9]* -> {Item ","}* 

%% ItemSet
equations

  [1] {l1, i, l2, i, l3}   = {l1, i, l2, l3} 
  [2] {l1, i1, l2, i2, l3} = {l1, i2, l2, i1, l3}
\end{boxedverbatim}
\end{IncCode}
\caption{Set specification which can not be executed}\label{CODE:itemsets}
\end{figure}   

\subsection{Common Errors when Executing Specifications}

Note: new variable in {\tt !=}, lacking equation, infinite loops, 
WARNING when a condition contains both instantiated and 
uninstantiated variables.

\subsection{Evaluating Terms}
\label{eval-term}

\subsection{Compiling a Specification}
\label{compiling-specs}

By means of the button {\tt Compile ...} in the pop up menu for module
operations (Figure \ref{FIG:module-menu}) or the button pane the \asfsdf2C
compiler can be activated. C code is generated for the selected module
(exactly {\em one} module can be selected for compilation) including
the imported modules.

There are a number of requirements that have to be fulfilled in order
to be able to generate this C code:
\begin{itemize}
\item There should exist a directory in which the C code can be generated.
The name of this directory can be communicated via
\begin{itemize}
\item The environment variable {\tt COMPILER\_OUTPUT}.
\item The {\tt -c} option when starting the \ASmetaenv\ via {\tt meta}.
\item The dialog box presented in Figure \ref{FIG:compiler-dir}.
\end{itemize}

\item The specification should be complete, no missing modules and
the equations sections should be error free.

\end{itemize}

If these requirements are fulfilled the C code can be generated.
This process C code generation is described in \cite{BKO99} in
detail.
We shall give a brief description of the main steps performed by the
\asfsdf2C compiler.

In \asfsdf\ there is {\em no} restriction in which module an equation
is defined, except that all applied syntax rules should be defined.
This freedom asks for a `reshuffling' of the equations given the
set of defined syntax rules. This reshuffling is needed because for
each syntax rule a separate C function is generated. This C function
must contain the C code for {\em all} equations with the C function
as outermost function symbol in the left-hand side.
By having all equations with the same outermost function
symbol in the left-hand side together an optimal matching automaton
can be generated.
Equations with the same outermost function symbol are moved to the 
corresponding syntax rule.
This syntax rule together with the equations is `stored' in an
intermediate module `$\mbox{\tt AUX-M}_{ij}$' where $\mbox{\tt M}_i$
is the module which contained the definition of the syntax rule.

XXX Example??? XXX

These intermediate modules are input to the actual \asfsdf2C compiler.
For each $\mbox{\tt AUX-M}_{ij}$ module a separate C file is generated
in the {\tt COMPILER\_OUTPUT} directory.

XXX Example??? XXX

Upon completion of the code generation process a {\tt Makefile} is 
generated.
When compiling this generated C code, a library is constructed
as well an executable. This library can be used in order to
combine various compiled specifications in an efficient way
or to combine compiled specifications with `hand-written' C code.

The \asfsdf2C compiler has some notion of incremental compilation.
The intermediate $\mbox{\tt AUX-M}_{ij}$ modules are stored
in the {\tt COMPILER\_OUTPUT} directory together with the generated
C files. If when recompiling the specification after modifications
the compiler first checks whether for each
new generated intermediate $\mbox{\tt AUX-M}_{ij}$ module
differs from the stored one. If so, new C code is generated, but
if they are equal {\em no} new C code will be generated.

\section{Examples of \asfsdf\ Specifications}
\label{large-examples}

Here are some examples of \asfsdf\ specifications, which are selected to
illustrate specific features of the formalism. Larger examples can be found in
the online specifications.

\subsection{Symbolic Differentiation}

Computing the derivative of an expression with respect to some variable is a
classical problem we discuss in this example. 
Computing the derivative of {\tt X * (X + Y + Z)} with respect to X gives:

{\tt d(X * (X + Y + Z)) / dX ) X + Y + Z + X}

Differentiation is defined in three stages. First, the sorts {\tt NAT}
(natural numbers), {\tt VAR} (variables), and {\tt EXP} (expressions) are
introduced. Next, a differentiation operator of the form {\tt d $E$/d$V$} is
defined. Then, the differentiation rules are defined (equations [1]-[5]).
Finally, some rules for simplifying expressions are given. As the above
example shows, further simplification rules could have been added to collect
multiple occurrences of a variable (giving {\tt 2*X + Y + Z}) or to 
compute constant expressions.
\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Diff 

imports Layout

exports
  sorts NAT VAR EXP
 
  lexical syntax
    [0-9]+   -> NAT 
    [XYZ]    -> VAR

  context-free syntax
    NAT                 -> EXP 
    VAR                 -> EXP 
    EXP "+" EXP         -> EXP {left} 
    EXP "*" EXP         -> EXP {left} 
    "(" EXP ")"         -> EXP {bracket} 
    "d" EXP "/" "d" VAR -> EXP

  variables
    "N"       -> NAT 
    "V"[0-9]* -> VAR 
    "E"[0-9]* -> EXP 

 context-free priorities
   EXP "*" EXP -> EXP > 
   EXP "+" EXP -> EXP

%% Diff.eqs
equations 
  [1] dN/dV = 0
  [2] dV/dV = 1 
  [3] V1 != V2 ==> dV1/dV2 = 0 
  [4] d(E1+E2)/dV = dE1/dV + dE2/dV 
  [5] d(E1*E2)/dV = dE1/dV * E2 + E1 * dE2/dV 
  [6] E + 0 = E 
  [7] 0 + E = E 
  [8] E * 1 = E 
  [9] 1 * E = E 
  [10] 0 * E = 0 
  [11] E * 0 = 0
\end{boxedverbatim}
\end{IncCode}
\caption{\asfsdf\ specification for differentiating}\label{CODE:diff}
\end{figure}   

\subsection{Sorting}

The use of list structures is illustrated by the specification of
the "Dutch National Flag" problem presented in Figure \ref{CODE:flag}: 
given an arbitrary list of the colours red,
white and blue, sort them in the order as they appear in the Dutch National
Flag. We want:

{\tt \{white blue red blue red white red\} $\Rightarrow$ \{red red red white
 white blue blue\}}

In the following specification, the list variables {\tt Cs1} and {\tt Cs2}
permit a succinct formulation of the search for adjacent colours that are in
the wrong order.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Flag

imports Layout

exports
  sorts Color Flag 

  context-free syntax
    "red"          -> Color 
    "white"        -> Color 
    "blue"         -> Color 
    "{" Color+ "}" -> Flag 

variables
    "Cs"[0-9]* -> Color* 
    "C"[0-9]*  -> Color 

%% Flag.eqs
equations

  [1] {Cs1 white red Cs2}  = {Cs1 red white Cs2}

  [2] {Cs1 blue white Cs2} = {Cs1 white blue Cs2} 

  [3] {Cs1 blue red Cs2}   = {Cs1 red blue Cs2}
\end{boxedverbatim}
\end{IncCode}
\caption{\asfsdf\ specification for sorting}\label{CODE:flag}
\end{figure} 

\subsection{Code Generation}

Consider a simple statement language (with assignment, if-statement and
while-statement) and suppose we want to compile this language to the following
stack machine code:

\begin{description}
\item{\tt push $N$} Push the number $N$. 
\item{\tt rvalue $I$} Push the contents of data location $I$.
\item{\tt lvalue $I$} Push the address of data location $I$. 
\item{\tt pop} Remove the top of the stack. 
\item{\tt copy} Push a copy of the top value on the stack. 
\item{\tt assign} The r-value on top of the stack is stored in the l-value
  below it and both are popped.
\item{\tt add, sub, mul}
Replace the two values on top of the stack by their sum (difference,
product). 
\item{\tt label $L$} Place a label (target of jumps). 
\item{\tt goto $L$} Next instruction is taken from statement following label
  $L$. 
\item{\tt gotrue $L$} Pop the top value; jump if it is nonzero.
\item{\tt  gofalse $L$}
Pop the top value; jump if it is zero.
\end{description}

\noindent The statement:
\begin{quote}
{\tt while a do a := a - 1; b := a * c od }
\end{quote}
will now be translated to the following instruction sequence:
\begin{verbatim}
label xx ; 
rvalue a ; 
gofalse xxx ; 
lvalue a ; 
rvalue a ; 
push 1 ;
sub ; 
assign ;
lvalue b ; 
rvalue a ; 
rvalue c ; 
mul ; 
assign ; 
goto xx ; 
label xxx
\end{verbatim}

\noindent Figure \ref{CODE:basicnotions} defines the 
sorts {\tt Nat} (numbers) and {\tt Id} (identifiers).
Given these basic notions the expressions and statements of our little 
source language are defined, see Figure \ref{CODE:expressions} and
\ref{CODE:statements}, respectively.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module BasicNotions 
exports
  sorts Nat Id 
  lexical syntax
    [0-9]+         -> Nat 
    [a-z][a-z0-9]* -> Id

variables
  "Nat"[0-9\']* -> Nat 
  "Id"[0-9\']*  -> Id
\end{boxedverbatim}
\end{IncCode}
\caption{\asfsdf\ specification for BasicNotions}\label{CODE:basicnotions}
\end{figure}

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Expressions 

imports BasicNotions

exports
  sorts Exp 
  context-free syntax
    Nat         -> Exp 
    Id          -> Exp 
    Exp "+" Exp -> Exp {left}
    Exp "-" Exp -> Exp {left}
    Exp "*" Exp -> Exp {left}

  variables
    "Exp"[0-9\']* -> Exp 

  context-free priorities
    Exp "*" Exp -> Exp > {left: Exp "+" Exp -> Exp
                                Exp "-" Exp -> Exp}
\end{boxedverbatim}
\end{IncCode}
\caption{\asfsdf\ specification for Expressions}\label{CODE:expressions}
\end{figure}

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module Statements 

imports Expressions 

exports
  sorts Stat Stats 
  context-free syntax
    Id ":=" Exp                 -> Stat 
    "if" Exp "then" Stats "fi"  -> Stat 
    "while" Exp "do" Stats "od" -> Stat
    {Stat ";"}+                 -> Stats 

  variables
    "Stat"[0-9\']*  -> Stat
    "Stat+"[0-9\']* -> {Stat ";"}+
\end{boxedverbatim}
\end{IncCode}
\caption{\asfsdf\ specification for Statements}\label{CODE:statements}
\end{figure}


The instructions of the stack machine are defined in 
Figure \ref{CODE:assemblylanguage}.
Next, we define a function to construct a next label given the
previous one. It is defined on the lexical notion of labels ({\tt Label}). 
The scheme of appending the character `{\tt x}' to the previous label is, of
course, naive and will in real life be replaced by a more sophisticated one,
see Figure \ref{CODE:nextlabel} for the actual definition.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module AssemblyLanguage

imports BasicNotions 
exports 
  sorts Label Instr Instrs
  lexical syntax
    [a-z0-9]+ -> Label 
  context-free syntax
    "push" Nat      -> Instr
    "rvalue" Id     -> Instr 
    "lvalue" Id     -> Instr 
    "assign"        -> Instr 
    "add"           -> Instr 
    "sub"           -> Instr 
    "mul"           -> Instr 
    "label" Label   -> Instr 
    "goto" Label    -> Instr 
    "gotrue" Label  -> Instr 
    "gofalse" Label -> Instr
    {Instr ";"}+   -> Instrs 

  variables
    "Instr"[0-9\']*      -> Instr 
    "Instr-list"[0-9\']* -> {Instr ";"}+
    "Label"[0-9\']*      -> Label
\end{boxedverbatim}
\end{IncCode}
\caption{\asfsdf\ specification for AssemblyLanguage}\label{CODE:assemblylanguage}
\end{figure}

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module NextLabel
  
imports AssemblyLanguage
  
exports
  context-free syntax
    "nextlabel" "(" Label ")" -> Label 
  variables
    "Label"[0-9\']* -> LABEL

hiddens
  variables
    "Char*"[0-9]* -> CHAR*

%% NextLabel.eqs
equations

 [1] nextlabel(label(Char*)) = label(Char* "x")
\end{boxedverbatim}
\end{IncCode}
\caption{\asfsdf\ specification for NextLabel}\label{CODE:nextlabel}
\end{figure}

It remains to define a function `{\tt tr}' that translates statements into
instructions. During code generation we should generate new label names for
the translation of if- and while-statements. This is an instance of a
frequently occurring problem: how do we maintain global information (in this
case: the last label name generated)? A standard solution is to introduce an
auxiliary sort ({\tt Instrs-Lab}) that contains both the generated instruction
sequence and the last label name generated so far.
Figure \ref{CODE:codegenerator} show the module containing this actual
translation function.

This completes the specification of our code generator.

\begin{figure}[tb]
\begin{IncCode}
\begin{boxedverbatim}
module CodeGenerator

imports Statements AssemblyLanguage NextLabel 
  
exports
  context-free syntax
    "tr" "(" Stats ")" -> Instrs
  
hiddens
  sorts Instrs-lab 
  context-free syntax
    "<" Instrs "," Label ">"     -> Instrs-lab 
    "tr" "(" Stats "," Label ")" -> Instrs-lab 
    "tr" "(" Exp ")"             -> Instrs

%% CodeGenerator.eqs
equations 

[1] tr(Stat-list, x) = <Instr-list, Label>
    ======================================
    tr(Stat-list) = Instr-list

[2] tr(Stat, Label) = <Instr-list1, Label'>, 
    tr(Stat-list, Label') = <Instr-list2, Label''>
    ================================================================== 
    tr(Stat ; Stat-list, Label) = <Instr-list1 ; Instr-list2, Label''>

[3] tr(Exp) = Instr-list
    ============================================================= 
    tr(Id := Exp, Label) = <lvalue Id; Instr-list; assign, Label>

[4] tr(Exp) = Instr-list1, tr(Stat-list, Label) = <Instr-list2, Label'>,
    Label'' = nextlabel(Label') 
    ================================================================ 
    tr(if Exp then Stat-list fi, Label) =
    <Instr-list1; gofalse Label''; Instr-list2; label Label'', Label''>

[5] tr(Exp) = Instr-list1, tr(Stat-list, Label) = <Instr-list2, Label'>,
    Label'' = nextlabel(Label'), Label''' = nextlabel(Label'') 
    ================================================================ 
    tr(while Exp do Stat-list od, Label) =
    <label Label''; Instr-list1; gofalse Label'''; Instr-list2;
     goto Label''; label Label''', Label'''>

[6] tr(Exp1) = Instr-list1, tr(Exp2) = Instr-list2
    =============================================== 
    tr(Exp1 + Exp2) = Instr-list1; Instr-list2; add

[7] tr(Exp1) = Instr-list1, tr(Exp2) = Instr-list2
    =============================================== 
    tr(Exp1 - Exp2) = Instr-list1; Instr-list2; sub

[8] tr(Exp1) = Instr-list1, tr(Exp2) = Instr-list2
    =============================================== 
    tr(Exp1 * Exp2) = Instr-list1; Instr-list2; mul

[9] tr(Nat) = push Nat 
[10] tr(Id) = rvalue Id
\end{boxedverbatim}
\end{IncCode}
\caption{\asfsdf\ specification for CodeGenerator}\label{CODE:codegenerator}
\end{figure}

\subsection{Large \asfsdf\ specifications}

There are a number of very large \asfsdf\ specifications:
\begin{itemize}
\item the \asfsdf2C compiler.
\item a part of the parse table generator for \sdf2.
\item the syntax and type checking of a domain specific language for
describing financial products. 
\end{itemize}

\section{Miscellaneous}

\subsection{Parsing a term outside the \ASmetaenv}

\subsection{Rewriting a term using a compiled specification}

\subsection{Unparsing a (parsed/normalized) term}

\end{document}
