\documentclass[10pt,twoside]{book}
\usepackage{a4wide}
\usepackage[english]{babel}
\usepackage{url}
\usepackage{times}
\usepackage{xspace}
\usepackage{alltt}
\usepackage{supertabular}
\usepackage{epsfig}
\usepackage{picinpar}
\usepackage{moreverb}
\usepackage{verbatim}
\usepackage{fancyheadings}


\newcommand{\rscript}[0]{\textsc{Rscript}\xspace}
\newcommand{\rstore}[0]{\textsc{Rstore}\xspace}
\newcommand{\asfsdf}[0]{\textsc{Asf+Sdf}\xspace}
\newcommand{\TB}[0]{\textsc{ToolBus}\xspace}

\newcommand{\note}[1]{\paragraph{Note:} \emph{#1}}

\newenvironment{exam}
        {\begin{quote}\small}
        {\end{quote}}  

\pagestyle{fancy}
% Switch off shouting makeuppercase from fancyheaders.
\renewcommand{\MakeUppercase}[1]{#1}
\lhead[\leftmark]{\rscript Tutorial}
\rhead[\rscript Tutorial]{\leftmark}

\title{A Tutorial Introduction to \rscript\\ ---a Relational Approach to
  Software Analysis---\\[2cm]
\epsfig{figure=figs/windas.ps,width=16cm}\label{FIG:windas}
}
\author{Paul Klint}

\date{DRAFT: \today}

\begin{document}
%%\initfloatfigs
\maketitle

\begin{figure}[h]

\end{figure}
\tableofcontents



\newpage

\chapter{Introduction}\label{SEC:Introduction}

\begin{figure}[tb]
\begin{center}
\vspace*{-1cm}
\epsfig{figure=figs/paradigm.eps,width=10cm}
\vspace*{-4cm}
\end{center}
\hrulefill
\caption{\label{FIG:paradigm} The extract-enrich-view paradigm}
\end{figure}

\begin{window}[0,l,\fbox{\epsfig{figure=figs/balloon.ps,height=9.5cm}},{}]
\label{FIG:balloon}
\noindent \textbf{Extract-Enrich-View paradigm:}
\rscript is a small scripting language based on the relational
calculus.  It is intended for analyzing and querying the source code
of software systems: from finding uninitialized variables in a single
program to formulating queries about the architecture of a complete
software system. \rscript fits well in the extract-enrich-view paradigm
shown in Figure~\ref{FIG:paradigm}:\\
%%\begin{itemize}
\textbf{Extract:} Given the source text, extract relevant information from it in
the form of relations. Examples are the CALLS relation that describes direct
calls between procedures, the USE relation that relates statements with the
variables that are used in the statements, and the PRED relation that relates
a statement with its predecessors in the control flow graph.  The extraction
phase is outside the scope of \rscript but may, for instance, be implemented
using \asfsdf~\cite{BDHJJKKMOSVVV01} and we will give examples how to do this.\\
\textbf{Enrich:} Derive additional information from the relations
extracted from the source text. For instance, use CALLS to compute
procedures that can also call each other indirectly (using transitive
closure).  Here is where \rscript shines.\\
\textbf{View:} The result of the enrichment phase are again bags and relations.
These can be displayed with various tools like, Dot~\cite{Dot96},
Rigi~\cite{Mueller88} and others. \rscript is not concerned with viewing but
we will give some examples anyway.

\end{window}

\paragraph{Application of Relations to Program Analysis}

Many algorithms for program analysis are usually presented as \emph{graph}
algorithms and this seems to be at odds with the extensive experience of using
\emph{term} rewriting for tasks as type checking, fact extraction, analysis
and transformation.  The major obstacle is that graphs can and terms cannot
contain cycles.  Fortunately, every graph can be represented as a relation and
it is therefore natural to have a look at the combination of relations and
term rewriting.

Once you start considering problems from a relational perspective, elegant and
concise solutions start to appear. Some examples are:
\begin{itemize}
\item Analysis of call graphs and the structure of software architectures.
\item Detailed analysis of the control flow or dataflow of programs.
\item Program slicing.
\item Type checking.
\item Constraint problems.
\end{itemize}

\paragraph{What's new in \rscript?}
Given the considerable amount of related work to be discussed below, it is necessary to clearly
establish what is and what is not new in our approach:

\begin{itemize}

\item We use sets and relations like  Rigi~\cite{Mueller88} and
  GROK~\cite{Holt96} do. After extensive experimentation we have decided \emph{not}
  to use bags and multi-relations like in RPA~\cite{FeijsKrikhaarOmmering98}.

\item Unlike several other systems we allow \emph{nested} sets and relations
  and also support $n$-ary relations as opposed to just binary relations but
  don't support the complete repertoire of $n$-ary relations as in SQL.

\item We offer a strongly typed language with user-defined types.

\item Unlike Rigi~\cite{Mueller88}, GROK~\cite{Holt96} and
  RPA~\cite{FeijsKrikhaarOmmering98} we provide a relational \emph{calculus}
  as opposed to a relational algebra. Although the two have the same
  expressive power, a calculus increases, in our opinion, the readability of
  relational expressions because they allow the introduction of variables to
  express intermediate results.

\item We integrate an equation solver in a relational language. In this way
dataflow problems can be expressed.

\item We introduce an \emph{location} datatype with associated operations to
easily manipulate references to source code.

\item There is some innovation in syntactic notation and specific built-in
functions.

\item We introduce the notion of an \rstore that generalizes the RSF tuple
  format of Rigi. An \rstore consists of name/value pairs, where the values
  may be arbitrary nested bags or relations. An \rstore is a
  language-independent exchange format and can be used to exchange complex
  relational data between programs written in different languages.

\end{itemize}

\section{Background}


\paragraph{Relation-oriented Languages}
There is a long tradition in Computer Science to organize languages around one
a more prominent data types such as lists (Lisp), strings (SNOBOL), arrays
(APL) or sets (SETL).  We use sets and relations as primary datatypes and the
sets and set formers in SETL~\cite{SETL} are the best historic reference for
them. Set formers have later on be popularized in various functional languages
since they were introduced in KRC~\cite{Turner82}.  An overview of languages
centered around collection types such as sets and bags is given in
~\cite{Tannen94}.  Database languages in general and SQL in particular are
described in~\cite{Ullman82}.  The connection between comprehensions and
relational algebra is described in~\cite{WadlerLists87,Trinder89}. A further
analysis of this topic is given in~\cite{Buneman94}.

Systems supporting relational programming include RELVIEW~\cite{RELVIEW98}
(intended for the interactive creation and visualization of relations
and the prototyping of graph algorithms), ...

\paragraph{Relations and Program Analysis}

The idea to represent relational views of programs is already quite old.  For
instance, in~\cite{Linton84} all syntactic as well as semantic aspects of a
program were represented by relations and SQL was used to query them. Due to
the lack of expressiveness of SQL (notably the lack of transitive closures)
and the performance problems encountered, this approach has not seen wider
use.  In Rigi~\cite{Mueller88}, a tuple format (RSF) is introduced to
represent relations and a language (RCL) to manipulate them.
In~\cite{PaulPrakash94} a \emph{source code algebra} is described that can be
used to express relational queries on source text.  In~\cite{BKV96b} a
\emph{query algebra} is formulated to express direct queries on the syntax
tree. It also allows the querying of information that is attached to the
syntax tree via annotations.  Relational algebra is used in GROK~\cite{Holt96}
and Relation Partition Algebra
(RPA)~\cite{FeijsKrikhaarOmmering98,Feijs99,Krikhaar99} to represent basic
facts about software systems and to query them.  In GUPRO~\cite{GUPRO98}
graphs are used to represent programs and to query them. In
F(p)--$\ell$~\cite{CanforRaEtAl99} a Prolog database and a special-purpose
language are used to represent and query program facts.

The requirements for a query language for reverse engineering are discussed
in~\cite{holt-towards}.



\section{Plan for this Tutorial}

In Chapter~\ref{SEC:motivating-example} we first provide a motivating example
of our relational approach.
In Chapter~\ref{SEC:rscript-language} follows a complete description
of all the features in \rscript.
In the following Chapters~\ref{SEC:operators} and \ref{SEC:functions}
all built-in operators and functions are described.
The most interesting part of this tutorial is probably
Chapter~\ref{SEC:larger-examples} where we present a menagerie of larger
examples ranging from computing the McCabe complexity of code, analyzing the
component structure of systems, to program slicing.
Chapter~\ref{SEC:running-rscript} describes how to run an \rscript.
Two appendices complete this tutorial:
Appendix~\ref{AP:operators} summarizes all built-in operators
and Appendix~\ref{AP:functions} summarizes all built-in functions.

\chapter{A Motivating Example} \label{SEC:motivating-example}

\fbox{\epsfig{figure=figs/caruso.ps,width=6cm}}
\label{FIG:caruso}
\hspace*{0.5cm}\parbox[b]{8cm}{Suppose a mystery box ends up on your desk. When you open it, it contains a
huge software system with several questions attached to it:

\begin{itemize}

\item How many procedure calls occur in this system?

\item How many procedures contains it?

\item What are the entry points for this system, i.e., procedures that call
  others but are not called themselves?

\item What are the leaves of this application, i.e., procedures that are
called but do not make any calls themselves?


\end{itemize}
}

\begin{itemize}

\item Which procedures call each other indirectly?

\item Which procedures are called directly or indirectly from each entry
  point?

\item Which procedures are called from all entry points?

\end{itemize}

\noindent There are now two possibilities. Either you have this superb
programming environment or tool suite that can immediately answer all these
questions for you or you can use \rscript.


\begin{figure}[tb]
\begin{center}
%%\vspace*{-1cm}
\epsfig{figure=figs/calls-workflow.eps,width=10cm}
\vspace*{-4cm}
\end{center}
\hrulefill
\caption{\label{FIG:calls-workflow} Workflow for analyzing mystery box.}
\end{figure}

\paragraph{Preparations}

\begin{figure}[tb]
\begin{center}
\vspace*{-1cm}
\epsfig{figure=figs/calls.eps,width=14cm}
\vspace*{-13cm}
\end{center}
\hrulefill
\caption{\label{FIG:calls} Graphical representation of the {\tt calls} relation}
\end{figure}


To illustrate this process consider the workflow in
Figure~\ref{FIG:calls-workflow}. First we have to extract the calls from the
source code. Recall that \rscript does not consider fact extraction \emph{per
se} so we assume that this call graph has been extracted from the software by
some other tool. Also keep in mind that a real call graph of a real
application will contain thousands and thousands of calls. Drawing it in the
way we do later on in Figure~\ref{FIG:calls} makes no sense since we get a
uniformly black picture due to all the call dependencies. After the extraction
phase, we try to understand the extracted facts by writing queries to explore
their properties. For instance, we may want to know \emph{how many calls}
there are, or \emph{how many procedures}. We may also want to enrich these
facts, for instance, by computing who calls who in more than one step.
Finally, we produce a simple textual report giving answers to the questions we
are interested in.


Now consider the call graph shown in Figure~\ref{FIG:calls}.  This section is
intended to give you a first impression what can be done with \rscript. Please
return to this example when you have digested the detailed description of
\rscript in Chapters~\ref{SEC:rscript-language},~\ref{SEC:operators} and
\ref{SEC:functions}.

\rscript supports some basic data types like integers and strings which are
sufficient to formulate and answer the questions at hand.  However, we can
gain readability by introducing separately named types for the items we are
describing.  First, we introduce therefore a new type {\tt proc} (an alias for
strings) to denote procedures:

\begin{exam}
\begin{verbatim}
type proc = str
\end{verbatim}
\end{exam}

Suppose that the following facts have been extracted from the source
code and are represented by the relation {\tt Calls}:

\begin{exam}
\begin{verbatim}
rel[proc , proc] Calls = {<"a", "b">, <"b", "c">, <"b", "d">,
   <"d", "c">, <"d","e">, <"f", "e">, <"f", "g">, <"g", "e">}.
\end{verbatim}
\end{exam}

\noindent This concludes the preparatory steps and now we move on to answer the
questions.

\paragraph{How many procedure calls occur in this system?}
To determine the numbers of calls, we simply determine the number of tuples
in the {\tt Calls} relation, as follows:

\begin{exam}\begin{verbatim}
int nCalls = # Calls
\end{verbatim}
\end{exam}
The operator \verb@#@ determines the number of elements in a bag or relation
and is explained in Section~\ref{BO:misc}.
In this example, {\tt nCalls} will get the value {\tt 8}.

\paragraph{How many procedures contains it?}

We get the number of procedures by determining which names occur
in the tuples in the relation {\tt Calls} and then determining the
number of names:

\begin{exam}\begin{verbatim}
set[proc] procs = carrier(Calls)
int nprocs = # procs
\end{verbatim}
\end{exam}
The built-in function {\tt carrier} determines all the values that occur
in the tuples of a relation. In this case,
{\tt procs} will get the value  \verb@{"a", "b", "c", "d", "e", "f", "g"}@
and {\tt nprocs} will thus get value {\tt 7}. A more concise way of expressing this
would be to combine both steps:
\begin{exam}\begin{verbatim}
int nprocs = # carrier(Calls)
\end{verbatim}
\end{exam}

\paragraph{What are the entry points for this system?}
The next step in the analysis is to determine which \emph{entry points} this
application has, i.e., procedures which call others but are not called
themselves. Entry points are useful since they define the external interface
of a system and may also be used as guidance to split a system in
parts.

The \emph{top} of a relation contains those left-hand sides of tuples in a
relation that do not occur in any right-hand side.  When a relation is viewed
as a graph, its top corresponds to the root nodes of that graph.
Similarly, the \emph{bottom} of a relation corresponds to the leaf nodes of
the graph. See Section~\ref{BI:bottom} for more details.
Using this knowledge, the entry points can be computed by determining the top of the
{\tt Calls} relation:
\begin{exam}\begin{verbatim}
set[proc] entryPoints = top(Calls)
\end{verbatim}
\end{exam}

\noindent In this case, {\tt entryPoints} is equal to  \verb@{"a", "f"}@.
In other words, procedures {\tt "a"} and {\tt "f"} are the entry points
of this application.

\paragraph{What are the leaves of this application?}
In a similar spirit, we can determine the \emph{leaves} of this application,
i.e., procedures that are being called but do not make any calls themselves:

\begin{exam}\begin{verbatim}
set[proc] bottomCalls = bottom(Calls).
\end{verbatim}
\end{exam}
In this case, {\tt bottomCalls} is equal to  \verb@{"c", "e"}@.

\paragraph{Which procedures call each other indirectly?}
We can also determine the \emph{indirect calls} between procedures, by
taking the transitive closure of the {\tt Calls} relation:

\begin{exam}\begin{verbatim}
rel[proc, proc] closureCalls = Calls+
\end{verbatim}
\end{exam}
In this case, {\tt closureCalls} is equal to
\begin{exam}\begin{verbatim}
{<"a", "b">, <"b", "c">, <"b", "d">, <"d", "c">, <"d","e">, <"f", "e">, 
 <"f", "g">, <"g", "e">, <"a", "c">, <"a", "d">, <"b", "e">, <"a", "e">}
\end{verbatim}
\end{exam}

\paragraph{ Which procedures are called directly or indirectly from each entry
  point?}

We know now the entry points for this application ({\tt "a"} and {\tt "f"})
and the indirect call relations. Combining this information, we can determine
which procedures are called from each entry point. This is done by taking the
\emph{right image} of {\tt closureCalls}. The right image operator determines
yields all right-hand sides of tuples that have a given value as left-hand
side:
\begin{exam}\begin{verbatim}
set[proc] calledFromA = closureCalls["a"]
\end{verbatim}
\end{exam}
yields \verb@{"b", "c", "d", "e"}@ and
\begin{exam}\begin{verbatim}
set[proc] calledFromF = closureCalls["f"]
\end{verbatim}
\end{exam}
yields \verb@{"e", "g"}@.

\paragraph{Which procedures are called from all entry points?}
Finally, we can determine which procedures are called from both entry points
by taking the intersection of the two sets {\tt calledFromA} and {\tt calledFromF}
\begin{exam}\begin{verbatim}
set[proc] commonProcs = calledFromA inter calledFromF
\end{verbatim}
\end{exam}
which yields \verb@{"e"}@. In other words, the procedures called from both
entry
points are mostly disjoint except for the common procedure  {\tt "e"}.

\paragraph{Wrap-up}
These findings can be verified by inspecting a graph view of the calls
relation as shown in Figure~\ref{FIG:calls}.  Such a visual inspection does
\emph{not} scale very well to large graphs and this makes the above form of
analysis particularly suited for studying large systems.

\chapter{The \rscript Language} \label{SEC:rscript-language}
\fbox{\epsfig{figure=figs/signalpha-web.ps,width=6cm}},{}]
\label{FIG:signalpha}
\hspace*{0.5cm}\parbox[b]{7.8cm}{
\rscript is based on \emph{binary relations} only and has no direct support
for $n$-ary relations with labeled columns as usual in a general database
language. However, some syntactic support for $n$-ary relations exists. We
will explain this further below.

An \rscript consists of a sequence of declarations for variables and/or
functions. Usually, the value of one of these variables is what the writer of the
script is interested in.

The language has scalar types (Boolean, integer, string, location) and
composite types (set and relation). Expressions are constructed from
comprehensions, function invocations and operators. These are all
described below.}

\section{Types and Values}

\subsection{Elementary Types and Values} \label{SEC:ElementaryTypes}

\paragraph{Booleans}
The Booleans are represented by the type {\tt bool} and have two values:
{\tt true} and {\tt false}.

\paragraph{Integers}
The integer values are represented by the type {\tt int} and are written as
usual, e.g., {\tt 0}, {\tt 1}, or {\tt 123}.

\paragraph{Strings}
The string values are represented by the type {\tt str} and consist
of character sequences surrounded by double quotes. e.g., {\tt "a"} or
{\tt "a\ long\ string"}.

\paragraph{Locations}
Location values are represented by the type {\tt loc} and serve as
text coordinates in a specific source file. They should \emph{always} be generated automatically but
for the curious here is an example how they look like: {\tt
  area-in-file("/home/paulk/example.pico", area(6, 17, 6, 18, 131, 1))}.


\section{Tuples, Sets and Relations}

\paragraph{Tuples}

Tuples are represented by the type {\tt <$T_1$, $T_2$>}, where $T_1$ and
$T_2$ are arbitrary types. An example of a tuple type is {\tt <int, str>}.
\rscript directly supports tuples consisting of two elements (also
know as \emph{pairs}).  For convenience, $n$-ary tuples are also allowed, but
there are some restrictions on their use, see the paragraph {\bf Relations}
below.
Examples are:
\begin{itemize}
\item \verb@<1, 2>@ is of type {\tt <int, int>},
\item \verb@<1, 2, 3>@ is of type {\tt <int, int, int>},
\item \verb@<1, "a", 3>@ is of type {\tt <int, str, int>},
\end{itemize}

\paragraph{Sets}
Sets are represented by the type {\tt set[$T$]}, where $T$ is an arbitrary
type. Examples are {\tt set[int]}, {{\tt set[<int,int>]} and {\tt
set[set[str]]}.  Sets are denoted by a list of elements, separated by comma's
and enclosed in braces as in  \verb@{@{\tt $E_1$, $E_2$, ..., $E_n$}\verb@}@,
where the $E_i$ ($1 \leq i \leq n$) are expressions that yield the desired element
type. For example, 
\begin{itemize}
\item \verb@{1, 2, 3}@ is of type {\tt set[int]},
\item \verb@{<1,10>, <2,20>, <3,30>}@ is of type {\tt set[<int,int>]},
\item \verb@{<"a",10>, <"b",20>, <"c",30>}@ is of type {\tt set[<str,int>]}, and 
\item \verb@{{"a", "b"}, {"c", "d", "e"}}@ is of type {\tt set[set[str]]}.
\end{itemize}

\paragraph{Relations}
Relations are nothing more than sets of tuples, but since they are used so
often we provide some shorthand notation for them.

Relations are represented by the type {\tt rel[$T_1$, $T_2$]}, where {\tt
$T_1$} and {\tt $T_2$} are arbitrary types; it is a shorthand for {\tt
set[<$T_1$, $T_2$>]}.  Examples are {\tt rel[int,str]} and {\tt
rel[int,set[str]]}.  Relations are denoted by \verb@{@{\tt <$E_{11}$, $E_{12}$>, <$E_{21}$,
$E_{22}$>, ..., <$E_{n1}$, $E_{n2}$>}\verb@}@, where the $E_{ij}$ are expressions that
yield the desired element type. For example, \verb@{<1, "a">, <2, "b">, <3,"c">}@ is of type {\tt rel[int, str]}.

Not surprisingly, $n$-ary relations are represented by the type {\tt
rel[$T_1$, $T_2$, ..., $T_n$]} which is a shorthand for {\tt set[<$T_1$,
$T_2$, ..., $T_n$>]}.  Most built-in operators and functions require binary
relations as arguments.  It is, however, perfectly possible to use $n$-ary
relations as values, or as arguments or results of functions.
Examples are:
\begin{itemize}
\item \verb@{<1,10>, <2,20>, <3,30>}@ is of type {\tt rel[int,int]} (yes
  indeed, you saw this same example before and then we gave  {\tt
  set[<int,int>]} as its type; remember that these types are interchangeable.),
\item \verb@{<"a",10>, <"b",20>, <"c",30>}@ is of type {\tt rel[str,int]}, and 
\item \verb@{{"a", 1, "b"}, {"c", 2, "d"}}@ is of type {\tt rel[str,int,str]}.
\end{itemize}


\subsection{User-defined Types and Values}

\paragraph{Alias types}
Everything can be expressed using the elementary types and values that are
provided by \rscript.  However, for the purpose of documentation and
readability it is sometimes better to use a descriptive name as type
indication, rather than an elementary type. The type declaration
\begin{exam}
{\tt type $T_1$ = $T_2$}
\end{exam}
states that the new type name $T_1$ can be used everywhere instead of the
already defined type name $T_2$. For instance,
\begin{exam}\begin{verbatim}
type ModuleId = str
type Frequency = int
\end{verbatim}
\end{exam}
introduces two new type names {\tt ModuleId} and {\tt Frequency}, both an
alias for the type {\tt str}.
The use of type aliases is a good way to hide representation details.

\paragraph{Composite Types and Values}
In ordinary programming languages record types or classes exist to introduce a
new type name for a collection of related, named, values and to provide access
to the elements of such a collection through their name. In \rscript,
tuples with named elements provide this facility. The type declaration
\begin{exam}
{\tt type $T$ = <$T_1$ $F_1$ ,..., $T_n$ $F_n$>}
\end{exam}
introduces a new composite type $T$, with $n$ elements.  The $i$-th element
$T_i$ $N_i$ has type $T_i$ and field name $F_i$.
The common dot notation for field access is used to address an element of
a composite type. If $V$ is a variable of type $T$, then the $i$-th element
can be accessed by {\tt $V$.$F_i$}. For instance,\footnote{The variable
  declarations that appear on lines 2 and 3 of this example are explained
  fully in Section~\ref{SEC:Declarations}.}
\begin{exam}\begin{verbatim}
type Triple = <int left, str middle, bool right>
Triple TR = <3, "a", true>
str S = TR.middle
\end{verbatim}
\end{exam}
first introduces the composite type {\tt Triple} and defines the {\tt Triple} variable
{\tt TR}. Next, the field selection {\tt TR.middle} is used to define the
string {\tt S}.

\paragraph{Implementation Note.} The current implementation severely restricts the re-use of
field names in different type declarations.  The only re-use that is
allowed are fields with the same name and the same type that appear at
the same position in different type declarations.

\paragraph{Type equivalence}
An \rscript should be \emph{well-typed}, this means above all that identifiers
that are used in expressions have been declared, and that operations and
functions should have operands of the required type.  We use \emph{structural
equivalence} between types as criterion for type equality.
The equivalence of two types $T_1$ and $T_2$ can be determined as follows:

\begin{itemize}
\item Replace in both $T_1$ and $T_2$ all user-defined types by their
  definition until all user-defined types have been eliminated.  This may
  require repeated replacements.  This gives, respectively, $T_1'$ and $T_2'$.

\item If $T_1'$ and $T_2'$ are identical, then $T_1$ and $T_2$ are equal.
\item Otherwise $T_1$ and $T_2$ are not equal.
\end{itemize}

\section{Comprehensions}

We will use the familiar notation
\begin{exam}
  \verb@{@{\tt $E_1$, ..., $E_m$ | $G_1$, ..., $G_n$}\verb@}@
\end{exam}
to denote the construction of a set consisting of the union of
successive values of the expressions $E_1 ,..., E_m$.  The values and the
generated set are determined by  $E_1 ,..., E_m$ and the \emph{generators}
$G_1 ,..., G_n$.  $E$ is computed for all possible
combinations of values produced by the generators.

Each generator may introduce new variables
that can be used in subsequent generators as well as in the expressions  $E_1 ,..., E_m$.
A generator can use the variables introduced by preceding
generators.  Generators may enumerate all the values in a set or
relation, they may perform a test, or they may assign a value to
variables.

\subsection{Generators}

\paragraph{Enumerator}
Enumerators generate all the values in a given set or relation.
They come in two flavors: 

\begin{itemize}
\item {\tt $T$ $V$~:~$E$}: the elements of the set $S$ (of type {\tt set[$T$]})
  that results from the evaluation
of expression $E$ are enumerated and subsequently assigned to the new variable
  $V$ of type $T$.
Examples are: 
\begin{itemize}
\item \verb@int N : {1, 2, 3, 4, 5}@,
\item \verb@str K : KEYWORDS@, where {\tt KEYWORDS} should evaluate to a value of
  type {\tt set[str]}.
\end{itemize}

\item {\tt <$D_1$,~...,~$D_n$>~:~$E$}: the elements of the relation $R$ (of type
{\tt rel[<$T'_1$,...,$T'_n$]}, where $T'_i$ is determined by the type of each
target $D_i$, see below) that results from the evaluation of expression $E$
are enumerated. The $i$-the element ($i=1,...,n$) of the resulting $n$-tuple
is subsequently combined with each target $D_i$ as follows:
\begin{itemize}
  \item If $D_i$ is a variable declaration of the form $T_i$ $V_i$, then the $i$-th element is assigned to $V_i$.
  \item If $D_i$ is an arbitrary expression $E_i$, then the value of
   the $i$-th element should be equal to the value of $E_i$. If they
   are unequal, computation continues with enumerating the next
   tuple in the  relation $R$.
\end{itemize}
Examples are:
\begin{itemize}
\item \verb@<str K, int N> : <"a",10>, <"b",20>, <"c",30>}@<
\item \verb@<str K, int N> : FREQUENCIES@, where {\tt FREQUENCIES} should
  evaluate to a value of type {\tt rel[str,int]}.
\item \verb@<str K, 10> : FREQUENCIES@, will only generate pairs with {\tt 10}
  as second element.
\end{itemize}
  
\end{itemize}

\paragraph{Test}
A test is a boolean-valued expression. If the evaluation yields {\tt true}
this indicates that the current combination of generated values up to this test
is still as desired and execution continues with subsequent generators.  If
the evaluation yields {\tt false} this indicates that the current combination
of values is undesired, and that another combination should be
tried. Examples:

\begin{itemize}
\item \verb@N >= 3@ tests whether {\tt N} has a value greater than or equal {\tt 3}.
\item \verb@S == "coffee"@ tests whether {\tt S} is equal to the string {\tt
"coffee"}.
\end{itemize}
In both examples, the variable ({\tt N}, respectively, {\tt S}) should have been introduced by a generator that
occurs earlier in the enclosing comprehension.

\paragraph{Assignment}
Assignments assign a value to one or more variables and also come in two flavors:

\begin{itemize}

\item {\tt $T$ $V$ <- $E$}: assigns the value of expression $E$ to the new variable $V$ of type $T$.

\item {\tt <$R_1$, ..., $R_n$> <- $E$}: combines the elements of the $n$-tuple
resulting from the evaluation of expression $E$ with each $T_i$ as follows:

\begin{itemize}

\item If $R_i$ is a variable declaration of the form $T$ $V_i$, then the $i$-th element is assigned to $V_i$.
\item If $R_i$ is an arbitrary expression $E_i$, then the value of
   the $i$-th element should be equal to the value of $E_i$. If they
   are unequal, the assignment acts as a test that fails (see above).
\end{itemize}

\end{itemize}

Examples of assignments are:
\begin{itemize}

\item {\tt rel[str,str] ALLCALLS <- CALLS+} assigns the transitive
closure of the relation {\tt CALLS} to the variable {\tt ALLCALLS}.

\item {\tt bool Smaller <- A <= B} assigns the result of the test {\tt
A <= B} to the Boolean variable {\tt Smaller}.

\item {\tt <int N, str S, 10> <- E} evaluates expression {\tt E}
(which should yield a tuple of type {\tt <int, str, int>}) and
performs a tuple-wise assignment to the new variables {\tt N} and {\tt
S} \emph{provided} that the third element of the result is equal to
{\tt 10}. Otherwise the assignment acts as a test that fails.

\end{itemize}


\subsection{Examples of Comprehensions}

\begin{itemize}

\item \verb@{X | int X : {1, 2, 3, 4, 5},  X >= 3}@ yields the set \verb@{3,4,5}@.

\item \verb@{<X, Y> | int X : {1, 2, 3}, int Y : {2, 3, 4}, X >= Y}@ yields the
  relation
\newline
\verb@{<2, 2>, <3, 2>, <3, 3>}@.


\item \verb@{<Y, X> | <int X, int Y> : {<1,10>, <2,20>}}@ yields the inverse of
the given relation: \verb@{<10,1>, <20,2>}@.

\item 
\verb@{X, X * X | X : {1, 2, 3, 4, 5},  X >= 3}@ yields the set
\verb@{3,4,5,9,16,25}@.
\end{itemize}

\section{Declarations} \label{SEC:Declarations}

\subsection{Variable Declarations}
A variable declaration has the form 
\begin{exam}
{\tt $T$ $V$ = $E$}
\end{exam}
where $T$ is a type,
$V$ is a variable name, and $T$ is an expression that should have type
$T$. The effect is that the value of expression $E$ is assigned to
$V$ and can be used later on as $V$'s value. Double declarations are
not allowed. As a convenience, also declarations without an initialization expression are
permitted and have the form 
\begin{exam}
{\tt $T$ $V$} 
\end{exam}
and only introduce the variable $V$. Examples:

\begin{itemize}
\item \verb@int max = 100@ declares the integer variable
{\tt max} with value {\tt 100}.

\item The definition
\begin{exam}
\begin{verbatim}
rel[str,int] day = {<"mon", 1>, <"tue", 2>, <"wed",3>, 
                    <"thu", 4>, <"fri", 5>, <"sat",6>, <"sun",7>}
\end{verbatim}
\end{exam}
declares the variable {\tt day}, a relation that maps strings to integers.
\end{itemize}

\subsection{Local Variable Declarations}
Local variables can be introduced as follows:
\begin{exam}
{\tt $E$ where $T_1$ $V_1$ = $E_1$, ..., $T_n$ $V_n$ = $E_n$ end where}
\end{exam}
First the local variables $V_i$ are bound to their respective values
$E_i$, and then the value of expression $E$ is yielded.


\subsection{Function Declarations}
A function declaration has the form
\begin{exam}
{\tt $T$ $F$($T_1 ~ V_1$, ..., $T_n ~ V_n$) = $E$}
\end{exam}
Here $T$ is the result type of the function and this should be equal to the
type of the associated expression $E$.  Each $T_i$ $V_i$ represents a typed
formal parameter of the function. The formal parameters may occur in $E$ and
get their value when $F$ is invoked from another expression.
Example:

\begin{itemize}
\item The function declaration
\begin{exam}\begin{verbatim}
rel[int, int] invert(rel[int,int] R) = {<Y, X> | <int X, int Y> : R }
\end{verbatim}
\end{exam}
yields the inverse of the argument relation {\tt R}. For instance,
\verb@invert({<1,10>, <2,20>})@ yields \verb@{<10,1>, <20,2>}@.
\end{itemize}

\paragraph{Parameterized types in function declarations}
The types that occur in function declarations may also contain
\emph{type variables} that are written as {\tt \&} followed by an identifier.
 In this way functions can be defined for arbitrary
types. Examples:

\begin{itemize}

\item The declaration
\begin{exam}\begin{verbatim}
rel[&T2, &T1] invert2(rel[&T1,&T2] R) = {<Y, X> | <&T1 X, &T2 Y> : R }
\end{verbatim}
\end{exam}
yields an inversion function that is applicable to any binary relation.
For instance,
\begin{itemize}
\item \verb@invert2({<1,10>, <2,20>})@ yields \verb@{<10,1>, <20,2>}@,
and 
\item \verb@invert2({<"mon", 1>, <"tue", 2>})@
yields \verb@{<1, "mon">, <2, "tue">}@.
\end{itemize}


\item The function
\begin{exam}\begin{verbatim}
<&T2, &T1> swap(&T1 A, &T2 B) = <B, A>
\end{verbatim}
\end{exam}
can be used to swap the elements of pairs of arbitrary types.  For instance,
\begin{itemize}
\item \verb@swap(<1, 2>)@ yields \verb@<2,1>@ and 
\item \verb@swap(<"wed", 3>)@ yields \verb@<3, "wed">@.
\end{itemize}
\end{itemize}

\section{Assertions}
An assert statement may occur everywhere where a declaration is allowed.  It
has the form 
\begin{exam}
{\tt assert $L$: $E$}
\end{exam}
 where $L$ is a string that serves as a
label for this assertion, and $E$ is a boolean-value expression.  During
execution, a list of true and false assertions is maintained.  When the script
is executed as a \emph{test suite} (see Section~\ref{running}) a summary of this
information is shown to the user. When the script is executed in the standard
fashion, the assert statement has no affect. Example:

\begin{itemize}
\item \begin{exam}\begin{verbatim}
assert "Equality on Sets 1": {1, 2, 3, 1} == {3, 2, 1, 1}
\end{verbatim}
\end{exam}
\end{itemize}

\section{Equations}
It is also possible to define mutually dependent sets of equations:

\begin{exam}
{\tt equations \\
       \hspace*{0.5cm}initial \\
          \hspace*{1cm}$T_1$ $V_1$ init $I_1$\\
          \hspace*{1cm}  ... \\
          \hspace*{1cm}$T_n$ $V_n$ init $I_n$\\
       \hspace*{0.5cm}satisfy\\
          \hspace*{1cm}$V_1$ = $E_1$\\
          \hspace*{1cm}...\\
          \hspace*{1cm}$V_n$ = $E_n$\\
end equations}
\end{exam}

\noindent In the {\tt initial} section, the variables $V_i$ are declared and
initialized.
In the {\tt satisfy} section, the actual set of equations is given.
The expressions $E_i$ may refer to any of the variables 
  $V_i$ (and to any variables declared earlier).  This set of equations is
  solved by evaluating the expressions $E_i$, assigning their value to
  the corresponding variables $V_i$, and repeating this as long as the
  value of one of the variables was changed. This is typically used for
  solving a set of dataflow equations. Example:

\begin{itemize}
\item 
Although transitive closure is provided as a built-in operator, we can use
equations to define the transitive closure of a relation.
Recall that \[R+ = R \cup (R \circ R) \cup (R \circ R \circ R) \cup ... .\]
This can be expressed as follows.

\begin{exam}
\begin{verbatim}
rel[int,int] R =  {<1,2>, <2,3>, <3,4>}

equations
  initial
     rel[int,int] T init R
  satisfy
     T = T union (T o R)
end equations
\end{verbatim}
\end{exam}
The resulting value of {\tt T} is as expected:
\begin{exam}
\begin{verbatim}
 {<1,2>, <2,3>, <3,4>, <1, 3>, <2, 4>, <1, 4>}
\end{verbatim}
\end{exam}
\end{itemize}


\chapter{Built-in Operators} \label{SEC:operators}

\fbox{\epsfig{figure=figs/microscope.ps,width=6cm}} \label{FIG:microscope}
\hspace*{0.5cm}\parbox[b]{8cm}{The built-in operators can be subdivided in several broad categories:
\begin{itemize}
\item Operations on Booleans (Section~\ref{BO:bool}): logical operators ({\tt
  and}, {\tt or}, {\tt implies} and {\tt  not}).
\item Operations on integers (Section~\ref{BO:int}):
arithmetic operators ({\tt +}, {\tt -}, {\tt *}, and {\tt /}) and 
comparison operators ({\tt ==}, {\tt !=}, {\tt <}, {\tt <=}, {\tt >}, and {\tt >=}).
\item Operations on strings (Section~\ref{BO:str}):
comparison operators ({\tt ==}, {\tt !=}, {\tt <}, {\tt <=}, {\tt >}, and {\tt >=}).
\item Operations on locations (Section~\ref{BO:loc}).
comparison operators ({\tt ==}, {\tt !=}, {\tt <}, {\tt <=}, {\tt >}, and {\tt >=}).
\item Operations on sets or relations (Section~\ref{BO:set-or-rel}):
membership tests ({\tt in}, {\tt notin}),
comparison operators ({\tt ==}, {\tt !=}, {\tt <}, {\tt <=}, {\tt >}, and {\tt
  >=}), and
construction operators ({\tt union}, {\tt inter}, {\tt diff}).

\item Operations on relations (Section~\ref{BO:relations}):
composition ({\tt o}), Cartesian product ({\tt x}),
left and right image operators, and
transitive closures ({\tt +}, {\tt *}).
\end{itemize}
\noindent The following sections give detailed descriptions and examples of all built-in operators.}

\section{Operations on Booleans} \label{BO:bool}

\begin{tabular}{|p{3.3cm}|p{10.7cm}|} \hline
\emph{bool}$_1$ \texttt{and} \emph{bool}$_2$ & yields {\tt true} if both arguments have the value true and
{\tt false} otherwise\\ \hline

\emph{bool}$_1$ \texttt{or} \emph{bool}$_2$ & yields {\tt true} if either argument has
                         the value {\tt true} and {\tt false} otherwise\\ \hline

\emph{bool}$_1$ \texttt{implies} \emph{bool}$_2$ & yields {\tt false} if
                             \emph{bool}$_1$ has the value {\tt true} and
                               \emph{bool}$_2$ has value {\tt false}, and
                         {\tt true} otherwise\\ \hline

{\tt not} \emph{bool} & yields true if \emph{bool} is {\tt false} and {\tt true} otherwise \\
\hline
\end{tabular}

\section{Operations on Integers} \label{BO:int}

\begin{tabular}{|p{3.3cm}|p{10.7cm}|} \hline
\emph{int}$_1$ {\tt ==} \emph{int}$_2$ & yields {\tt true} if both arguments are numerically equal and {\tt false}
otherwise\\ \hline

\emph{int}$_1$ {\tt !=} \emph{int}$_2$ & yields {\tt true} if both arguments are numerically unequal  and {\tt false}
otherwise\\ \hline

\emph{int}$_1$ {\tt <=} \emph{int}$_2$ & yields {\tt true} if \emph{int}$_1$ is numerically less than
or equal to \emph{int}$_2$ and {\tt false} otherwise\\ \hline

\emph{int}$_1$ {\tt <} \emph{int}$_2$ & yields {\tt true} if \emph{int}$_1$ is a numerically less than \emph{int}$_2$
and {\tt false} otherwise\\ \hline

\emph{int}$_1$ {\tt >=} \emph{int}$_2$ & yields {\tt true} if \emph{int}$_1$ is numerically greater
than or equal to \emph{int}$_2$  and {\tt false} otherwise\\ \hline

\emph{int}$_1$ {\tt >} \emph{int}$_2$ & yields {\tt true} if \emph{int}$_1$  is numerically greater than \emph{int}$_2$
and {\tt false} otherwise\\ \hline

\emph{int}$_1$ {\tt +} \emph{int}$_2$ & yields the arithmetic sum of
\emph{int}$_1$ and \emph{int}$_2$\\ \hline

\emph{int}$_1$ {\tt -} \emph{int}$_2$ & yields the arithmetic difference of
\emph{int}$_1$ and \emph{int}$_2$\\ \hline

\emph{int}$_1$ {\tt *} \emph{int}$_2$ & yields the arithmetic product of
\emph{int}$_1$ and \emph{int}$_2$\\ \hline

\emph{int}$_1$ {\tt /} \emph{int}$_2$ & yields the integer division of
\emph{int}$_1$ and \emph{int}$_2$ \\ \hline

\end{tabular}

\section{Operations on Strings} \label{BO:str}

\begin{tabular}{|p{3.3cm}|p{10.7cm}|} \hline

\emph{str}$_1$ {\tt ==} \emph{str}$_2$ & yields {\tt true} if both arguments are equal and {\tt false}
otherwise\\ \hline

\emph{str}$_1$ {\tt !=} \emph{str}$_2$ & yields {\tt true} if both arguments are unequal  and {\tt false}
otherwise\\ \hline

\emph{str}$_1$ {\tt <=} \emph{str}$_2$ & yields {\tt true} if \emph{str}$_1$ is lexicographically less than
or equal to \emph{str}$_2$ and {\tt false} otherwise\\ \hline

\emph{str}$_1$ {\tt <} \emph{str}$_2$ & yields {\tt true} if \emph{str}$_1$ is a lexicographically less than \emph{str}$_2$
and {\tt false} otherwise\\ \hline

\emph{str}$_1$ {\tt >=} \emph{str}$_2$ & yields {\tt true} if \emph{str}$_1$ is lexicographically greater
than or equal to \emph{str}$_2$  and {\tt false} otherwise\\ \hline

\emph{str}$_1$ {\tt >} \emph{str}$_2$ & yields {\tt true} if \emph{str}$_1$  lexicographically greater than \emph{str}$_2$
and {\tt false} otherwise\\ \hline

\end{tabular}
\section{Operations on Locations} \label{BO:loc}

\begin{tabular}{|p{3.3cm}|p{10.7cm}|} \hline
\emph{loc}$_1$ {\tt ==} \emph{loc}$_2$ & yields {\tt true} if both arguments
are identical and {\tt false}
otherwise\\ \hline

\emph{loc}$_1$ {\tt !=} \emph{loc}$_2$ & yields {\tt true} if both arguments are unequal  and {\tt false}
otherwise\\ \hline

\emph{loc}$_1$ {\tt <=} \emph{loc}$_2$ & yields {\tt true} if
\emph{loc}$_1$ is textually contained in 
or equal to \emph{loc}$_2$ and {\tt false} otherwise\\ \hline

\emph{loc}$_1$ {\tt <} \emph{loc}$_2$ & yields {\tt true} if \emph{loc}$_1$
is strictly textually contained  in \emph{loc}$_2$
and {\tt false} otherwise\\ \hline

\emph{loc}$_1$ {\tt >=} \emph{loc}$_2$ & yields {\tt true} if
\emph{loc}$_1$ textually encloses or
or is equal to \emph{loc}$_2$  and {\tt false} otherwise\\ \hline

\emph{loc}$_1$ {\tt >} \emph{loc}$_2$ & yields {\tt true} if \emph{loc}$_1$
strictly textually encloses \emph{loc}$_2$
and {\tt false} otherwise\\ \hline

\end{tabular}

\paragraph{Examples}
In the following examples the offset and length part of a location are set to
{\tt 0}; they are not used when determining the outcome of the comparison operators.

\begin{itemize}

 \item {\tt area-in-file("f", area(11, 1, 11, 9, 0, 0)) <} \newline 
{\tt area-in-file("f", area(10, 2, 12, 8, 0, 0))} yields {\tt true}.

 \item {\tt area-in-file("f", area(10, 3, 11, 7, 0,0))  <} \newline 
{\tt area-in-file("f", area(10, 2, 11, 8, 0, 0))} yields {\tt true}.

 \item {\tt area-in-file("f", area(10, 3, 11, 7, 0, 0))  <} \newline
{\tt area-in-file("g", area(10, 3, 11, 7, 0, 0))} yields {\tt false}.

\end{itemize}

\section{Operations on Sets or Relations} \label{BO:set-or-rel}

\subsection{Membership Tests} \label{BO:member}

\begin{tabular}{|p{3.3cm}|p{10.7cm}|} \hline

\emph{any} {\tt in} \emph{set} & yields {\tt true} if \emph{any} occurs as element
in \emph{set} and {\tt false} otherwise \\ \hline

\emph{any} {\tt notin} \emph{set} & yields {\tt false} if \emph{any} occurs as
element in \emph{set} and {\tt true} otherwise \\ \hline

\emph{tuple} {\tt in} \emph{rel} & yields {\tt true} if \emph{tuple} occurs as element in
\emph{rel}  and {\tt false} otherwise \\ \hline

\emph{tuple} {\tt notin} \emph{rel} & yields {\tt false} if \emph{tuple} occurs as
element in \emph{rel} and {\tt true} otherwise \\ \hline
\end{tabular}

\paragraph{Examples}

\begin{itemize}

\item \verb@3 in {1, 2, 3}@ yields {\tt true}.
\item \verb@4 in {1, 2, 3}@ yields {\tt false}.
\item \verb@3 notin {1, 2, 3}@ yields {\tt false}.
\item \verb@4 notin {1, 2, 3}@ yields {\tt true}.
\item \verb@<2,20> in {<1,10>, <2,20>, <3,30>}@ yields {\tt true}.
\item \verb@<4,40> notin {<1,10>, <2,20>, <3,30>}@ yields {\tt true}.

\end{itemize}

\paragraph{Note} If the first argument of these operators has type $T$, then
the second argument should have type {\tt set[$T$]}.

\subsection{Comparisons} \label{BO:set-comp}

\begin{tabular}{|p{3.3cm}|p{10.7cm}|} \hline
\emph{set}$_1$ {\tt ==} \emph{set}$_2$ & yields {\tt true} if both arguments are equal sets and {\tt false}
otherwise\\ \hline

\emph{set}$_1$ {\tt !=} \emph{set}$_2$ & yields {\tt true} if both arguments are unequal sets and {\tt false}
otherwise\\ \hline

\emph{set}$_1$ {\tt <=} \emph{set}$_2$ & yields {\tt true} if \emph{set}$_1$ is a subset of \emph{set}$_2$
and {\tt false} otherwise\\ \hline

\emph{set}$_1$ {\tt <} \emph{set}$_2$ & yields {\tt true} if \emph{set}$_1$ is a
strict subset of \emph{set}$_2$
and {\tt false} otherwise\\ \hline

\emph{set}$_1$ {\tt >=} \emph{set}$_2$ & yields {\tt true} if \emph{set}$_1$  is a
superset of \emph{set}$_2$
and {\tt false} otherwise\\ \hline

\emph{set}$_1$ {\tt >} \emph{set}$_2$ & yields {\tt true} if  \emph{set}$_1$  is a strict superset of \emph{set}$_2$
and {\tt false} otherwise\\ \hline 
\end{tabular}

\subsection{Construction} \label{BO:set-cons}

\begin{tabular}{|p{3.3cm}|p{10.7cm}|} \hline
\emph{set}$_1$ {\tt union} \emph{set}$_2$ & yields the set resulting from the union of the two arguments.
%%The number of occurrences of each element in the result is the {\bf maximum} of the number of occurrences of that element
%%in \emph{set}$_1$  and \emph{set}$_2$.
 \\ \hline

\emph{set}$_1$ {\tt inter} \emph{set}$_2$ & yields the set resulting from the intersection of the two arguments.
%%The number of occurrences of each element in the result is the {\bf minimum} of the number of occurrences of that element
%%in \emph{set}$_1$  and \emph{set}$_2$.
 \\ \hline

\emph{set}$_1$ \verb+\+ \emph{set}$_2$ & yields the set resulting from the difference of the two arguments.
%%The number of occurrences of each element in the result is the {\bf difference} of the number of occurrences of that element
%%in \emph{set}$_1$  and \emph{set}$_2$.
 \\ \hline

\end{tabular}

\paragraph{Examples}

\begin{itemize}
\item \verb@{1, 2, 3} union {4, 5, 6}@ yields \verb@{1, 2, 3, 4, 5, 6}@.
\item \verb@{1, 2, 3} union {1, 2, 3}@ yields  \verb@{1, 2, 3}@.
\item \verb@{1, 2, 3} union {4, 5, 6}@ yields \verb@{1, 2, 3, 4, 5, 6}@.

\item \verb@{1, 2, 3} inter {4, 5, 6}@ yields \verb@{ }@.
\item \verb@{1, 2, 3} inter {1, 2, 3}@ yields  \verb@{1, 2, 3}@.

\item \verb@{1, 2, 3, 4}  \ {1, 2, 3}@ yields  \verb@{4}@.
\item \verb@{1, 2, 3}  \ {4, 5, 6}@ yields \verb@{1, 2, 3}@.

\end{itemize}

\subsection{Miscellaneous} \label{BO:misc}
\begin{tabular}{|p{3.3cm}|p{10.7cm}|} \hline

\verb@#@ \emph{set} & yields the number of elements in \emph{set}. \\ \hline
\verb@#@ \emph{rel} & yields the number of tuples in \emph{rel}. \\ \hline
\end{tabular}

\paragraph{Examples}

\begin{itemize}
\item \verb@#{1, 2, 3}@ yields {\tt 3}.
\item \verb@{<1,10>, <2,20>, <3,30>}@ yield {\tt 3}.
\end{itemize}

\section{Operations on Relations} \label{BO:relations}

\begin{tabular}{|p{3.3cm}|p{10.7cm}|} \hline

\emph{rel}$_1$ {\tt o} \emph{rel}$_2$ & yields the relation resulting from the composition of the two arguments
 \\ \hline

\emph{set}$_1$ {\tt x}~ \emph{set}$_2$ & yields the relation resulting from the Cartesian product of the two arguments
 \\ \hline


\emph{rel} {\tt [-,} \emph{set} {\tt ]} & yields the left image of the \emph{rel}
 \\ \hline

\emph{rel} {\tt [-,} \emph{elem} {\tt ]} & yields the left image of the \emph{rel}
 \\ \hline

\emph{rel} {\tt [} \emph{elem} {\tt ,-]} & yields the right image of \emph{rel}
 \\ \hline

\emph{rel} {\tt [} \emph{set} {\tt ,-]} & yields the right image of \emph{rel}
 \\ \hline

\emph{set} {\tt [} \emph{elem} {\tt ]} & yields the right image of \emph{rel}
 \\ \hline

\emph{rel} {\tt [} \emph{set} {\tt ]} & yields the right image of \emph{rel}
 \\ \hline


\emph{rel} {\tt +} & yields the relation resulting from the transitive closure of
 \emph{rel}  \\ \hline

\emph{rel} {\tt *}  & yields the relation resulting from the reflexive transitive closure of
 \emph{rel}  \\ \hline

\end{tabular}

\paragraph{Composition: {\tt o}}

The composition operator combines two relations and can be defined as follows:

\begin{exam}
\begin{verbatim}
rel[&T1,&T3] compose(rel[&T1,&T2] R1, rel[&T2,&T3] R2) =
   {<V, Y> | <&T1 V, &T2 W> : R1, <&T2 X, &T3 Y> : R2, W == X }
\end{verbatim}
\end{exam}

\paragraph{Example}

\begin{itemize}
\item \verb@{<1,10>, <2,20>, <3,15>} o {<10,100>, <20,200>}@ yields  \verb@{<1,100>, <2,200>}@.
\end{itemize}


\paragraph{Cartesian product: {\tt x}}
The product operator combines two sets into a relation and can be defined as
follows:

\begin{exam}
\begin{verbatim}
rel[&T1,&T2] product(set[&T1] S1, set[&T2] S2) = 
   {<V, W> | &T1 V : S1, &T2 W : S2 }
\end{verbatim}
\end{exam}

\paragraph{Example}
\begin{itemize}
\item \verb@{1, 2, 3} x {9}@ yields \verb@{<1, 9>, <2, 9>, <3, 9>}@.
\end{itemize}

\paragraph{Left image: {\tt [-,~]}}

Taking the left image of a relation amounts to selecting
some elements from the domain of a relation.

The \emph{left} image operator takes a relation and an element {\tt E} and
produces a set consisting of all elements {\tt E}$_i$ in the domain of the relation
that occur in tuples of the form {\tt <E$_i$, E>}. It can be defined as
follows:

\begin{exam}
\begin{verbatim}
set[&T1] left-image(rel[&T1,&T2] R, &T2 E) = 
   { V | <&T1 V, &T2 W> : R, W == E }
\end{verbatim}
\end{exam}

The left image operator can be extended to take a set of elements as second
element instead of a single element:

\begin{exam}
\begin{verbatim}
set[&T1] left-image(rel[&T1,&T2] R, set[&T2] S) = 
   { V | <&T1 V, &T2 W> : R, W in S }
\end{verbatim}
\end{exam}

\paragraph{Examples}
Assume that {\tt Rel} has value
\verb@{<1,10>, <2,20>, <1,11>, <3,30>, <2,21>}@ in the following examples.
\begin{itemize}
\item \verb@Rel[-,10]@ yields  \verb@{1}@.
\item \verb@Rel[-,{10}]@ yields  \verb@{1}@.
\item \verb@Rel[-,{10, 20}]@ yields \verb@{1, 2}@.
\end{itemize}

\paragraph{Right image: {\tt [ ]} and {\tt [~,-]}}
Taking the right image of a relation amounts to selecting
some elements from the range of a relation.

The \emph{right} image operator takes a relation and an element {\tt E} and
produces a set consisting of all elements {\tt E}$_i$ in the range of the relation
that occur in tuples of the form {\tt <E, E$_i$>}. It can be defined as
follows:

\begin{exam}
\begin{verbatim}
set[&T2] right-image(rel[&T1,&T2] R, &T1 E) = 
   { W | <&T1 V, &T2 W> : R, V == E }
\end{verbatim}
\end{exam}

The right image operator can be extended to take a set of elements as second
element instead of a single element:

\begin{exam}
\begin{verbatim}
set[&T2] right-image(rel[&T1,&T2] R, set[&T1] S) = 
   { W | <&T1 V, &T2 W> : R, V in S}
\end{verbatim}
\end{exam}

\paragraph{Examples}
Assume that {\tt Rel} has value \verb@{<1,10>, <2,20>, <1,11>, <3,30>, <2,21>}@  in the following examples.
\begin{itemize}
\item \verb@Rel[1]@ yields \verb@{10, 11}@.
\item \verb@Rel[{1}]@ yields \verb@{10, 11}@.
\item \verb@Rel[{1, 2}]@ yields \verb@{10, 11, 20, 21}@.
\end{itemize}

\noindent These expressions are abbreviations for, respectively 
\verb@Rel[1,-]@,
\verb@Rel[{1},-]@. 
and 
\verb@Rel[{1, 2},-]@.

\chapter{Built-in Functions} \label{SEC:functions}
\fbox{\epsfig{figure=figs/declinatorium.ps,width=6cm}}
\label{FIG:declinatorium}
\hspace*{0.5cm}\parbox[b]{8cm}{
The built-in functions can be subdivided in several broad categories:

\begin{itemize}
\item Elementary functions on sets and relations
  (Section~\ref{elementary-functions}): identity ({\tt id}), inverse ({\tt
  inv}), complement ({\tt compl}), and powerset ({\tt power0}, {\tt power1}).

\item Extraction from relations (Section~\ref{extraction}):
domain ({\tt domain}), range ({\tt range}), and carrier ({\tt carrier}).

\item Restrictions and exclusions on relations (Section~\ref{restrictions}):
domain restriction ({\tt domainR}), range restriction ({\tt rangeR}),
carrier restriction ({\tt carrierR}),
domain exclusion ({\tt domainX}), range exclusion ({\tt rangeX}), and carrier
exclusion ({\tt carrierX}).


\end{itemize}
}

\begin{itemize}

\item Functions on tuples (Section~\ref{tuples}):
first element ({\tt first}),
and second element ({\tt second}).

\item Relations viewed as graphs (Section~\ref{relations-as-graphs}):
the root elements ({\tt top}),
the leaf elements ({\tt bottom}),
reachability with restriction ({\tt reachR}), and
reachability with exclusion ({\tt reachX}).

\item Functions on locations (Section~\ref{locations}):
file name ({\tt filename}),
beginning line ({\tt beginline}),
first column ({\tt begincol}),
ending line ({\tt endline}), and
ending column ({\tt endcol}).

\item Functions on sets of integers (Section~\ref{sets-of-integers}):
sum ({\tt sum}), average ({\tt average}), maximum ({\tt max}), and minimum
({\tt min}).

\end{itemize}
\noindent The following sections give detailed descriptions and examples of all built-in functions.}

\newcommand{\function}[5]{\subsection{#1: {\tt #2}}\label{BI:#2}
Definition:
\begin{quote}
#3
\end{quote}
#4
Example(s):
\begin{itemize}
#5
\end{itemize}
}

\newcommand{\functiona}[2]{\subsection{#1: {\tt #2}}\label{BI:#2}
Definition:}

\section{Elementary Functions on Sets and Relations}
\label{elementary-functions}


\functiona{Identity Relation}{id}
\begin{exam}
\begin{verbatim}
rel[&T, &T] id(set[&T] S) = { <X, X> | &T X : S}
\end{verbatim}
\end{exam}
{Yields the relation that results from transforming
each element in {\tt S} into a pair with that element as first and
second element.
}
{Examples: 
\begin{itemize}
\item \verb@id({1,2,3})@ yields \verb@{<1,1>, <2,2>, <3,3>}@.
\item \begin{sloppypar} 
  \verb@id({"mon", "tue", "wed"})@ yields \verb@{<"mon","mon">, <"tue","tue">, <"wed","wed">}@.\end{sloppypar}
\end{itemize}
}

\functiona{Deprecated: Set with unique elements}{unique}
\begin{exam}
\begin{verbatim}
set[&T] unique(set[&T] S) = primitive
\end{verbatim}
\end{exam}
{Yields the set (actually the set) that results from removing all duplicate
  elements from {\tt S}. This function stems from previous versions when we used bags instead of sets.
It now acts as the identity function and is deprecated.
}
{Example: 
\begin{itemize}
\item \verb@unique({1,2,1,3,2})@ yields \verb@{1,2,3}@.
\end{itemize}
}

\functiona{Inverse of a Relation}{inv}
\begin{exam}
\begin{verbatim}
 rel[&T2, &T1] inv (rel[&T1, &T2] R) = { <Y, X> | <&T1 X, &T2 Y> : R }
\end{verbatim}
\end{exam}
{ Yields the relation that is the inverse of the
argument relation {\tt R}, i.e. the relation in which the elements of all
tuples in {\tt R} have been
interchanged.
}
{Example: \begin{itemize}
\item \verb@inv({<1,10>, <2,20>})@ yields \verb@{<10,1>,<20,2>}@.
\end{itemize}
}
\functiona{Complement of a Relation}{compl}
\begin{exam}
\begin{verbatim}
rel[&T1, &T2] compl(rel[&T1, &T2] R) = (domain(R) x range(R)) \ R}
\end{verbatim}
\end{exam}
{ Yields the relation that is the complement of the
argument relation {\tt R}, using the carrier set of {\tt R} as universe.
}
{Example:
\begin{itemize}
\item \verb@compl({<1,10>}@  yields \verb@{<1, 1>, <10, 1>, <10, 10>}@.
\end{itemize}
}
%%----
\functiona{Powerset of a Set}{power0}
\begin{exam}
\begin{verbatim}
set[set[&T]] power0(set[&T] S) = primitive
\end{verbatim}
\end{exam}
{ Yields the powerset of set {\tt S} (including the empty set).}
{Example:
\begin{itemize}
\item \verb@power0({1, 2, 3, 4})@ yields 
\begin{exam}
\begin{verbatim}
  { {}, {1}, {2}, {3}, {4},{1,2}, {1,3}, {1,4}, {2,3}, {2,4}, {3,4},
    {1,2,3}, {1,2,4}, {1,3,4}, {2,3,4}, {1,2,3,4}}
\end{verbatim}
\end{exam}
\end{itemize}
}
%%----
\functiona{Powerset of a Set}{power1}
\begin{exam}
\begin{verbatim}
set[set[&T]] power1(set[&T] S) = primitive
\end{verbatim}
\end{exam}
{ Yields the powerset of set {\tt S} (excluding the empty set).}
{Example:
\begin{itemize}
\item \verb@power1({1, 2, 3, 4})@ yields 
\begin{exam}
\begin{verbatim}
{ {1}, {2}, {3}, {4},{1,2}, {1,3}, {1,4}, {2,3}, {2,4}, {3,4},
  {1,2,3}, {1,2,4}, {1,3,4}, {2,3,4}, {1,2,3,4}}
\end{verbatim}
\end{exam}
\end{itemize}
}
%%----
\section{Extraction from Relations} \label{extraction}
%%----
\functiona{Domain of a Relation}{domain}
\begin{exam}
\begin{verbatim}
set[&T1] domain (rel[&T1,&T2] R) = { X | <&T1 X, &T2 Y> : R }
\end{verbatim}
\end{exam}
{Yields the set that results from taking
the first element of each tuple in relation {\tt R}.
}
{Examples:
\begin{itemize}
\item \verb@domain({<1,10>, <2,20>})@ yields \verb@{1, 2}@.
\item \verb@domain({<"mon", 1>, <"tue", 2>})@ yields \verb@{"mon", "tue"}@.
\end{itemize}
}
%%----
\functiona {Range of a Relation}{range}
\begin{exam}
\begin{verbatim}
set[&T2] range (rel[&T1,&T2] R) = { Y | <&T1 X, &T2 Y> : R }
\end{verbatim}
\end{exam}
{Yields the set that results from taking
the second element of each tuple in relation {\tt R}.
}
{Examples:
\begin{itemize}
\item \verb@range({<1,10>, <2,20>})@ yields \verb@{10, 20}@.
\item \verb@range({<"mon", 1>, <"tue", 2>})@ yields \verb@{1, 2}@.
\end{itemize}
}
%%----
\functiona {Carrier of a Relation}{carrier}
\begin{exam}
\begin{verbatim}
set[&T]  carrier (rel[&T,&T] R) = domain(R) union range(R)
\end{verbatim}
\end{exam}
{Yields the set that results from taking
the first and  second element of each tuple in the relation {\tt R}.
Note that the domain and range type of {\tt R} should be the same.
}
{Example:
\begin{itemize}
\item \verb@carrier({<1,10>, <2,20>})@ yields \verb@{1, 10, 2, 20}@.
\end{itemize}
}
%%----
\section{Restrictions and Exclusions on Relations} \label{restrictions}
%%---
\functiona{Domain Restriction of a Relation}{domainR}
\begin{exam}
\begin{verbatim}
rel[&T1,&T2] domainR (rel[&T1,&T2] R, set[&T1] S) =
   { <X, Y> | <&T1 X, &T2 Y> : R, X in S }
\end{verbatim}
\end{exam}
{ Yields a relation identical to the relation {\tt R}
  but only containing tuples whose first element occurs in set {\tt S}.
}
{Example:
\begin{itemize}
\item \verb@domainR({<1,10>, <2,20>, <3,30>}, {3, 1}@ yields \verb@{<1,10>, <3,30>}@.
\end{itemize}
}
%%---
\functiona{Range Restriction of a Relation}{rangeR}
\begin{exam}
\begin{verbatim}
rel[&T1,&T2] rangeR (rel[&T1,&T2] R, set[&T2] S) =
   { <X, Y> | <&T1 X, &T2 Y> : R, Y in S }
\end{verbatim}
\end{exam}
{ Yields a relation identical to relation {\tt R} but only containing tuples
  whose second element occurs in set {\tt S}.
}
{Example:
\begin{itemize}
 \item \verb@rangeR({<1,10>, <2,20>, <3,30>}, {30, 10}@ yields \verb@{<1,10>, <3,30>}@.
\end{itemize}
}
%%---
\functiona{Carrier Restriction of a Relation}{carrierR}
\begin{exam}
\begin{verbatim}
rel[&T,&T] carrierR (rel[&T,&T] R, set[&T] S) = 
   { <X, Y> | <&T X, &T Y> : R, X in S, Y in S }
\end{verbatim}
\end{exam}
{ Yields a relation identical to relation {\tt R}
  but only containing tuples whose first and second element occur in set {\tt
    S}.
}
{Example:
\begin{itemize}
 \item \verb@carrierR({<1,10>, <2,20>, <3,30>}, {10, 1, 20})@ yields \verb@{<1,10>}@.
\end{itemize}
}
%%---
\functiona{Domain Exclusion of a Relation}{domainX}
\begin{exam}
\begin{verbatim}
rel[&T1,&T2] domainX (rel[&T1,&T2] R, set[&T1] S) =
   { <X, Y> | <&T1 X, &T2 Y> : R, X notin S }
\end{verbatim}
\end{exam}
{ Yields a relation identical to relation {\tt R}
  but with all tuples removed whose first element occurs in set {\tt S}.}
{Example:
\begin{itemize}
\item \verb@domainX({<1,10>, <2,20>, <3,30>}, {3, 1})@ yields \verb@{<2, 20>}@.
\end{itemize}
}
%%---
\functiona{Range Exclusion of a Relation}{rangeX}
\begin{exam}
\begin{verbatim}
rel[&T1,&T2] rangeX (rel[&T1,&T2] R, set[&T2] S) =
   { <X, Y> | <&T1 X, &T2 Y> : R, Y notin S }
\end{verbatim}
\end{exam}
{ Yields a relation identical to relation {\tt R} but with all tuples removed
  whose  second element occurs in set {\tt S}.}
{Example:
\begin{itemize}
 \item \verb@rangeX({<1,10>, <2,20>, <3,30>}, {30, 10})@ yields \verb@{<2, 20>}@.
\end{itemize}
}
%%---
\functiona{Carrier Exclusion of a Relation}{carrierX}
\begin{exam}
\begin{verbatim}
rel[&T,&T] carrierX (rel[&T,&T] R, set[&T] S) =
   { <X, Y> | <&T1 X, &T2 Y> : R, X notin S, Y notin S }
\end{verbatim}
\end{exam}
{ Yields a relation identical to relation {\tt R}
  but with all tuples removed whose first or second element occurs in set {\tt
    S.}
{Example:
\begin{itemize}
 \item \verb@carrierX({<1,10>, <2,20>, <3,30>}, {10, 1, 20})@ yields \verb@{<3,30>}@.
\end{itemize}
}
%%---
\section{Tuples} \label{tuples}
%%---
\functiona{First Element of a Tuple}{first}
\begin{exam}
\begin{verbatim}
&T1 first(<&T1, &T2> P) = primitive
\end{verbatim}
\end{exam}
{ Yields the first element of the tuple {\tt P}.}
{Examples:
\begin{itemize}
\item \verb@first(<1, 10>)@ yields {\tt 1}.
\item \verb@first(<"mon", 1>)@ yields {\tt "mon"}.
\end{itemize}
}
%%---
\functiona{Second Element of a Tuple}{second}
\begin{exam}
\begin{verbatim}
&T2 second(<&T1, &T2> P) = primitive
\end{verbatim}
\end{exam}
{ Yields the second element of the tuple {\tt P}.}
{Examples:
\begin{itemize}
\item \verb@second(<1, 10>)@ yields {\tt 10}.
\item \verb@second(<"mon", 1>)@ yields {\tt 1}.
\end{itemize}
}
%%---
\section{Relations viewed as graphs} \label{relations-as-graphs}
%%---
\functiona {Top of a Relation}{top}
\begin{exam}
\begin{verbatim}
set[&T] top(rel[&T, &T] R) = unique(domain(R)) \ range(R)
\end{verbatim}
\end{exam}
{Yields the set of all roots when the relation {\tt R} is
viewed as a graph. Note that the domain and range type of {\tt R} should be the same.
}
{Example:
\begin{itemize}
\item \verb@top({<1,2>, <1,3>, <2,4>, <3,4>})@ yields \verb@{1}@.
\end{itemize}
}
%%---
\functiona{Bottom of a Relation}{bottom}
\begin{exam}
\begin{verbatim}
set[&T] bottom(rel[&T,&T] R) = unique(range(R)) \ domain(R)
\end{verbatim}
\end{exam}
{Yields the set of all leaves when the relation {\tt R} is
viewed as a graph. Note that the domain and range type of {\tt R} should be
the same.
}
{Example:
\begin{itemize}
\item \verb@bottom({<1,2>, <1,3>, <2,4>, <3,4>})@ yields \verb@{4}@.
\end{itemize}
}
%%---
\functiona{Reachability with Restriction}{reachR}
\begin{exam}
\begin{verbatim}
set[&T] reachR( set[&T] Start, set[&T] Restr, rel[&T,&T] Rel) =
   range(domainR(Rel, Start) o carrierR(Rel, Restr)+)
\end{verbatim}
\end{exam}
{ Yields the elements that can be reached from set {\tt Start} using the
  relation {\tt Rel}, such that only elements in set {\tt Restr} are used.
}
{Example:
\begin{itemize}
\item  \verb@reachR({1}, {1, 2, 3}, {<1,2>, <1,3>, <2,4>, <3,4>})@ yields \verb@{2, 3}@.
\end{itemize}
}
%%---
\functiona{Reachability with Exclusion}{reachX}
\begin{exam}
\begin{verbatim}
set[&T] reachX( set[&T] Start, set[&T] Excl, rel[&T,&T] Rel) =
   range(domainR(Rel, Start) o carrierX(Rel, Excl)+)
\end{verbatim}
\end{exam}
{ Yields the elements that can be reached from  set {\tt Start} using the
  relation {\tt Rel}, such that no elements in set {\tt Excl} are used.
}
{Example:
\begin{itemize}
\item  \verb@reachX({1}, {2}, {<1,2>, <1,3>, <2,4>, <3,4>})@ yields  \verb@{3, 4}@.
\end{itemize}
}
%%---
\section{Functions on Locations} \label{locations}
%%---
\functiona{File Name of a Location}{filename}
\begin{exam}
\begin{verbatim}
str filename(loc A) = primitive
\end{verbatim}
\end{exam}
{Yields the file name of location {\tt A}.}
{ Example:
\begin{itemize}
\item \verb@filename(area-in-file("pico1.trm",area(5,2,6,8,0,0)))@ yields {\tt "pico1.trm"}.
\end{itemize}
}
%%----
\functiona{Beginning Line of a Location}{beginline}
\begin{exam}
\begin{verbatim}
int beginline(loc A) = primitive
\end{verbatim}
\end{exam}
{Yields the first line of location {\tt A}.}
{ Example:
\begin{itemize}
\item \verb@beginline(area-in-file("pico1.trm",area(5,2,6,8,0,0)))@ yields {\tt 5}.
\end{itemize}
}
%%----
\functiona{First Column of a Location}{begincol}
\begin{exam}
\begin{verbatim}
int begincol(loc A) = primitive
\end{verbatim}
\end{exam}
{Yields the first column of location {\tt A}.}
{ Example:
\begin{itemize}
\item \verb@begincol(area-in-file("pico1.trm",area(5,2,6,8,0,0)))@ yields {\tt 2}.
\end{itemize}
}
%%----
\functiona{Ending Line of a Location}{endline}
\begin{exam}
\begin{verbatim}
int endline(loc A) = primitive
\end{verbatim}
\end{exam}
{Yields the last line of location {\tt A}.}
{ Example:
\begin{itemize}
\item \verb@endline(area-in-file("pico1.trm",area(5,2,6,8,0,0)))@ yields {\tt 6}.
\end{itemize}
}
%%----
\functiona{Ending Column of a Location}{endcol}
\begin{exam}
\begin{verbatim}
int endcol(loc A) = primitive
\end{verbatim}
\end{exam}
{Yields the last column of location {\tt A}.}
{ Example:
\begin{itemize}
\item \verb@endcol(area-in-file("pico1.trm",area(5,2,6,8,0,0)))@ yields {\tt 8}.
\end{itemize}
}
%%----
\section{Functions on Sets of Integers} \label{sets-of-integers}
The functions in this section operate on sets of integers.
Some functions (i.e., {\tt sum-domain}, {\tt sum-range}, {\tt average-domain},
{\tt average-range}) exist to solve the problem that we can only provide sets
of integers and cannot model bags that may contain repeated occurrences of the
same integer. For some calculations it is important to include these
repetitions in the calculation (e.g., computing the average length of class methods
given a relation from methods names to number of lines in the method.)
%%----
\functiona{Sum of a Set of Integers}{sum}
\begin{exam}
\begin{verbatim}
int sum(set[int] S) = primitive
\end{verbatim}
\end{exam}
{Yields the sum of the integers in set {\tt S}.}
{Example:
\begin{itemize}
\item \verb@sum({1, 2, 3})@ yields {\tt 6}.
\end{itemize}
}
%%----
\functiona{Sum of First Elements of Tuples in a Relation}{sum-domain}
\begin{exam}
\begin{verbatim}
int sum-domain(rel[int,&T] R) = primitive
\end{verbatim}
\end{exam}
{Yields the sum of the integers that appear in the first element of the tuples of {\tt R}.}
{Example:
\begin{itemize}
\item \verb@sum-domain({<1,"a">, <2,"b">, <1,"c">})@ yields {\tt 4}.
\end{itemize}
Be aware that
\verb@sum(domain({<1,"a">, <2,"b"">, <1, "c">}))@ would be equal to {\tt 3}
because the function {\tt domain} creates a \emph{set} (as
opposed to a bag) and its result would thus contain only one occurrence of {\tt 1}.
}
%%----
\functiona{Sum of Second Elements of Tuples in a Relation}{sum-range}
\begin{exam}
\begin{verbatim}
int sum-range(set[int] S) = primitive
\end{verbatim}
\end{exam}
{Yields the sum of the integers that appear in the second element of the tuples of {\tt R}.}
{Example:
\begin{itemize}
\item \verb@sum-range({<"a",1>, <"b",2>, <"c",1>})@ yields {\tt 4}.
\end{itemize}
}
%%---- *********************************************** average-domain en average-range
\functiona{Average of a Set of Integers}{average}
\begin{exam}
\begin{verbatim}
int average(set[int] S) = sum(S)/(#S)
\end{verbatim}
\end{exam}
{Yields the average of the integers in set {\tt S}.}
{Example:
\begin{itemize}
\item \verb@average({1, 2, 3})@ yields {\tt 3}.
\end{itemize}
}
%%----
\functiona{Average of First Elements of Tuples in a Relation}{average-domain}
\begin{exam}
\begin{verbatim}
int average-domain(rel[int,&T] R) = sum-domain(R)/(#R)
\end{verbatim}
\end{exam}
{Yields the average of the integers that appear in the first element of the tuples of {\tt R}.}
{Example:
\begin{itemize}
\item \verb@average({<1,"a">, <2,"b">, <3,"c">})@ yields {\tt 2}.
\end{itemize}
}
%%----
\functiona{Average of Second Elements of Tuples in a Relation}{average-range}
\begin{exam}
\begin{verbatim}
int average(rel[&T,int] R) = sum-range(R)/(#R)
\end{verbatim}
\end{exam}
{Yields the average of the integers that appear in the second element of the tuples of {\tt R}.}
{Example:
\begin{itemize}
\item \verb@average({<"a",1>, <"b",2>, <"c",3>})@ yields {\tt 2}.
\end{itemize}
}
%%----
\functiona{Maximum of a Set of Integers}{max}
\begin{exam}
\begin{verbatim}
int max(set[int] S) = primitive
\end{verbatim}
\end{exam}
{Yields the largest integer in set {\tt S}.}
{Example:
\begin{itemize}
\item \verb@max({1, 2, 3})@ yields {\tt 3}.
\end{itemize}
}
%%----
\functiona{Minimum of a Set of Integers}{min}
\begin{exam}
\begin{verbatim}
int min(set[int] S) = primitive
\end{verbatim}
\end{exam}
{Yields the smallest integer in set {\tt S}.}
{Example:
\begin{itemize}
\item \verb@min({1, 2, 3})@ yields {\tt 1}.
\end{itemize}
}
%%----
\newpage
\chapter{Larger Examples} \label{SEC:larger-examples}

\fbox{\epsfig{figure=figs/vuurtoren.ps,height=10cm}} \label{FIG:vuurtoren}
\hspace*{0.5cm}\parbox[b]{7.5cm}{
Now we will have a closer look at some larger applications of \rscript.
We start by analyzing the global structure of a software system. 
You may now want to reread the example of call graph analysis given earlier in
Chapter~\ref{SEC:motivating-example} as a reminder. The component structure of
an application is analyzed in Section~\ref{SEC:components}  and Java systems
are analyzed in Section~\ref{SEC:Java-analysis}. Next we move on to the
detection
of initialized variables in Section~\ref{SEC:uninit} and we explain how source
code locations can be included in a such an analysis
(Section~\ref{SEC:UsingLocations}).

As an example of computing code metrics, we describe the calculation of
McCabe's cyclomatic complexity in Section~\ref{SEC:McCabe}. Several examples
of dataflow analysis follow in Section~\ref{SEC:dataflow}. A description of
program slicing concludes the chapter (Section~\ref{SEC:slicing}).}

\section{Analyzing the Component Structure of an Application}\label{SEC:components}
A frequently occurring problem is that we know the call
relation of a system but that we want to understand it at the component level
rather than at the procedure level. If it is known to which component each
procedure belongs, it is possible to \emph{lift} the call relation to the
component level as proposed in \cite{Krikhaar99}.

First, introduce new types to denote procedure calls as well as components of a system:

\begin{exam}\begin{verbatim}
type proc = str
type comp = str
\end{verbatim}
\end{exam}

\noindent Given a calls relation {\tt Calls2}, the next step is to define the
components of the system and to define a {\tt PartOf} relation between procedures and
components.

\begin{exam}\begin{verbatim}
rel[proc,proc] Calls = {<"main", "a">, <"main", "b">, <"a", "b">, 
                         <"a", "c">, <"a", "d">, <"b", "d">}

set[comp] Components = {"Appl", "DB", "Lib"}

rel[proc, comp] PartOf = {<"main", "Appl">, <"a", "Appl">, <"b", "DB">,
                          <"c", "Lib">, <"d", "Lib">}
\end{verbatim}
\end{exam}

\noindent Actual lifting, amounts to translating each call between procedures by a call between components.
This is achieved by the following function {\tt lift}:

\begin{exam}
\begin{verbatim}
rel[comp,comp] lift(rel[proc,proc] aCalls,  rel[proc,comp] aPartOf) =
   { <C1, C2> | <proc P1, proc P2> : aCalls, 
                <comp C1, comp C2> : aPartOf[P1] x aPartOf[P2]
   }
\end{verbatim}
\end{exam}

\noindent In our example, the lifted call relation between components is obtained by

\begin{exam}\begin{verbatim}
rel[comp,comp] ComponentCalls = lift(Calls2, PartOf)
\end{verbatim}
\end{exam}
and has as value:
\begin{exam}\begin{verbatim}
{<"DB", "Lib">, <"Appl", "Lib">, <"Appl", "DB">, <"Appl", "Appl">}
\end{verbatim}
\end{exam}

\noindent The relevant relations for this example are shown in Figure ~\ref{FIG:parts}.


\begin{figure}[tb]
\begin{center}
\epsfig{figure=figs/parts.eps,width=13cm}
\vspace*{-12.5cm}
\end{center}
\hrulefill
\caption{\label{FIG:parts} (a) {\tt Calls2}; (b) {\tt PartOf}; (c) {\tt ComponentCalls}}
\end{figure}

\section{Analyzing the Structure of Java Systems}\label{SEC:Java-analysis}

\begin{figure}[tb]
{\small
\begin{verbatim}
package CH.ifa.draw.standard;

import java.awt.Point;
import CH.ifa.draw.framework.*;
/**
 * A LocatorHandle implements a Handle by delegating the location requests to
 * a Locator object.
 */
public class LocatorHandle extends AbstractHandle {
    private Locator       fLocator;
    /**
     * Initializes the LocatorHandle with the given Locator.
     */
    public LocatorHandle(Figure owner, Locator l) {
        super(owner);
        fLocator = l;
    }
    /**
     * Locates the handle on the figure by forwarding the request
     * to its figure.
     */
    public Point locate() {
        return fLocator.locate(owner());
    }
}
\end{verbatim} 
\hrulefill}
\caption{\label{FIG:LocatorHandle}The class {\tt LocatorHandle} from JHotDraw 5.2}
\end{figure}

Now we consider the analysis of Java systems (inspired by \cite{BNL03}).
Suppose that the type {\tt class} is defined as follows
\begin{exam}\begin{verbatim}
type class = str
\end{verbatim}
\end{exam}
and that the following relations are available about a Java application:

\begin{itemize}

\item {\tt rel[class,class] CALL}: If {\tt <C$_1$, C$_2$>} is an element of {\tt CALL}, then
some method of {\tt C$_2$} is called from {\tt C$_1$}.

\item {\tt rel[class,class] INHERITANCE}: If {\tt <C$_1$, C$_2$>} is an element of {\tt INHERITANCE},
then class {\tt C$_1$} either extends class {\tt C$_2$} or {\tt C$_1$}
implements interface {\tt C$_2$}.

\item {\tt rel[class,class] CONTAINMENT}: If {\tt <C$_1$, C$_2$>} is an element of {\tt CONTAINMENT},
then one of the attributes of class  {\tt C$_1$} is of type {\tt C$_2$}.

\end{itemize}

To make this more explicit, consider the class {\tt LocatorHandle} from the
JHotDraw application (version 5.2) as shown in Figure~\ref{FIG:LocatorHandle}.
It leads to the addition to the above relations of the following tuples:

\begin{itemize}
\item To {\tt CALL} the pairs {\tt <"LocatorHandle", "AbstractHandle">} and
  {\tt <"LocatorHandle", "Locator">} will be added.

\item To {\tt INHERITANCE} the pair      {\tt <"LocatorHandle",
  "AbstractHandle">} will be added.
\item To {\tt CONTAINMENT} the pair  {\tt <"LocatorHandle",  "Locator">} will
  be added.
\end{itemize}

\paragraph{Classes in Cycles}
Cyclic structures in object-oriented systems makes understanding hard.
Therefore it is interesting to spot classes that occur as part of a cyclic
dependency.  Here we determine cyclic uses of classes that include calls,
inheritance and containment. This is achieved as follows:

\begin{exam}\begin{verbatim}
rel[class,class] USE = CALL union CONTAINMENT union INHERITANCE
set[str] ClassesInCycle =
   {C1 | <class C1, class C2> : USE+, C1 == C2}
\end{verbatim}
\end{exam}
First, we define the {\tt USE} relation as the union of the three available
relations {\tt CALL}, {\tt CONTAINMENT} and {\tt INHERITANCE}. Next, we consider all
pairs {\tt <C1, C2>} in the transitive closure of the {\tt USE} relation such that
{\tt C1} and {\tt C2} are equal.  Those are precisely the cases of a class with a cyclic
dependency on itself.

Probably, we do not only want to know which classes occur in a cyclic
dependency, but we also want to know which classes are involved in such a
cycle. In other words, we want to associate with each class a set of classes
that are responsible for the cyclic dependency. This can be done as follows.

\begin{exam}\begin{verbatim}
rel[class,class] USE = CALL union CONTAINMENT union INHERITANCE
set[class] CLASSES = carrier(USE)
rel[class,class] USETRANS = USE+
rel[class,set[class]] ClassCycles = 
   {<C, USETRANS[C]> | class C : CLASSES, <C, C> in USETRANS }
\end{verbatim}
\end{exam}
First, we introduce two new shorthands: {\tt CLASSES} and {\tt USETRANS}.  Next,
we consider all classes {\tt C} with a cyclic dependency and add the pair {\tt
<C, USETRANS[C]>} to the relation {\tt ClassCycles}.  Note that {\tt
USETRANS[C]} is the right image of the relation {\tt USETRANS} for element
{\tt C}, i.e., all classes that can be called transitively from class {\tt C}.

\section{Finding Uninitialized and Unused Variables in a Program}\label{SEC:uninit}

Consider the following program in the toy language Pico:
\footnote{This is an extended version of the example presented earlier
  in~\cite{KlintIWPC03}.}

\begin{verbatim}
[ 1] begin declare x : natural, y : natural,
[ 2]              z : natural, p : natural;
[ 3]  x := 3;
[ 4]  p := 4;
[ 5]  if q then
[ 6]        z := y + x
[ 7]  else
[ 8]        x := 4
[ 9]  fi;
[10]  y := z
[11] end
\end{verbatim}

Inspection of this program learns that some of the variables are being used
before they have been initialized.  The variables in question are {\tt q}
(line 5), {\tt y} (line 6), and {\tt z} (line 10). It is also clear that
variable {\tt p} is initialized (line 4), but is never used.  How can we
automate these kinds of analysis?

Recall from Section~\ref{SEC:Introduction} that we follow extract-enrich-view
paradigm to approach such a problem.

The first step is to determine which elementary facts we need about the
program.  For this and many other kinds of program analysis, we need at least
the following:

\begin{itemize}
\item The \emph{control flow graph} of the program. We represent it by a relation
{\tt PRED} (for predecessor) which relates each statement with each
predecessors.

\item The \emph{definitions} of each variable, i.e., the program statements where a
  value is assigned to the variable. It is represented by the relation {\tt
  DEFS}.

\item The \emph{uses} of each variable, i.e., the program statements where the
  value of the variable is used.  It is represented by the relation {\tt
  USES}.
\end{itemize}

In this example, we will use line numbers to identify the statements in the
program.\footnote{In Section~\ref{SEC:UsingLocations}, we will use locations to represent statements.}

Assuming that there is a tool to extract the above information from a program text,
we get the following for the above example:

\begin{exam}
\begin{verbatim}
type expr = int
type varname = str
expr ROOT = 1
rel[expr,expr] PRED = { <1,3>, <3,4>, <4,5>, <5,6>, <5,8>, <6,10>, <8,10> }
rel[expr,varname] DEFS = {<3,"x">, <4,"p">, <6,"z">, <8,"x">, <10,"y">}
rel[expr,varname] USES = {<5,"q">, <6,"y">, <6,"x">, <10,"z">}
\end{verbatim}
\end{exam}

This concludes the extraction phase. Next, we have to enrich these basic
facts to obtain the initialized variables in the program. 

So, when is a variable \emph{V} in some statement \emph{S} initialized?  If we
execute the program (starting in {\tt ROOT}), there may be several possible
execution path that can reach statement \emph{S}.  All is well if \emph{all}
these execution path contain a definition of \emph{V}.  However, if one or
more of these path do \emph{not} contain a definition of \emph{V}, then
\emph{V} may be uninitialized in statement \emph{S}. This can be formalized as
follows:
\begin{exam}
\begin{verbatim}
rel[expr,varname] UNINIT = 
   { <E, V> | <expr E, varname V>: USES, 
              E in reachX({ROOT}, DEFS[-,V], PRED)
   }
\end{verbatim}
\end{exam}

\noindent We analyze this definition in detail:
\begin{itemize}
\item {\tt <expr E, varname V> : USES} enumerates all tuples in the {\tt USES} relation.
In other words, we consider the use of each variable in turn.

\item {\tt E in reachX({ROOT}, DEFS[-,V], PRED)} is a test that
  determines whether statement {\tt S} is reachable from the {\tt ROOT}
  without encountering a definition of variable {\tt V}.
  \begin{itemize}
    \item {\tt \{ROOT\}} represents the initial set of nodes from which all
    path should start.
    \item {\tt DEFS[-,V]} yields the set of all statements in which a definition
    of variable {\tt V} occurs. These nodes form the exclusion set for
    {\tt reachX}: no path will be extended beyond an element in this set.
    \item {\tt PRED} is the relation for which the reachability has to be
    determined.
    \item The result of  {\tt reachX({ROOT}, DEFS[-,V], PRED)} is a set
    that contains all nodes that are reachable from the
    {\tt ROOT} (as well as all intermediate nodes on each path).
    \item Finally, {\tt E in reachX({ROOT}, DEFS[-,V], PRED)} tests
    whether expression {\tt E} can be reached from the {\tt ROOT}.
  \end{itemize}
\item The net effect is that {\tt UNINIT} will only contain pairs
that satisfy the test just described.
\end{itemize}

When we execute the resulting \rscript (i.e., the declarations of {\tt ROOT},
{\tt PRED}, {\tt DEFS}, {\tt USES} and {\tt UNINIT}), we get as value
for {\tt UNINIT}:

\begin{exam}
\begin{verbatim}
 {<5, "q">, <6, "y">, <10, "z">}
\end{verbatim}
\end{exam}
and this is in concordance with the informal analysis given at the beginning of this
example.

As a bonus, we can also determine the \emph{unused} variables in a
program, i.e., variables that are defined but are used nowhere.
This is done as follows:
\begin{exam}
\begin{verbatim}
set[var] UNUSED = range(DEFS) \ range(USES)
\end{verbatim}
\end{exam}
Taking the range of the relations {\tt DEFS} and {\tt USES} yields the
variables that are defined, respectively, used in the program. The difference
of these two sets yields the unused variables, in this case \verb@{"p"}@.

\section{Using Locations to Represent Program
  Fragments}\label{SEC:UsingLocations}

\begin{figure}[tb]
\begin{center}
\epsfig{figure=figs/meta-pico.eps,width=6cm}
\hspace*{0.5cm}
\epsfig{figure=figs/pico-example.eps,width=6cm}
\end{center}
\hrulefill
\caption{\label{FIG:meta-pico}Checking undefined variables in Pico programs
  using the ASF+SDF Meta-Environment. On the left, main window of Meta-Environment
  with error messages related to Pico program shown on the right.}
\end{figure}

One aspect of the example we have just seen is artificial: where do these
line numbers come from that we used to indicate expressions in the program?
One solution is to let the extraction phase generate \emph{locations}
to precisely indicate relevant places in the program text.

Recall from Section~\ref{SEC:ElementaryTypes}, that a location
consists of a file name, a begin line, a begin position, an end line, and an
end position. Also recall that locations can be compared: a location $A_1$ is smaller
than another location $A_2$, if $A_1$ is textually contained in $A_2$.
By including locations in the final answer of a relational
expression, external tools will be able to highlight places of interest in the
source text. 

The first step, is to define the type {\tt expr} as aliases for {\tt loc}
(instead of {\tt int}):

\begin{exam}\begin{verbatim} 
type expr = loc
type varname = str
\end{verbatim}
\end{exam}

Of course, the actual relations are now represented differently.
For instance,  the {\tt USES} relation may now look like
\begin{exam}
\begin{verbatim}
{ <area-in-file("/home/paulk/example.pico", area(5,5,5,6,106,1)), "q">, 
  <area-in-file("/home/paulk/example.pico", area(6,13,6,14,127,1)), "y">, 
  <area-in-file("/home/paulk/example.pico", area(6,17,6,18,131,1)), "x">, 
  <area-in-file("/home/paulk/example.pico", area(10,7,10,8,168,1)), "z">
} 
\end{verbatim}
\end{exam}

The definition of {\tt UNINIT} can be nearly reused as is. The only thing that
remains to be changed is to map the (expression, variable-name) tuples to
(variable-name, variable-occurrence) tuples, for the benefit of the precise
highlighting of the relevant variables.

We define a new type {\tt var} to represent variable occurrences and an
auxiliary set that {\tt VARNAMES} that contains all variable names:

\begin{exam}\begin{verbatim}
type var = loc
set[varname] VARNAMES  = range(DEFS) union range(USES)
\end{verbatim}
\end{exam}
Remains the new definition of {\tt UNINIT}:
\begin{exam}
\begin{verbatim}
rel[var, varname] UNINIT =
   { <V, VN>| var-name VN : VARNAMES, 
              var V : USES[-,VN], 
              expr E : reachX({ROOT}, DEFS[-,VN], PRED),
	      V <= E
   }

\end{verbatim}
\end{exam}
This definition can be understood as follows:
\begin{itemize}
\item {\tt var-name VN : VARNAMES} generates all variable names.
\item {\tt var V : USES[-,VN]} generates all variable uses {\tt V} for variables
  with name {\tt VN}.
\item As before, {\tt expr E : reachX({ROOT}, DEFS[-,VN], PRED)} generates all
  expressions {\tt E} that can be reached from the start of the program
  without encountering a definition for variables named {\tt VN}.
\item {\tt V <= E} tests whether variable use {\tt V} is enclosed in that
  expression (using a comparison on locations).  If so, we have found an
  uninitialized occurrence of the variable named {\tt VN}.
\end{itemize}

In Figure~\ref{FIG:meta-pico} it is shown how checking of Pico programs in the
ASF+SDF Meta-Environment looks like.



\section{McCabe Cyclomatic Complexity}\label{SEC:McCabe}
The \emph{cyclomatic complexity} of a program is defined as $e - n + 2$, where
$e$ and $n$ are the number of edges and nodes in the control flow graph,
respectively.  It was proposed by McCabe~\cite{McCabe76} as a measure of
program complexity.

Experiments have shown that programs with a higher cyclomatic complexity are
more difficult to understand and test and have more errors.  It is generally
accepted that a program, module or procedure with a cyclomatic complexity
larger than 15 is \emph{too complex}.  Essentially, cyclomatic complexity
measures the number of decision points in a program and can be computed by
counting all if statement, case branches in switch statements and the number
of conditional loops.

Given a control flow in the form of a predecessor relation {\tt rel[stat,stat]
PRED} between statements,
the cyclomatic complexity can be computed in an \rscript as follows:
\begin{exam}
\begin{verbatim}
int cyclomatic-complexity(rel[stat,stat] PRED) = 
    #PRED - #carrier(PRED) + 2
\end{verbatim}
\end{exam}

The number of edges $e$ is equal to the number of tuples in {\tt PRED}.
The number of nodes $n$ is equal to the number of elements in the carrier of
{\tt PRED}, i.e., all elements that occur in a tuple in {\tt PRED}.

\section{Dataflow Analysis}\label{SEC:dataflow}

\emph{Dataflow analysis} is a program analysis technique that forms the basis
for many compiler optimizations. It is described in any text book on compiler
construction, e.g. \cite{ASU86}. The goal of dataflow analysis is to determine
the effect of statements on their surroundings. Typical examples are:

\begin{itemize}

\item Dominators (Section~\ref{SEC:dominators}): which nodes in the
flow dominate the execution of other nodes?

\item Reaching definitions (Section~\ref{SEC:reaching}): which
definitions of variables are still valid at each statement?

\item Live variables (Section~\ref{SEC:live}): of which variables will
  the values be used by successors of a statement?

\item Available expressions: an expression is available if it is computed
  along each path from the start of the program to the current statement.

\item and more.
\end{itemize}

\subsection{Dominators} \label{SEC:dominators}

\begin{figure}[tb]
{\small
\begin{verbatim}
rel[stat,stat] dominators(rel[stat,stat] PRED, int ROOT) = 
   DOMINATES
where
    set[int] VERTICES = carrier(PRED)

    rel[int,set[int]] DOMINATES =
    { <V,  VERTICES \ {V, ROOT} \ reachX({ROOT}, {V}, PRED)> |  int V : VERTICES }
endwhere
\end{verbatim} 
\hrulefill}
\caption{\label{FIG:dominators-function}The function {\tt dominators}}
\end{figure}

\begin{figure}[tb]

\hspace*{-2cm} \epsfig{figure=figs/dominators.eps,width=10cm} 
\hspace*{-4cm} \epsfig{figure=figs/dominator-tree.eps,width=10cm}
\vspace*{-4.5cm}

\hrulefill
\caption{\label{FIG:dominators} (a) Flow graph and (b) dominator tree}
\end{figure}

A node $d$ of a flow graph \emph{dominates} a node $n$, if every path from the
initial node of the flow graph to $n$ goes through $d$~\cite[Section
10.4]{ASU86}. Dominators play a role in the analysis of conditional statements
and loops. In Figure~\ref{FIG:dominators-function}, we show the function {\tt
dominators} that computes the dominators for a given flow graph {\tt PRED} and
an entry node {\tt ROOT}.
First, the auxiliary set {\tt VERTICES} (all the statements) is computed. The relation {\tt
  DOMINATES} consists of all pairs {\tt <S, \verb-S-$_1$,...,S$_n$\verb-}->} such that
\begin{itemize}
\item {\tt S$_i$} is not an initial node or equal to {\tt S}.
\item {\tt S$_i$} cannot be reached from the initial node without going through {\tt S}.
\end{itemize}

\noindent Consider the flow graph

\begin{exam}
\begin{verbatim}
rel[int,int] PRED = {
<1,2>, <1,3>,
<2,3>,
<3,4>,
<4,3>,<4,5>, <4,6>,
<5,7>,
<6,7>,
<7,4>,<7,8>,
<8,9>,<8,10>,<8,3>,
<9,1>,
<10,7>
}
\end{verbatim}
\end{exam}
and the result of applying {\tt dominators} to it:

\begin{exam}
\begin{verbatim}
{<1, {2, 3, 4, 5, 6, 7, 8, 9, 10}>, 
<2, {}>, 
<3, {4, 5, 6, 7, 8, 9, 10}>, 
<4, {5, 6, 7, 8, 9, 10}>, 
<5, {}>, 
<6, {}>, 
<7, {8, 9, 10}>, 
<8, {9, 10}>, 
<9, {}>, 
<10, {}>}
\end{verbatim}
\end{exam}

The original flow graph and the resulting \emph{dominator tree} are
shown in Figure~\ref{FIG:dominators}.  The dominator tree has the
initial node as root and each node $d$ in the tree only dominates its
descendants in the tree.



\subsection{Reaching Definitions} \label{SEC:reaching}
\begin{figure}[tb]
\begin{center}
\hspace*{3cm} \epsfig{figure=figs/df-graph.eps,width=10cm}
\vspace*{-6cm}
\end{center}
\hrulefill
\caption{\label{FIG:df-graph} Flow graph for various dataflow problems}
\end{figure}

\begin{figure}[tb]
\begin{center}
\epsfig{figure=figs/reach.eps,width=10cm}
\vspace*{-6cm}
\end{center}
\hrulefill
\caption{\label{FIG:reach} Reaching definitions for flow graph in Figure~\ref{FIG:df-graph}}
\end{figure}

We illustrate the calculation of reaching definitions using the example in
Figure~\ref{FIG:df-graph} which was inspired by \cite[Example 10.15]{ASU86}.

As before, we assume the following basic relations {\tt PRED}, {\tt DEFS} and
{\tt USES} about the program:
\begin{exam}
\begin{verbatim}
type stat = int
type var = str
rel[stat,stat] PRED = { <1,2>, <2,3>, <3,4>, <4,5>, <5,6>, <5,7>, <6,7>, 
                      <7,4>}
rel[stat, var] DEFS = { <1, "i">, <2, "j">, <3, "a">, <4, "i">, 
                       <5, "j">, <6, "a">, <7, "i">}
rel[stat, var] USES = { <1, "m">, <2, "n">, <3, "u1">, <4, "i">, 
                       <5, "j">, <6, "u2">, <7, "u3">}
\end{verbatim}
\end{exam}

For convenience, we introduce a notion {\tt def} that describes
that a certain statement defines some variable and we
revamp the basic relations into a more convenient
format using this new type:
\begin{exam}
\begin{verbatim}
type def  = <stat theStat, var theVar>

rel[stat, def] DEF = {<S, <S, V>> | <stat S, var V> : DEFS}
rel[stat, def] USE = {<S, <S, V>> | <stat S, var V> : USES}
\end{verbatim}
\end{exam}
The new {\tt DEF} relation gets as value:
\begin{exam}
\begin{verbatim}
 {<1, <1, "i">>, <2, <2, "j">>, <3, <3, "a">>, <4, <4, "i">>, 
  <5, <5, "j">>, <6, <6, "a">>, <7, <7, "i">>
\end{verbatim}
\end{exam}
and {\tt USE} gets as value:
\begin{exam}
\begin{verbatim}
{<1, <1, "m">>, <2, <2, "n">>, <3, <3, "u1">>, <4, <4, "i">>, 
 <5, <5, "j">>, <6, <6, "u2">>, <7, <7, "u3">>}
\end{verbatim}
\end{exam}

Now we are ready to define an important new relation {\tt KILL}.
{\tt KILL} defines which variable definitions are undone (killed) at each
 statement and is defined as follows:
\begin{exam}
\begin{verbatim}
rel[stat, def] KILL = 
   {<S1, <S2, V>> | <stat S1, var V> : DEFS, <stat S2, V> : DEFS, S1 != S2}
\end{verbatim}
\end{exam}
In this definition, all variable definitions are compared with each other,
and for each variable definition all \emph{other} definitions of the same variable
are placed in its kill set. In the example, {\tt KILL} gets the value
\begin{exam}
\begin{verbatim}
{<1, <4, "i">>, <1, <7, "i">>, <2, <5, "j">>, <3, <6, "a">>, 
 <4, <1, "i">>, <4, <7, "i">>, <5, <2, "j">>, <6, <3, "a">>, 
 <7, <1, "i">>, <7, <4, "i">>}
\end{verbatim}
\end{exam}
and, for instance, the definition of variable {\tt i} in statement {\tt 1}
kills the definitions of {\tt i} in statements {\tt 4} and {\tt 7}.  Next, we
introduce the collection of statements
\begin{exam}
\begin{verbatim}
set[stat] STATEMENTS = carrier(PRED)
\end{verbatim}
\end{exam}
which gets as value \verb@{1, 2, 3, 4, 5, 6, 7}@ and
two convenience functions to obtain
the predecessor, respectively, the successor of a statement:
\begin{exam}
\begin{verbatim}
set[stat] predecessor(stat S) = PRED[-,S]
set[stat] successor(stat S) = PRED[S,-]
\end{verbatim}
\end{exam}

After these preparations, we are ready to formulate the reaching definitions
problem in terms of two relations {\tt IN} and {\tt OUT}.  {\tt IN} captures
all the variable definitions that are valid at the entry of each statement and
{\tt OUT} captures the definitions that are still valid after execution of
each statement. Intuitively, for each statement {\tt S}, {\tt IN[S]} is equal to
the union of the {\tt OUT} of all the predecessors of {\tt S}.
{\tt OUT[S]}, on the other hand, is equal to the definitions generated by
{\tt S} to which we add {\tt IN[S]} minus the definitions that are killed
in {\tt S}. Mathematically, the following set of equations captures this idea
for each statement:

\[
IN[S] = \bigcup_{P \in predecessor of S} OUT[P] \]
\[ OUT[S] = DEF[S] \cup (IN[S] - KILL[S]) \]

\noindent This idea can be expressed in \rscript quite literally:
\begin{exam}
\begin{verbatim}
equations
  initial
        rel[stat,def] IN init {}
        rel[stat,def] OUT init DEF
  satisfy
        IN  = {<S, D> | stat S : STATEMENTS, 
                        stat P : predecessor(S), 
                        def D : OUT[P]}
        OUT = {<S, D> | stat S : STATEMENTS, 
                        def D : DEF[S] union (IN[S] \ KILL[S])}
end equations
\end{verbatim}
\end{exam}
First, the relations {\tt IN} and {\tt OUT} are declared and initialized. Next, 
two equations are given that very much resemble the ones given above.
For our running example (Figure~\ref{FIG:reach}) the results are as follows.
Relation {\tt IN} has as value:
\begin{exam}
\begin{verbatim}
{<2, <1, "i">>, <3, <2, "j">>, <3, <1, "i">>, <4, <3, "a">>, 
 <4, <2, "j">>, <4, <1, "i">>, <4, <7, "i">>, <4, <5, "j">>, 
 <4, <6, "a">>, <5, <4, "i">>, <5, <3, "a">>, <5, <2, "j">>, 
 <5, <5, "j">>, <5, <6, "a">>, <6, <5, "j">>, <6, <4, "i">>, 
 <6, <3, "a">>, <6, <6, "a">>, <7, <5, "j">>, <7, <4, "i">>, 
 <7, <3, "a">>, <7, <6, "a">>}
\end{verbatim}
\end{exam}
If we consider statement {\tt 3}, then the definitions of {\tt i} and {\tt j}
from the preceding two statements are still valid. A more interesting case
are the definitions that can reach statement {\tt 4}:
\begin{itemize}
\item  The definitions of variables {\tt a}, {\tt j} and {\tt i} from,
  respectively, statements {\tt 3}, {\tt 2} and {\tt 1}.

\item The definition of variable {\tt i} from statement {\tt 7} (via the
  backward control flow path from {\tt 7} to {\tt 4}).

\item The definition of variable {\tt j} from statement{\tt 5} (via the path
  {\tt 5}, {\tt 7}, {\tt 4}).
\item The definition of variable {\tt a} from statement {\tt 6} (via the path
 {\tt 6}, {\tt 7}, {\tt 4}).
\end{itemize}

Relation {\tt OUT} has as value:
\begin{exam}
\begin{verbatim}
{<1, <1, "i">>, <2, <2, "j">>, <2, <1, "i">>, <3, <3, "a">>, 
 <3, <2, "j">>, <3, <1, "i">>, <4, <4, "i">>, <4, <3, "a">>, 
 <4, <2, "j">>, <4, <5, "j">>, <4, <6, "a">>, <5, <5, "j">>, 
 <5, <4, "i">>, <5, <3, "a">>, <5, <6, "a">>, <6, <6, "a">>, 
 <6, <5, "j">>, <6, <4, "i">>, <7, <7, "i">>, <7, <5, "j">>, 
 <7, <3, "a">>, <7, <6, "a">>}
\end{verbatim}
\end{exam}
Observe, again for statement {\tt 4}, that
all definitions of variable  {\tt i} are missing in {\tt OUT[4]} since
they are killed by the definition of {\tt i} in statement {\tt 4} itself. Definitions for
{\tt a} and {\tt j} are, however, contained in {\tt OUT[4]}.
The result of reaching definitions computation is illustrated in
Figure~\ref{FIG:reach}.

In Figure~\ref{FIG:reaching-definitions} the above definitions are used to
formulate the function {\tt reaching-definitions}. It assumes appropriate
definitions for the types {\tt stat} and {\tt var}. It also assumes more
general versions of {\tt predecessor} and {\tt successor}.  We will use it
later on in Section~\ref{SEC:slicing} when defining program slicing.

\begin{figure}[tb]
{\small
\begin{verbatim}
type def  = <stat theStat, var theVar>
type use  = <stat theStat, var theVar>

set[stat] predecessor(rel[stat,stat] P, stat S) = P[-,S]

set[stat] successor(rel[stat,stat] P, stat S) = P[S,-]

rel[stat, def] reaching-definitions(rel[stat,var] DEFS, rel[stat,stat] PRED) = 
   IN
where
    set[stat] STATEMENT = carrier(PRED)

    rel[stat,def] DEF  = {<S,<S,V>> | <stat S, var V> : DEFS}

    rel[stat,def] KILL = 
        {<S1, <S2, V>> | <stat S1, var V> : DEFS, <stat S2, V> : DEFS, S1 != S2}

    equations 
       initial
           rel[stat,def] IN init {}
           rel[stat,def] OUT init DEF
       satisfy
           IN  =  {<S, D> | int S : STATEMENT, 
                            stat P : predecessor(PRED,S), 
                            def D : OUT[P]}
           OUT = {<S, D> |  int S : STATEMENT, 
                            def D : DEF[S] union (IN[S] \ KILL[S])}
    end equations
end where
\end{verbatim}
\hrulefill}
\caption{\label{FIG:reaching-definitions}Reaching definitions}
\end{figure}

\begin{figure}[tb]
\begin{center}
\epsfig{figure=figs/live.eps,width=10cm}
\vspace*{-6cm}
\end{center}
\hrulefill
\caption{\label{FIG:live} Live variables for flow graph in Figure~\ref{FIG:df-graph}}
\end{figure}

\subsection{Live Variables} \label{SEC:live}

The live variables of a statement are those variables whose value will be used
by the current statement or some successor of it. The mathematical formulation
of this problem is as follows:

\[
IN[S] =USE[S] \cup (OUT[S] - DEF[S]) \]
\[ OUT[S] = \bigcup_{S' \in successor of S} IN[S'] \]
The first equation says that a variable is live coming into a statement if
either it is used before redefinition in that statement or it is live coming
out of the statement and is not redefined in it.  The second equation says
that a variable is live coming out of a statement if and only if it is live
coming into one of its successors.
This can be expressed in \rscript as follows:
\begin{exam}
\begin{verbatim}
equations
  initial
        rel[stat,def] LIN init {}
        rel[stat,def] LOUT init DEF
  satisfy
        LIN  =  { < S, D> | stat S : STATEMENTS,  
                            def D : USE[S] union (LOUT[S] \ (DEF[S]))}
        LOUT =  { < S, D> | stat S : STATEMENTS,  
                            stat Succ : successor(S), 
                            def D : LIN[Succ] }
end equations
\end{verbatim}
\end{exam}

\noindent The results of live variable analysis for our running example are
illustrated in Figure~\ref{FIG:live}.

\section{Program Slicing} \label{SEC:slicing}

\begin{figure}[tb]
\begin{center}
{\small
\begin{verbatim}
      [ 1] read(n)           [ 1] read(n)            [ 1] read(n)
      [ 2] i := 1            [ 2] i := 1             [ 2] i := 1
      [ 3] sum := 0          [ 3] sum := 0          
      [ 4] product := 1                              [ 4] product := 1
      [ 5] while i<= n do    [ 5] while i<= n do     [ 5] while i<= n do
           begin                  begin                   begin
      [ 6]   sum := sum + i  [ 6]   sum := sum + i
      [ 7]   product :=                              [ 7]   product := 
               product * i                                    product * i
      [ 8]   i := i + 1      [ 8]  i := i + 1        [ 8]   i := i + 1
           end                    end                     end
      [ 9] write(sum)        [ 9] write(sum)
      [10] write(product)                            [10] write(product)
\end{verbatim}
}
\end{center}

\noindent\hspace{1cm}(a)\hspace{4cm}(b)\hspace{4cm}(c)

\hrulefill

\caption{\label{FIG:slicing}(a) Sample program, 
(b) slice for statement {\tt [9]}, (c) slice for statement {\tt [10]}}
\end{figure}


Program slicing is a technique proposed by Weiser~\cite{Weiser84} for
automatically decomposing programs in parts by analyzing their data
flow and control flow. Typically, a given statement in a program is
selected as the \emph{slicing criterion} and the original program is
reduced to an independent subprogram, called a \emph{slice}, that is
guaranteed to represent faithfully the behavior of the original
program at the slicing criterion.  An example is given in
Figure~\ref{FIG:slicing}.  The initial program is given in
Figure~\ref{FIG:slicing}(a).  The slice with statement {\tt [9]} as
slicing criterion is shown in Figure~\ref{FIG:slicing}(b): statements
{\tt [4]} and {\tt [7]} are irrelevant for computing statement {\tt
[9]} and do not occur in the slice. Similarly, Figure~\ref{FIG:slicing}(c)
shows the slice with statement {\tt [10]} as slicing criterion.
This particular form of slicing is called \emph{backward slicing}.
Slicing can be used for debugging and program understanding,
optimization and more. An overview of slicing techniques and
applications can be found in ~\cite{Tip95}.

Here we will explore a relational formulation of slicing adapted from a proposal
in ~\cite{Jackson&Rollins94}. The basic ingredients of the approach are as
follows:

\begin{itemize}

\item We assume the relations {\tt PRED}, {\tt DEFS} and {\tt USES} as before.

\item We assume an additional set {\tt CONTROL-STATEMENT} that defines which
  statements are control statements.

\item To tie together dataflow and control flow, three auxiliary variables are
  introduced:
  \begin{itemize}

    \item The variable {\tt TEST} represents the outcome of
    a specific test of a conditional statement. The conditional statement
    defines {\tt TEST} and all statements that are control dependent on this
    conditional statement will use {\tt TEST}.

    \item The variable {\tt EXEC} represents the potential execution
    dependence of a statement on some conditional statement.  The dependent
    statement defines {\tt EXEC} and an explicit (control) dependence is made
    between {\tt EXEC} and the corresponding {\tt TEST}.

    \item The variable {\tt CONST} represents an arbitrary constant.	

  \end{itemize}

\end{itemize}

\begin{figure}[tb]
{\small
\begin{verbatim}
set[use] BackwardSlice(
    set[stat] CONTROL-STATEMENT, 
    rel[stat,stat] PRED,
    rel[stat,var] USES,
    rel[stat,var] DEFS,    
    use Criterion) 
= USE-USE[Criterion]

where
    rel[stat, def] REACH = reaching-definitions(DEFS, PRED)

    rel[use,def] use-def = 
       {<<S1,V>, <S2,V>> | <stat S1, var V> : USES, <stat S2, V> : REACH[S1]}

    rel[def,use] def-use-per-stat  = 
       {<<S,V1>, <S,V2>> | <stat S, var V1> : DEFS, <S, var V2> : USES}
             union
       {<<S,V>, <S,"EXEC">> | <stat S, var V> : DEFS}
             union
       {<<S,"TEST">,<S,V>> | stat S : CONTROL-STATEMENT, 
                             <S, var V> : domainR(USES, {S})}

    rel[stat, stat] CONTROL-DOMINATOR = 
       domainR(dominators(PRED), CONTROL-STATEMENT)

    rel[def,use] control-dependence  =
       { <<S2, "EXEC">,<S1,"TEST">> | <stat S1, stat S2> : CONTROL-DOMINATOR}

    rel[use,def] use-control-def = use-def union control-dependence

    rel[use,use] USE-USE = (use-control-def o def-use-per-stat)*

endwhere
\end{verbatim}
\hrulefill}
\caption{\label{FIG:backward-slice}Backward slicing}
\end{figure}


\noindent The calculation of a (backward) slice now proceeds in six steps:

\begin{enumerate}

\item 	Compute the relation {\tt rel[use,def] use-def} that relates all uses
  to their corresponding definitions. The function {\tt reaching-definitions}
  as shown earlier in Figure~\ref{FIG:reaching-definitions} does most of the work.

\item 	Compute the relation {\tt rel[def,use] def-use-per-stat} that relates the ``internal''
  definitions and uses of a statement.

\item 	Compute the relation {\tt rel[def,use] control-dependence} that links
  all {\tt EXEC}s to the corresponding {\tt TEST}s.
 
\item	Compute the relation {\tt rel[use,def] use-control-def} combines
  use/def dependencies with control dependencies.

\item 	After these preparations, compute the relation {\tt rel[use,use]
  USE-USE} that contains dependencies of uses on uses.

\item The backward slice for a given slicing criterion (a use) is now simply
  the projection of {\tt USE-USE} for the slicing criterion.
\end{enumerate}

This informal description of backward slicing is described precisely in
Figure~\ref{FIG:backward-slice}. Let's apply this to the example
in Figure~\ref{FIG:slicing} and assume the following:

\begin{exam}
\begin{verbatim}
rel[stat,stat] PRED = {<1,2>, <2,3>, <3,4>, <4,5>, <5,6>, <5,9>, <6,7>,
                       <7,8>,<8,5>, <8,9>, <9,10>}

rel[stat,var] DEFS  = {<1, "n">, <2, "i">, <3, "sum">, <4,"product">,
                       <6, "sum">, <7, "product">, <8, "i">}

rel[stat,var] USES  = {<5, "i">, <5, "n">, <6, "sum">, <6,"i">,
                       <7, "product">, <7, "i">, <8, "i">, <9, "sum">, 
                       <10, "product">}

set[int] CONTROL-STATEMENT = { 5 }
\end{verbatim}
\end{exam}
The result of the slice
\begin{exam}
\begin{verbatim}
BackwardSlice(CONTROL-STATEMENT, PRED, USES, DEFS, <9, "sum">)
\end{verbatim}
\end{exam}
will then be
\begin{exam}
\begin{verbatim}
 { <1, "EXEC">, <2, "EXEC">,  <3, "EXEC">, <5, "i">, <5, "n">,  
   <6, "sum">, <6, "i">, <6, "EXEC">, <8, "i">, <8, "EXEC">, 
   <9, "sum"> }.
\end{verbatim}
\end{exam}
Take the domain of this result and we get exactly the statements
in Figure~\ref{FIG:slicing}(b).

\chapter{Extracting Facts from Source Code} \label{SEC:ExtractingFacts}
\begin{figure}[tb]
%%\hrulefill
\begin{center}
%% \vspace*{-1cm}
\epsfig{figure=figs/extract-workflow.eps,width=10cm}
\vspace*{-2.5cm}
\end{center}
\hrulefill
\caption{\label{FIG:extract-workflow}Workflow for fact extraction}
\end{figure}


\fbox{\epsfig{figure=figs/spektroskoop.ps,width=8cm}} \label{FIG:spektroskoop}
\hspace*{0.5cm}\parbox[b]{6cm}{
In this tutorial we have, so far, concentrated on querying and enriching facts
that have been extracted from source code. As we have seen from the examples,
once these facts are available, a concise \rscript suffices to do the required
processing. But how is fact extraction achieved and how difficult is it? To
answer these questions we first describe the workflow of the fact extraction
process (Section~\ref{SEC:extraction-wortkflow}) and then we give a more
detailed account of fact extraction using ASF+SDF
(Section~\ref{SEC:ASF+SDF-extraction}).}

\section{Workflow for Fact Extraction} \label{SEC:extraction-wortkflow}

Figure~\ref{FIG:extract-workflow} shows a typical workflow for fact extraction
for a \emph{System Under Investigation} (SUI). It assumes that the SUI uses
only \emph{one} programming language and that you need only one grammar. In
realistic cases, however, several such grammars may be needed. The workflow consists of
three main phases:
\begin{itemize}
\item Grammar: Obtain and improve the grammar for the source language of the SUI.
\item Facts: Obtain and improve facts extracted from the SUI.
\item Queries: Write and improve queries that give the desired answers.
\end{itemize}

Of course, it may happen that you have a lucky day and that extracted facts
are readily available or that you can reuse a good quality fact extractor that
you can apply to the SUI. On ordinary days you have the above workflow as
fall-back.

It may come as a surprise that there is such a strong emphasis on validation
in this workflow. The reason is that the SUI is usually a huge system that
defeats manual inspection. Therefore we must be very careful that we validate
the outcome of each phase.

\paragraph{Grammar}
In many cases there is no canned grammar available that can be used to parse
  the programming language dialect used in the SUI. Usually an existing
  grammar can be adjusted to that dialect, but then it is then mandatory to
  validate that the adjusted grammar can be used to parse the sources of the
  SUI.

\paragraph{Facts}
  It may happen that the facts extracted from the source code are
  \emph{wrong}. Typical error classes are:
  \begin{itemize}
  \item Extracted facts are \emph{wrong\/}: the extracted facts incorrectly state that procedure {\tt P} calls
  procedure {\tt Q} but this is contradicted by a source code inspection.
  \item Extracted facts are \emph{incomplete\/}: the inheritance between certain classes
  in Java code is missing.
  \end{itemize}
  The strategy to validate extracted facts differ per case but here are three
  strategies:
  \begin{itemize}
  \item Postprocess the extracted facts (using \rscript, of course) to obtain
  trivial facts about the source code such as total lines of source code and
  number of procedures, classes, interfaces and the like. Next validate these
  trivial facts with tools
  like {\tt wc} (word and line count), {\tt grep} (regular expression
  matching) and others.

  \item Do a manual fact extraction on a small subset of the code and compare
  this with the automatically extracted facts.

  \item Use another tool on the same source and compare results whenever
  possible. A typical example is a comparison of a call relation extracted
  with different tools.

  \end{itemize}

\paragraph{Queries} For the validation of the answers to the queries essentially the same
  approach can be used as for validating the facts. Manual checking of answers
  on random samples of the SUI may be mandatory. It also happens frequently
  that answers inspire new queries that lead to new answers, and so on.


\section{Fact Extraction using ASF+SDF} \label{SEC:ASF+SDF-extraction}

\begin{figure}[tb]
%%\hrulefill
\begin{center}
%%\vspace*{-1cm}
\epsfig{figure=figs/extract-meta.eps,width=10cm}
\vspace*{-5cm}
\end{center}
\hrulefill
\caption{\label{FIG:extract-meta}The \emph{Separation-of-Concerns\/} strategy
  for  fact extraction}
\end{figure}

\subsection{Strategies for Fact Extraction}
The following global scenario's are available when writing a fact extractor in ASF+SDF:
\begin{itemize}
\item \emph{Dump-and-Merge\/:} Parse each source file, extract the relevant facts, and
  return the resulting (partial) Rstore. In a separate phase, merge all the
  partial Rstores into a complete Rstore for the whole SUI. The tool {\tt
  merge-rstores} is available for this.
\item \emph{Extract-and-Update\/}: Parse each source file, extract the
  relevant facts, and add these directly to the partial Rstore that has been
  constructed for previous source files.
\end{itemize}
The experience is that the \emph{Extract-and-Update} is more efficient.

A second consideration is the scenario used for the fact extraction per
file. Here there are again two possibilities:
\begin{itemize}
\item \emph{All-in-One\/}: Write one function that extracts all facts in one
  traversal of the source file. Typically, this function has an Rstore as
  argument and returns an Rstore as well. During the visit of specific
  language constructs additions are made to named sets or relations in the
  Rstore.
\item \emph{Separation-of-Concerns\/}: Write a separate function for each fact
  you want to extract. Typically, each function takes a set or relation as
  argument and returns an updated version of it. At the top level all these
  functions are called and their results are put into an Rstore.
  This strategy is illustrated in Figure~\ref{FIG:extract-meta}
\end{itemize}
The experience here is that everybody starts with the \emph{All-in-One}
strategy but that the complexities of the interactions between the various
fact extraction concerns soon start to hurt. The advice is therefore to use
the \emph{Separation-of-Concerns\/} strategy even if it may be seem to be less
efficient since it requires a traversal of the source program for each
extracted set or relation.

\subsection{Extracting Facts for Pico}


\begin{figure}[tb]
{\small
\begin{verbatim}
module PicoFactExtraction
imports Pico-syntax
imports basic/Integers
imports Rstore
imports utilities/PosInfo[PROGRAM] utilities/PosInfo[STATEMENT]
        utilities/PosInfo[EXP] utilities/PosInfo[PICO-ID]
exports
  context-free syntax
    cflow({ STATEMENT ";"}*)     -> <Set[[Elem]], Rel[[Elem]], Set[[Elem]]>

    uses(PROGRAM, Rel[[Elem]])   -> Rel[[Elem]] {traversal(accu,top-down,continue)}
    uses(EXP, Rel[[Elem]])       -> Rel[[Elem]] {traversal(accu,top-down,continue)}

    defs(PROGRAM, Rel[[Elem]])   -> Rel[[Elem]] {traversal(accu,top-down,break)}
    defs(STATEMENT, Rel[[Elem]]) -> Rel[[Elem]] {traversal(accu,top-down,break)}

    id2str(PICO-ID)              -> String
\end{verbatim}
}
\hrulefill
\caption{\label{FIG:PicoFactExtraction.sdf}Syntax of functions for Pico fact extraction}
\end{figure}

After all these mental preparations, we are now ready to delve into the details
of a Pico fact extractor. Figure~\ref{FIG:PicoFactExtraction.sdf} shows the
syntax of the functions that we will need for Pico fact extraction. There are
some things to observe:
\begin{itemize}
\item Module {\tt Pico-syntax} is imported to make available the Pico
  grammar.
\item Module {\tt Rstore} is imported to get access to all functions on
  Rstores.
\item The module {\tt PosInfo} is imported with various sort names as
  parameter. For all these sorts, the function {\tt get-location} will be
  defined that extracts the source text location from a given language
  construct.
\item The function {\tt cflow} will extract the control flow from Pico
  programs.
\item The functions {\tt uses} and {\tt defs} extracts the uses and
  definitions of variables from the source text.
\item {\tt id2str} is an auxiliary function that converts Pico identifiers to
  strings that can be included in an Rstore.
\item We have omitted all declarations for ASF+SDF variables to be used in the
  specification. The convention is that such variables all start with a dollar
  sign ({\tt \$}).
\end{itemize}

\begin{figure}[tb]
{\small 
\begin{verbatim}
%% ---- control flow of statement lists
[cf1] <$Entry1, $Rel1, $Exit1> := cflow($Stat),
      <$Entry2, $Rel2, $Exit2> := cflow($Stat+)
       ==========================================================
       cflow($Stat ; $Stat+) =
       < $Entry1,
         $Rel1 union $Rel2 union ($Exit1 x $Entry2),
         $Exit2
       >
[cf2] cflow() = <{}, {}, {}>

%% ---- control flow of individual statements
[cf3]  <$Entry, $Rel, $Exit> := cflow($Stat*),
       $Control := get-location($Exp)
       =========================================================
       cflow(while $Exp do $Stat* od) =
       < {$Control},
         ({$Control} x $Entry) union $Rel union ($Exit x {$Control}),
         {$Control}
       >

[cf4]  <$Entry1, $Rel1, $Exit1> := cflow($Stat*1),
       <$Entry2, $Rel2, $Exit2> := cflow($Stat*2),
       $Control := get-location($Exp)
       =========================================================
       cflow(if $Exp then $Stat*1 else $Stat*2 fi) =
       < {$Control},
         ({$Control} x $Entry1) union ({$Control} x $Entry2) 
                                union  $Rel1 union $Rel2,
         $Exit1 union $Exit2
       >
[default-cf]
        $Loc := get-location($Stat)
       =========================================================
        cflow($Stat) = < {$Loc}, {}, {$Loc} >
\end{verbatim}
}
\hrulefill
\caption{\label{FIG:PicoFactExtraction-cflow}Equations for {\tt cflow}: computing control flow}
\end{figure}

\begin{figure}[tb]
{\small
\begin{verbatim}

%% ---- Variable definitions: <expression-location, var-name>

[vd1]  $Id := $Exp := $Stat
       ==========================================================
       defs($Stat, $Rel) = $Rel union {<get-location($Stat), id2str($Id)>}

%% ---- Variable uses <var-location, var-name>

[vu1]  $Id := $Exp
       ==========================================================
       uses($Exp, $Rel) = $Rel union  {<get-location($Id), id2str($Id)>}

%% ----- utilities

[i2s] id2str(pico-id($Char*)) = strcon(""" $Char* """)

\end{verbatim}
}
\hrulefill
\caption{\label{FIG:PicoFactExtraction-defs-uses}Equations for {\tt defs}, {\tt uses} and
  {\tt id2str}}
\end{figure}


\begin{figure}[tb]
{\small
\begin{verbatim}
module PicoQuery
imports RscriptCalculator
imports PicoFactExtraction
imports basic/Errors

exports
  start-symbols Summary
  context-free syntax
     extractRelations(PROGRAM)                   -> RSTORE
     pico-query(RSCRIPT, RSTORE, StrCon, StrCon) -> Summary
     uninit(PROGRAM)                             -> Summary
\end{verbatim}
}
\hrulefill
\caption{\label{FIG:PicoQuery.sdf}Syntax of function for two styles of querying}
\end{figure}

\begin{figure}[tb]
{\small
\begin{verbatim}
%% ---- extractRelations

[er-1] begin $Decls $Stat+ end := $Program,
       $Start := get-location($Program),
       <$Entry, $Rel, $Exit> := cflow($Stat+),

       $Loc :=  get-location($Program),
       $Rstore1 := assign(ROOT, expr, $Loc, rstore()),
       $Rstore2 := assign(PRED, rel[expr,expr],
                                $Rel union ({$Start} x $Entry), $Rstore1),
       $Rstore3 := assign(DEFS, rel[expr,varname], defs($Program, {}), $Rstore2),
       $Rstore4 := assign(USES, rel[var,varname], uses($Program, {}), $Rstore3)
       ==========================================================================
       extractRelations($Program) = $Rstore4

%% ---- pico-query

[pq1]  pico-query($Script, $Rstore, $StrCon1, $StrCon2) =
       convert2summary(
          $StrCon2,
          eval-rscript-with-rstore-and-yield($Script, $Rstore, $StrCon1)
       )
\end{verbatim}
}
\hrulefill
\caption{\label{FIG:PicoFactExtraction-extractRelations}Build an Rstore with
  {\tt extractRelations} and apply it using {\tt pico-query}}
\end{figure}

\begin{figure}[tb]
{\small
\begin{verbatim}
[ui-1] begin $Decls $Stat+ end := $Program,
       $Start := get-location($Program),
       <$Entry, $Rel, $Exit> := cflow($Stat+),
       $Rel1 := $Rel union ({$Start} x $Entry),
       $Rval := [| type expr = loc
                   type var  = loc
                   type varname = str

                   expr ROOT = $Start

                   rel[expr,expr] PRED = $Rel1
                   rel[expr,varname] DEFS  = defs($Program, {})
                   rel[var,varname] USES  = uses($Program, {})
                   set[varname] VARNAMES  = range(DEFS) union range(USES)

                   rel[var, varname] UNINIT =
                   { <V, VN>| var-name VN : VARNAMES,
                              var V : USES[-,VN],
                              expr E : reachX({ROOT}, DEFS[-,VN], PRED),
                              V <= E
                   }

                |] yield UNINIT
       ===================================================================
       uninit($Program) = convert2summary("Uninitialized variable", $Rval)            
\end{verbatim}
}
\hrulefill
\caption{\label{FIG:PicoFactExtraction-uninit}Combined fact extraction and
  query processing}
\end{figure}

\paragraph{Extracting control flow}
The function {\tt cflow} extracts the control flow from Pico programs. It
takes a list of statements as input and returns a triple as output:
\begin{itemize}
\item A set of program elements that may enter a construct.
\item A relation between the entries and exits of a construct.
\item A set of program elements that form the exits from the construct.
\end{itemize}
For instance, the test in an if-then-else statement forms the entry of the
statement, it is connected to the entry of the first statement of the then and
the else branch. The exits of the if-then-else statement are the exits of the
last statement in the then and the else branch. The purpose of {\tt cflow} is
to determine this information for individual statements and to combine this
information for compound statements. Its definition is shown in
Figure~\ref{FIG:PicoFactExtraction-cflow}.

\paragraph{Extracting uses and defs}
The functions {\tt defs} and {\tt uses} are shown in
Figure~\ref{FIG:PicoFactExtraction-defs-uses}.  They extract the definition,
respectively, the use of variables from the source code. Both functions are
defined by means of an ASF+SDF \emph{traversal function} which silently visits
all constructs in a tree, and only performs an action for the constructs for
which the specification contains an equation. In the case of {\tt defs},
equation {\tt [vd1]} operations on assignment statements and extracts a pair
that relates the location of the complete statement to the name of the
variable on the left-hand side. For the function {\tt uses}, equation {\tt
[vu1]} acts on all uses of variables. For completeness sake, the figure also
show the definition of utility function {\tt id2str}.

\paragraph{Queries}
Figure~\ref{FIG:PicoQuery.sdf} shows the syntax of the functions we will use
for querying. In fact, we will demonstrate two styles of definition.  In the
first style, the function {\tt extractRelation} extracts facts from a Pico
program and yields an Rstore. This can be used by {\tt pico-query} to run an
arbitrary \rscript on that Rstore. In the second style, fact extraction and
running an \rscript are done in a single function.

Figure~\ref{FIG:PicoFactExtraction-extractRelations} shows the first
definition style. In equation {\tt [er1]}, we see a step-by-step construction
of an Rstore that contains all the information gathered by the extraction
functions. An Rstore that contains all this information is returned as result
of {\tt extractRelations}. The function {\tt pico-query} can then be used to
run an \rscript for a given Rstore.

The second definition style is shown in
Figure~\ref{FIG:PicoFactExtraction-uninit}.  In this case, we see that all
work is done in a single (indeed large) equation. The construct {\tt [| ... |]
yield UNINIT} is particularly noteworthy since it allows the embedding of a
complete \rscript in an ASF+SDF equation. Also pay attention to the following:

\begin{itemize}

\item The \rscript is first simplified as much as possible according to
  ordinary ASF+SDF simplification rules. This implies that variables like {\tt
  \$Start}, {\tt \$Rel1}, and {\tt \$Program} are replaced by their respective
  values. This is also the case for the functions {\tt defs} and {\tt uses}
  that occur in the \rscript.

\item The  effect of the {\tt [| ... |] yield UNINIT} construct is that the
  \rscript is evaluated and that the value of {\tt UNINIT} is returned as
  result.

\item The definition of the function {\tt convert2summary} is not shown: it
  performs a straightforward conversion of {\tt UNINIT}'s value to the message
  format ({\tt Summary}) that is used by the Meta-Environment.

\end{itemize}

\section{Concluding Remarks}
As can already be seen from the very simple Pico example, over 100 lines of
ASF+SDF specification (including variable declarations and auxiliary functions
we did not show) are needed to extract facts, while only 10 lines of \rscript
are sufficient for the further processing of these facts. What can we learn
from this observation?

First, that even in the simple case of Pico fact extraction is more
complicated than the processing of these facts. This may be due to the following:
\begin{itemize}
\item The facts we are interested in may be scattered over different language
  constructs.  This implies that the fact extractor has to cover all these
  cases.
\item The extracted facts are completely optimized for relational processing
  but places a burden on the fact extractor to perform this optimization.

\end{itemize}

Second, that several research question remain unanswered:

\begin{itemize}

\item Is it possible to solve (parts of) the fact extraction in a
  language-parametric way. In other words, is it possible to define generic
  extraction methods that apply to multiple languages?

\item Is a further integration of fact extraction with relational processing
  desirable? We have already shown some form of integration in
  Figure~\ref{FIG:PicoFactExtraction-uninit} where an embedded \rscript occurs
  in an ASF+SDF specification. Is it, for instance, useful to bring some of
  the syntactic program domains like expressions and statements to the
  relational domain?

\end{itemize}


\chapter{Installing and Running \rscript} \label{SEC:running-rscript}

\begin{figure}[h]
\begin{center}
\epsfig{figure=figs/ruhmkorff.ps,width=15cm} \label{FIG:ruhmkorff}
\end{center}
\end{figure}

\section{Installing \rscript}
\rscript is available\footnote{\url{www.cwi.nl/projects/MetaEnv/...}}
as \texttt{relation-calculus-0.4.tar.gz} (or a newer version).  It
requires a recent version (e.g. at least 1.5.3) of the ASF+SDF
Meta-Environment to run.  A typical installation session on a typical
Unix/Linux system consists of the following steps:

\begin{itemize}

\item Extract all files from the distribution:
  \texttt{tar zxvf relation-calculus-0.4.tar.gz}
This command uncompresses the distribution file, creates a subdirectory
\texttt{relation-calculus-0.4} and places all directories and files
from the distribution in it.

\item Change to the new directory:
  \texttt{cd relation-calculus-0.4}
\item Configure the sources: \texttt{./configure}

\item Build and install application: \texttt{make install}

\end{itemize}

See the files \texttt{INSTALL} and \texttt{README} for more specific
installation instructions.


\section{Running \rscript from the command line} \label{SEC:running-commandline}

\subsection{File extensions}
The following file extensions are used by the command line tools:

\begin{itemize}

\item \texttt{.rscript} is the required file name extension for files that contain an \rscript.

\item \texttt{.rstore} is the required file name extension for files
that contain an rstore.  As intermediate result rstores also occur in
parsed form and then have the extension \texttt{.rstore.pt}. The tools
transparently accept rstores in both forms.

\item \texttt{.rviz} is the required file name extension for files that
contain relational data that are to be visualized (see
Chapter~\ref{SEC:Visualization}).

\end{itemize}

\subsection{\texttt{rscript}: check and execute an rscript}
The command \texttt{rscript} takes care of parsing, typechecking, and
executing an \rscript. Optionally, the script can only be checked, can
use a given rstore, be executed as test suite, or yield the value of a
given variable from the resulting rstore.

\begin{itemize}

\item \texttt{-c} or \texttt{--check-only}:
Only check the rscript for syntactic errors or typechecking errors
but do not execute it.

\item \texttt{-h} or \texttt{--help}; print help information.

\item \texttt{-i} \emph{name} or \texttt{--input} \emph{name}:
The \rscript to be processed is on file \emph{name}.
By default, the script is assumed to be on standard input.

\item \texttt{-o} \emph{name} or \texttt{--output-parse-tree} \emph{name}:
The result of the execution of the \rscript is an rstore and is written to file \emph{name}.
Note that this rstore is in the form of a parse tree.
By default, the resulting rstore is printed in textual form to standard output.

\item \texttt{-s} \emph{name} or \texttt{--store} \emph{name}:
The \rscript is executed using an initial rstore taken from file \emph{name}.
By default, the initial rstore is empty.


\item \texttt{-t} or \texttt{--testsuite}:
Execute the \rscript as a testsuite, i.e., execute all \texttt{assert} statements and report
which ones failed.

\item \texttt{-v} or \texttt{--verbose}: give verbose output.

\item \texttt{-y} \emph{name} or \texttt{--yield} \emph{name}:
Instead of producing a complete rstore as the result of executing the rscript,
only return the value of the variable \emph{name}.r
\end{itemize}

The following examples illustrate the use of the \texttt{rscript} command:

\begin{itemize}

\item  \texttt{rscript query.rscript} executes the script \texttt{query.rscript}
and prints the resulting rstore on standard output.

\item \texttt{rscript -i query.rscript -s previous.rstore -o result.rstore.pt}:
executes the same script, but uses \texttt{previous.rstore} as initial rstore
and writes the resulting store to \texttt{result.rstore.pt}>

\item \texttt{rscript -y nCalls calls.rscript}:
executes the script \texttt{calls.rscript} and prints the value of the variable \texttt{nCalls}
in the resulting rstore.

\item \texttt{rscript -t tests1.rscript}:
executes \texttt{tests2.rscript} as test suite and reports which assert
statements failed (if any).
\end{itemize}

\subsection{\texttt{extract-relations}: extract relations from source files} \label{SEC:extract-relations}

The command \texttt{extract-relations} provides a common framework for
\asfsdf-based fact extraction and has the following form:

\begin{exam}
\texttt{extract-relations [options] <input-files>}
\end{exam}

\noindent The following optional arguments are supported:

\begin{itemize}

\item \texttt{-h} or \texttt{--help}; print help information.

\item \texttt{-o} \emph{file} or \texttt{--output} \emph{file}: the name of
  the resulting rstore 
(default: \texttt{result.rstore.pt}).

\item \texttt{-e} \emph{program} or \texttt{--executable} \emph{program}: the
executable \emph{program} for performing extraction (default: none). This is most
likely to be a compiled \asfsdf specification.

\item \texttt{-s} \emph{sort} or \texttt{--sort} \emph{sort}:
\emph{sort} is the sort used for parsing each input file (default:
none). In other words, each input file should conform to the syntax of \emph{sort}.
Example: \texttt{CompilationUnit}.

\item \texttt{-f} \emph{name} or \texttt{--function} \emph{name}: the extraction function to be applied 
to each source file (default: \texttt{extractRelations}). The definition of
this function should conform to:
\begin{exam}
\texttt{extractRelations(}\emph{sort}\texttt{) -> RSTORE}
\end{exam}
where \emph{sort} is the sort of each input file as defined above.

\item \texttt{-p} \emph{file} or \texttt{--parse-table} \emph{file}: the parse table \emph{file} used for parsing input files (default: none).

\end{itemize}

\noindent The following examples illustrate the use of the \texttt{extract-relations} command:

\begin{itemize}

\item \texttt{extract-relations -e JavaAnalysis -s CompilationUnit -o
  jhotdraw.rstore.pt -p Java.trm.tbl dir/*.java}: extract relations from Java source
  code in the files \texttt{dir/*.java}. Use executable \texttt{JavaAnalysis}, each input file is of sort
  \texttt{CompilationUnit}, use parse table  \texttt{Java.trm.tbl}, and
  produce as output an rstore \texttt{jhotdraw.rstore.pt}.

\item
  \texttt{extract-relations -e TBExtr -s Tscript -p Tscript.trm.tbl *.tb}:
  extract relations from \TB source files. Use executable \texttt{TBExtr}, each input file is of
  sort \texttt{Tscript}, use parse table \texttt{Tscript.trm.tbl} and extract
  from the source files \texttt{*.tb}.

\end{itemize}


\subsection{\texttt{merge-rstores}: combine several rstores}

The command \texttt{merge-rstores} merges several rstores into a new
rstore.  This command is used in a scenario where an extraction tool
extracts facts from each source file in a software portfolio to be
analyzed and deposits these facts in a separate rstore per source
file.  When the complete portfolio is to be analyzed, the separate
rstores have to be merged into a single one. This merged rstore is then
used as initial rstore for the execution of some rscript.

The command has as arguments, a list of names of rstores to be merged.

The following optional arguments are supported:

\begin{itemize}
\item \texttt{-h} or \texttt{--help}: print help information.

\item \texttt{-o} \emph{name} or \texttt{--output} \emph{name}:
the name of the merged rstore is \emph{name}.
By default, the output is \texttt{result.rstore.pt}.
\note{tool should check for right output form}

\item \texttt{-v} or \texttt{--verbose}: give verbose output.

\end{itemize}

\section{Running \rscript Interactively} \label{SEC:running-interactive}
You can also edit and run Rscripts interactively:
\begin{itemize}
\item Change directory to your checked out copy of the directory {\tt relation-calculus/spec}.
\item Start the ASF+SDF Meta-Environment with the command {\tt meta}.
\item Open the module {\tt Rscript.sdf}.
\item Open your own term, using the {\tt Rscript} module.
\item Observe that a new menu with the name {\tt Rscript} appears in the menu bar.
\item Click the parse button in the {\tt Actions} menu of the editor:
now we know whether there are syntax errors. If so, correct them.

\item Click the {\tt Check} button in the {\tt Rscript} menu: this will
  perform a type check of your script. If there are type errors, correct them.

\item Click the {\tt Run} button in the {\tt Rscript} menu to execute your script: a new
editor pops up which shows all the variables at the end of the execution.
{\tt Run} also performs a type of your script so you may skip the previous step.

\item Click the {\tt Run with Rstore} button if you want to execute your
  \rscript with an existing ``Rstore'': a collection of relations that are the
  result of previous extraction phase. Currently, a fixed name is used for
  this Rstore: {\tt RSTORE.rstore}.

\end{itemize}

\paragraph{Running a Test suite} \label{running}
Same as above but use {\tt Testsuite} button instead of the {\tt Execute}
button in the {\tt Rscript} menu.  The effect is that the script is executed
and that a summary is printed of {\tt assert} statement that succeeded or
failed.

\section{Other Tools and Demos}

\subsection{Examples}

The subdirectory {\tt rscripts} contains several sample scripts.  See, for instance, {\tt
tests1.rscript} and {\tt tests2.rscript} for examples of the use of built-in
operators and functions.

\subsection{The Pico Demo}

The subdirectory {\tt demo/pico} contains in a single directory the
Pico syntax, Pico fact extraction (discussed in
Section~\ref{SEC:ASF+SDF-extraction}) and the test on uninitialized
variables presented in Section~\ref{SEC:uninit}.

\begin{itemize}

\item Change directory to \texttt{demo/pico}: \texttt{cd demo/pico}.

\item Start the \asfsdf Meta-Environment: \texttt{meta -m Pico-syntax.sdf}.

\item Open the term \texttt{exam.pico} over module \texttt{Pico-syntax.sdf}.

\item Under the \texttt{Pico} menu two styles of checking are available:
  \begin{itemize}
  \item Extract Relations: this extracts relations from the current Pico program.
  \item Uninitialized Vars (Style 1): uses the extracted facts and
  executes the \rscript \texttt{uninit.rscript}, see
  Figure~\ref{FIG:PicoFactExtraction-extractRelations}.
  \item Uninitialized Vars (Style 2): performs combined facts extraction and 
   query processing, see Figure~\ref{FIG:PicoFactExtraction-uninit}.
  \end{itemize}
  See Figure~\ref{FIG:meta-pico} for a screen dump.

\end{itemize}

\subsection{The Java Demo}

The Java demo consists of the following parts:

\begin{itemize}

\item \texttt{java/grammar}: Contains a SDF grammar for Java.

\item 
\begin{sloppypar}
\texttt{java/extraction}: defines \texttt{JavaAnalysis}, that
performs basic fact extraction from Java source code. It also defines the
command \texttt{extract-java}, a specialized version of
\texttt{extract-relations} (see Section~\ref{SEC:extract-relations}):
\end{sloppypar}

\item \texttt{java/rscripts}: defines a script \texttt{Enrich.rscript} enrich
  the facts extracted by JavaAnalysis. It also defines some sample scripts
that operate on the enriched rstores.

\item \texttt{java/example-hotdraw}: gives data for the JhotDraw example.

\end{itemize}

The command \texttt{extract-java} provides a common framework for
\asfsdf-based fact extraction from Java programs and has the following form:

\begin{exam}
\texttt{extract-java [options]}
\end{exam}

\noindent The following optional arguments are supported:

\begin{itemize}

\item \texttt{-h} or \texttt{--help}; print help information.

\item \texttt{-i} \emph{dir} or \texttt{--input} \emph{dir}: the name a
  directory \emph{dir} that contains the Java source code. All Java source
  files appearing in (subdirectories of) \emph{dir} will be used as input.
  (default: current directory).

\item \texttt{-o} \emph{file} or \texttt{--output} \emph{file}: the name of
  the resulting rstore 
(default: \texttt{result.rstore.pt}).

\item \texttt{-e} \emph{program} or \texttt{--executable} \emph{program}: the
executable \emph{program} for performing extraction (default: \texttt{JavaAnalysis}). This is most
likely to be a compiled \asfsdf specification.

\item \texttt{-f} \emph{name} or \texttt{--function} \emph{name}: the extraction function to be applied 
to each source file (default: \texttt{extractRelations}). The definition of
this function should conform to:
\begin{exam}
\texttt{extractRelations(CompilationUnit) -> RSTORE}
\end{exam}

\end{itemize}

\noindent The following examples illustrate the use of the
\texttt{extract-relations} command:
\begin{exam}
\texttt{extract-java -i JHotDraw5.2-sources -o jhotdraw.rstore.pt}
\end{exam}

Here is a scenario to go all the way from Java source code to the
visualization of the extracted and enriched facts:
{\footnotesize
\begin{verbatim}
cd example-hotdraw
extract-java -i /ufs/paulk/software/source/JHotDraw -o jhotdraw.rstore.pt
rscript -i ../rscripts/Enrich.rscript -s jhotdraw.rstore.pt -o enr.jhotdraw.rstore.pt
rscript -i validate.rscript -s enr.jhotdraw.rstore.pt
rstore2rviz -i enr.jhotdraw.rstore.pt -o jhotdraw.rviz
rviz jhotdraw.rviz
\end{verbatim}
}

\noindent In the next chapter, we will further explain this scenario.

\chapter{Visualization of Rstores} \label{SEC:Visualization}

\fbox{\epsfig{figure=figs/camera-obscura.ps,width=8cm}} \label{FIG:camera-obscura}
\hspace*{0.5cm}\parbox[b]{6cm}{ The sets and relations constructed for all but
the most trivial problems are voluminous and their textual representation is
hard to grasp for the human eye. This is where information visualization
techniques (**) come to our rescue.  In this chapter we present some initial
experiments to visualize the contents of an Rstore. This is a multi-stage
process described in Section~\ref{SEC:visualize-workflow}.
First facts are extracted from the source
(Section~\ref{SEC:ExtractingFactsAgain})
and are further enriched (Section~\ref{SEC:EnrichingFacts}).
Next the Rstore is converted to the \texttt{.rviz} format that is more
amenable as input for a visualization tool. This format is described in
Section~\ref{SEC:rvizformat} and the conversion from Rstore to this format is
discussed in Section~\ref{SEC:rstore2rviz}. Next, the \texttt{.rviz} file can
be visualized and explored. This is the topic of Section~\ref{SEC:rviz} }

\begin{figure}[tb]
\begin{center}
\epsfig{figure=figs/visualize-workflow.eps,width=10cm}
\vspace*{-0cm}
\end{center}
\hrulefill
\caption{\label{FIG:visualize-workflow}Workflow for visualization of System Under Investigation}
\end{figure}

\begin{figure}[tb]
\begin{center}
\epsfig{figure=figs/rviz1.ps,width=15cm}
\end{center}
\hrulefill
\caption{\label{FIG:rviz1}File view}
\end{figure}

\begin{figure}[tb]
\begin{center}
\epsfig{figure=figs/rviz2.ps,width=15cm}
\end{center}
\hrulefill
\caption{\label{FIG:rviz2}Tree map view}
\end{figure}


\section{The visualization workflow} \label{SEC:visualize-workflow}

The process of achieving a visualization of a System under Investigation (SUI) is shown in
Figure~\ref{FIG:visualize-workflow} and consists of the following steps:
\begin{itemize}
\item Extract facts from a source code directory \texttt{SUISrcDir} and
  produce an Rstore \texttt{SUI.rstore.pt}.
\item \begin{sloppypar} Enrich this Rstore by running an rscript \texttt{enr.rscript} on it,
  with resulting enriched Rstore \texttt{enr.rstore.pt}. \end{sloppypar}
\item Convert the enriched Rstore to the the visualization format
  \texttt{.rviz}.
\item Run the visualization tool \texttt{rviz} on these data.
\end{itemize}
\noindent The details of this process are now further explained.

\section{Extracting Facts} \label{SEC:ExtractingFactsAgain}
In Chapter~\ref{SEC:ExtractingFacts} we have already seen how fact extraction can
be organized and implemented. For the current presentation it is sufficient to
assume that there exists an \texttt{extract} tool that can be used:
\begin{exam}
\texttt{extract -i SUISrcDir -o SUI.rstore.pt}
\end{exam}
where \texttt{SUISrcDir} is the source directory where the source of the SUI
can be found. In the distribution a tool \texttt{extract-java} is available with precisely
this behavior for Java programs.

\section{Enriching Facts} \label{SEC:EnrichingFacts}
Given the Rstore  \texttt{SUI.rstore.pt} we enrich it by writing and executing
an \rscript
\texttt{enr.rscript} that extends the extracted facts as required by the goal
we want to achieve:
\begin{exam}
\texttt{rscript enr.rscript -s SUI.rstore.pt -o enr.SUI.rstore.pt}
\end{exam}

\section{The \texttt{.rviz} Format} \label{SEC:rvizformat}

Before explaining the conversion to the rviz format, it is helpful to
understand this format first.
Only two forms of data definitions can currently appear in an rviz file.
\emph{Elements} are values that can occur in relations and are defined by the
keyword \texttt{elm}.  \emph{Tuples} are defined by the keyword
\texttt{tup}. The definition of an \emph{element} has the following form:

\begin{exam}
\texttt{elm} \emph{Type} \emph{Name} \emph{File} \emph{BeginLine} \emph{BeginCol} \emph{EndLine} \emph{EndCol}
\end{exam}

\noindent \emph{Type} is the type as declared in the \rscript, \emph{Name} is
the textual name of the element, and the subsequent file and location
information characterize the precise coordinates of the element in the source
text. An example of an element definition is:

\begin{exam}
\texttt{elm "ClassName" "PolyLineFigure" ".../PolyLineFigure.java" 21 0 339 1}
\end{exam}

The definition of a \emph{tuple} has the following form:
\begin{exam}
\texttt{tup} \emph{RelName} \emph{Type1} \emph{Value1} \emph{Type2} \emph{Value2}
\end{exam}
\noindent \emph{RelName} is the name of the relation to which the tuple belongs.
It is followed two type/value pairs that define the two items in the tuple.
An example of a tuple definition is:

\begin{exam}
\texttt{tup IMPLEMENTS "ClassName" "AbstractHandle" "InterfaceName" "Handle"}
\end{exam}

\paragraph{Discussion} Observe that the current visualization format is very simple and does not 
allow the representation of all data that may be present in an Rstore. In particular, sets and
$n$-ary relations ($n > 2$) are not represented. Clearly, this format will further evolve.

\section{\texttt{rstore2rviz}: Convert Rstore to Visualization Format} \label{SEC:rstore2rviz}
The command \texttt{rstore2rviz} takes an rstore as input and converts it
to the \texttt{.rviz} format that is accepted by the visualization tool \texttt{rviz}.

\begin{itemize}

\item \texttt{-h} or \texttt{--help}: print help information.

\item \texttt{-i} \emph{name} or \texttt{--input} \emph{name}:
rstore comes from file \emph{name}. By default: standard input.

\item \texttt{-o} \emph{name} or \texttt{--output} \emph{name}:
the result is written to file \emph{name}. By default, this is
a file named \texttt{result.rviz}.

\item \texttt{-v} or \texttt{--verbose}: give verbose output.

\end{itemize}
Example:
   \texttt{rstore2rviz -i enr.SUI.rstore.pt -o SUI.rviz}

\section{\texttt{rviz}: Visualize an Rstore} \label{SEC:rviz}


Visualization is simply started by the command \texttt{rviz} with the
given visualization data as input, as in:

\begin{exam}
\texttt{rviz SUI.rviz}
\end{exam}

\noindent The result is a window as shown in Figure~\ref{FIG:rviz1} which
consists of several panes.  On the left-hand side three panes occur. On top is
the \emph{Relations} pane that lists the relations that are available.  One of
these relations can be selected and its elements will be displayed.  In the
middle appears an \emph{Element Type} pane that shows the element types that
are available for the selected relation.  Selecting one of these types lists
in the the bottom all \emph{Elements} that occur in the selected relation and
are of the selected type. By selecting one element from the \emph{Elements}
pane, that element (and all elements it is associated with by the selected
relation) will be highlighted in the large graphical pane on the right.

There are two visualization methods available that can be selected by the button
at the bottom left that is alternatively labeled as \texttt{View as Files} or
\texttt{View as TreeMap}. In the former case, files are shown as rectangles
with a a pattern of horizontal lines inside that reflect their textual
structure. In the latter case, a tree map is shown of the directory structure
of all files.

Figure Figure~\ref{FIG:rviz1} shows the visualization of facts extracted from
the JHotDraw application. The relation \texttt{IMPLEMENTS} has been selected,
and of the two possible element types \texttt{ClassName} has been chosen.
From the list of possible class names, \texttt{AbstractHandle} has been selected.
The result is that the element itself is shown in the file view (with all lines of its definition displayed in blue),
and all its ``related'' elements (e.g., the interfaces it implements) shown in red.

Figure Figure~\ref{FIG:rviz2} shows the same selection, but this time in the tree map view.

\vspace*{3cm}
\begin{figure}[b]
\begin{center}
\vspace*{-3cm}
\epsfig{figure=figs/teleskoop.ps,width=8cm} \label{FIG:teleskoop}

\end{center}
\end{figure}

\appendix

\chapter{Tables of Built-in Operators} \label{AP:operators}


\begin{center}
\begin{supertabular}{|l|l|c|} \hline
\tablecaption{Built-in operators}
\tablehead{\hline}
\tabletail{\hline} 
{\bf Operator} & {\bf Description} & {\bf Section} \\ \hline \hline
{\tt and}      & Boolean and & \ref{BO:bool}\\
{\tt implies}  & Boolean implication & \ref{BO:bool}\\
{\tt in}       & Membership test on sets/relations& \ref{BO:set-or-rel}\\
{\tt inter}    & Intersection of sets/relations& \ref{BO:set-or-rel}\\
{\tt not}      & Boolean negation & \ref{BO:bool}\\
{\tt notin}    & Non-membership test on sets/relations& \ref{BO:set-or-rel}\\
{\tt or}       & Boolean or & \ref{BO:bool}\\
{\tt union}    & Union of sets/relations& \ref{BO:set-or-rel}\\
{\tt ==}       & Equality of integers & \ref{BO:int}\\
{\tt ==}       & Equality of strings & \ref{BO:str}\\
{\tt ==}       & Equality of locations & \ref{BO:loc}\\
{\tt ==}       & Equality of sets/relations & \ref{BO:set-or-rel}\\

{\tt !=}       & Inequality of integers & \ref{BO:int}\\
{\tt !=}       & Inequality of strings & \ref{BO:str}\\
{\tt !=}       & Inequality of locations & \ref{BO:loc}\\
{\tt !=}       & Inequality of sets/relations & \ref{BO:set-or-rel}\\

{\tt <=}       & Less than or equal of integers & \ref{BO:int}\\
{\tt <=}       & Less than or equal of strings & \ref{BO:str}\\
{\tt <=}       & Textual inclusion of locations & \ref{BO:loc}\\
{\tt <=}       & Subset of sets/relations & \ref{BO:set-or-rel}\\

{\tt <}        & Less than of integers & \ref{BO:int}\\
{\tt <}        & Less than of strings & \ref{BO:str}\\
{\tt <}        & Strict textual inclusion of locations & \ref{BO:loc}\\
{\tt <}        & Strict subset of sets/relations & \ref{BO:set-or-rel}\\

{\tt >=}       & Greater than or equal of integers & \ref{BO:int}\\
{\tt >=}       & Greater than or equal of strings & \ref{BO:str}\\
{\tt >=}       & Textual containment of locations & \ref{BO:loc}\\
{\tt >=}       & Superset of sets/relations & \ref{BO:set-or-rel}\\

{\tt >}        & Greater than of integers & \ref{BO:int}\\
{\tt >}        & Greater than of strings & \ref{BO:str}\\
{\tt >}        & Strict textual containment of locations & \ref{BO:loc}\\
{\tt >}        & Strict superset of sets/relations & \ref{BO:set-or-rel}\\

{\tt +}        & Addition of integers & \ref{BO:int}\\
{\tt -}        & Subtraction of integers & \ref{BO:int}\\
{\tt *}        & Multiplication of integers & \ref{BO:int}\\
{\tt /}        & Division of integers & \ref{BO:int}\\

\verb+\+       & Difference of sets/relations & \ref{BO:set-or-rel}\\

{\tt o}        & Composition of relations  & \ref{BO:relations}\\
{\tt x}        & Carthesian product of sets & \ref{BO:relations}\\

\verb@#@       & Number of elements of set & \ref{BO:misc}\\
\verb@#@       & Number of tuples of relation & \ref{BO:misc}\\

{\tt [-, ]}    & Left image of relation & \ref{BO:relations}\\
{\tt [  ,-]}   & Right image of relation & \ref{BO:relations}\\
{\tt [ ]}      & Right image of relation & \ref{BO:relations}\\

{\tt +}        & Transitive closure of a relation  & \ref{BO:relations}\\
{\tt *}        & Reflexive transitive closure of a relation  & \ref{BO:relations}\\ \hline

\end{supertabular}
\end{center}

\chapter{Tables of Built-in Functions} \label{AP:functions}
\vspace*{-\baselineskip}
%%\tablecaption{Built-in functions}
\tablehead{\hline}
\tabletail{\hline}

\begin{center}
\begin{supertabular}{|l|l|c|}

{\bf Function}         & {\bf Description}   & {\bf Section} \\ \hline \hline

{\tt average}          & Average of a set of integers & \ref{BI:average} \\
{\tt average-domain}   & Average of first elements of tuples in relation & \ref{BI:average-domain} \\
{\tt average-range}    & Average of second elements of tuples in relation & \ref{BI:average-range} \\
{\tt begincol}         & First column of a location & \ref{BI:begincol}\\
{\tt beginline}        & Beginning line of a location & \ref{BI:beginline}\\
{\tt bottom}           & Bottom of a relation & \ref{BI:bottom} \\
{\tt carrier}          & Carrier of a relation & \ref{BI:carrier} \\
{\tt carrierR}         & Carrier restriction of a relation & \ref{BI:carrierR} \\
{\tt carrierX}         & Carrier exclusion of a relation & \ref{BI:carrierX} \\

{\tt compl}            & Complement of a relation & \ref{BI:compl} \\
{\tt endcol}           & Last column of a location & \ref{BI:endcol}\\
{\tt endline}          & Ending line of a location & \ref{BI:endline}\\
{\tt filename}         & File name of a location & \ref{BI:filename}\\
{\tt first}            & First element of a tuple & \ref{BI:first} \\
{\tt id}               & Identity relation & \ref{BI:id} \\
{\tt inv}              & Inverse of a relation & \ref{BI:inv} \\

{\tt domain}           & Domain of a relation & \ref{BI:domain} \\
{\tt domainR}          & Domain restriction of a relation & \ref{BI:domainR} \\
{\tt domainX}          & Domain exclusion of a relation & \ref{BI:domainX} \\
{\tt min}              & Minimum of a set of integers & \ref{BI:max} \\
{\tt max}              & Maximum of a set of integers & \ref{BI:max} \\
{\tt power0}           & Powerset of a set & \ref{BI:power0} \\
{\tt power1}           & Powerset of a set & \ref{BI:power1} \\

{\tt range}            & Range of a relation  & \ref{BI:range} \\
{\tt rangeR}           & Range restriction of a relation & \ref{BI:rangeR} \\
{\tt rangeX}           & Range exclusion of a relation & \ref{BI:rangeX} \\
{\tt reachR}           & Reachability with restriction & \ref{BI:reachR} \\
{\tt reachX}           & Reachability with exclusion& \ref{BI:reachX} \\

{\tt second}           & Second element of a tuple & \ref{BI:second} \\
{\tt sum}              & Sum of a set of integers & \ref{BI:sum} \\
{\tt sum-domain}       & Sum of first elements of tuples in relation & \ref{BI:sum-domain} \\
{\tt sum-range}        & Sum of a first elements of tuples in relation & \ref{BI:sum-range} \\
{\tt top}              & Top of a relation & \ref{BI:top} \\
{\tt unique}           & Deprecated: Set with unique elements & \ref{BI:unique}\\

\end{supertabular}
\end{center}




%%\begin{figure}[h]
%%\begin{center}
%%\epsfig{figure=figs/elektrometer.ps,height=10cm}
%%\end{center}
%%\end{figure}




%%\begin{figure}[h]
%%\begin{center}
%%\epsfig{figure=figs/sonometer.ps,width=15cm}
%%\end{center}
%%\end{figure}



%% \newpage
\section*{Acknowledgments}
Thanks to Tijs van der Storm for many useful discussions and experiments.
Thanks to Murat Ahat, Jan van Eijck, Taeke Kooiker, Tijs van der Storm, Ivan Vankov,
and Jurgen Vinju for comments on this tutorial.

\section*{Illustrations}

Most illustrations used in this tutorial concern physical instruments for
  measurement or observation and are taken from H. van de Stadt, \emph{Beknopt
  Leerboek der Natuurkunde} (Concise Text-book of Physics) Tjeenk Willink,
  Zwolle, 1902.
On the front page appears a windlass that amplifies manual power and is used in
water wells, drilling devices, and wind mills.
Page~\pageref{FIG:balloon}  shows a hot air balloon combined with a parachute
(circa 1900).
On page~\pageref{FIG:microscope} appears a composite microscope as proposed by
Drebbel (1621).
On page~\pageref{FIG:declinatorium} appears a \emph{declinatorium} used to
measure the difference between the magnetic and geographic north pole.
On page~\pageref{FIG:vuurtoren} the cross section is shown of a lighthouse as used along
the Dutch cost.
The spectroscope on page~\pageref{FIG:spektroskoop} is a design using four
prisms by Steinheil
and is used for the improved dispersion and analysis of the light emitted by
sodium vapor.
On page~\pageref{FIG:ruhmkorff} appears Ruhmkorff's induction-coil (1851) used
to create high-Voltage electric currents. 
Page \pageref{FIG:camera-obscura} shows a variation of the \emph{camera obscura} as
used for producing realistic drawings of a landscape.
Lassell's telescope (1863) appears on page~\pageref{FIG:teleskoop}.

 The photograph on page~\pageref{FIG:caruso} is the ``Caruso'' loudspeaker and
  appeared in an advertisement in J. Corver, \emph{Het Draadloos
  Amateurstation} (The Wireless Amateur (Radio) Station), Veenstra, 's
  Gravenhage, 1928.
The sign alphabet on page~\pageref{FIG:signalpha} has been taken from
\url{ www.inquiry.net/outdoor/skills/b-p/signaling.htm}
\bibliographystyle{plain} \bibliography{iwpc,tutorial}

%%\chapter{TO DO}
%%\begin{itemize}
%%\item {\tt all-path-to}, {\tt sort} not described.
%%\item $n$-ary relations
%%\item Termination criteria for solving equations
%%\item Access functions for $n$-ary tuples.
%%\item Describe Rstores
%%\item Give Rscript grammar
%%\item Yield
%%\item Make an index.

%%\end{itemize}

\end{document}
